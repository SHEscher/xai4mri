{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"xai4mri","text":"<p>Explainable A.I. for MRI research using deep learning.</p> <p></p> <p> </p>"},{"location":"#what-is-xai4mri","title":"What is <code>xai4mri</code>","text":"<p><code>xai4mri</code> is designed for advanced MRI analysis combining deep learning with explainable A.I. (XAI). It offers the following key functionalities:</p> <ul> <li>Data Integration: Effortlessly import new MRI datasets and apply the models to generate accurate predictions.</li> <li>Model Loading: Load (pretrained) 3D-convolutional neural network models tailored for MRI predictions.</li> <li>Interpretation Tools: Utilize analyzer tools, such as Layer-wise Relevance Propagation (LRP), to interpret model predictions through intuitive heatmaps.</li> </ul> <p>With <code>xai4mri</code>, you can complement your MRI analysis pipeline, ensuring precise predictions and insightful interpretations.</p>"},{"location":"#quick-start","title":"Quick-start","text":"<pre><code>pip install -U xai4mri\n</code></pre> <p>Get started with <code>xai4mri</code> in Python:</p> <pre><code>import xai4mri as xai\n</code></pre> <p>Visit the documentation, for detailed information.</p>"},{"location":"#citation","title":"Citation","text":"<p>When using <code>xai4mri</code>, please cite the following papers: [<code>toolbox paper in prep</code>] and Hofmann et al. (2022, NeuroImage).</p>"},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#001","title":"0.0.1","text":"<ul> <li>launch <code>xai4mri</code></li> <li>release first draft of documentation</li> </ul>"},{"location":"contributing/","title":"Contributing","text":"<p>Contributions are very welcome, and credit will always be given.</p>"},{"location":"contributing/#setup-for-development","title":"Setup for development","text":"<p>Fork &amp; then clone the repo:</p> <p>Install the dependencies for development, ideally in a virtual environment in editable mode:</p> <pre><code>cd xai4mri\npip install -e \".[develop,docs]\"\n</code></pre>"},{"location":"contributing/#development-workflow","title":"Development workflow","text":"<p>Make changes on a new branch:</p> <pre><code>git checkout -b develop\n</code></pre>"},{"location":"contributing/#testing","title":"Testing","text":"<p>Run the tests:</p> <pre><code>pytest . --cov --cov-report=html\n</code></pre>"},{"location":"contributing/#documentation","title":"Documentation","text":"<p>Use <code>sphinx</code> style docstrings in Python code.</p>"},{"location":"contributing/#pull-request","title":"Pull request","text":"<p>Contributions via pull requests (PR) are welcome. Push your changes to your fork and submit a pull request.</p>"},{"location":"contributing/#misc","title":"Misc","text":"<p>A more comprehensive contribution guide will be added soon.</p>"},{"location":"contributing/#future-directions-todos","title":"Future directions &amp; ToDo's","text":"<ul> <li> add transfer learning protocols</li> <li> model interpreter should check the analyzer type for compatibility with the model</li> <li> add more model architectures</li> <li> also add their pretrained versions</li> <li> add proper docs</li> <li> add examples, tutorials, and/or notebooks</li> <li> see ToDo's in code &amp; open issues</li> </ul>"},{"location":"dataloading/","title":"Loading MRI datasets","text":"<p>MRI datasets can be huge. <code>xai4mri</code> provides a simple way to load MRI datasets in a memory-efficient way. Moreover, <code>xai4mri</code> prepares the data for training and evaluation of deep learning models.</p>"},{"location":"dataloading/#prepare-your-research-data","title":"Prepare your research data","text":"<p>Your study data must be prepared to match the schema of the <code>xai4mri</code> package.</p> <p>It is recommended to use the BIDS format for structuring MRI data and derivatives, as well as to provide a corresponding study table (<code>*.tsv</code>, <code>*.csv</code>). However, the functions in <code>xai4mri.dataloader.datasets</code> allow for other data structures as well.</p>"},{"location":"dataloading/#mri-data","title":"MRI data","text":"<p>It is expected that the background in MRI data is set to zero. Statistical maps with negative and positive values are possible when the background remains set to zero.</p> <p>In the case, multiple MRI sequences and/or derivatives (including statistical maps) are present, but not for all subjects (<code>sid</code>), create separate dataset classes (see below) for each MRI sequence and/or derivative with their own corresponding study table.</p> <p>Why using <code>sid</code>?</p> <p>The <code>sid</code> column will become the index of a <code>pandas.DataFrame</code>, which is passed across the <code>xai4mri</code> package.</p>"},{"location":"dataloading/#study-table","title":"Study table","text":"<p>Importantly, subject IDs (<code>sid</code>) in the study table must correspond to existing MRI data. The first column of the study table must contain subject ID's and must be called '<code>sid</code>'.</p> <p>See the example below:</p> Example study table sid age condition sub-01 25 control sub-02 30 patient sub-03 35 control ... ... ... sub-99 45 patient"},{"location":"dataloading/#implement-your-own-dataset-class","title":"Implement your own dataset class","text":"<p>Inherit from the <code>BaseDataSet</code> to create a new dataset class, as shown in the example below:</p> <pre><code>from pathlib import Path\n\nfrom xai4mri.dataloader import BaseDataSet\n\n\nclass MyStudy(BaseDataSet):\n    def __init__(self):\n        super().__init__(\n            study_table_or_path=\"PATH/TO/STUDY_TABLE.csv\",  # or `*.tsv` OR table as `pd.DataFrame`\n            project_id=\"MyStudy\",  # this can be shared across multiple dataset classes\n            mri_sequence=\"t1w\",  # this should be unique for each dataset class\n            cache_dir=\"PATH/WHERE/TO/CACHE/PROCESSED/DATA\",\n            load_mode=\"full_array\",  # use \"file_path\" for very large datasets (N&gt;&gt;2,500)\n            # Optional kwargs for how to load/process MRIs\n            norm=False,  # Normalize MRI data\n            prune_mode=\"max\",  # Pruning means to minimize the background in the MRIs.\n        )\n\n    # This class method must be implemented\n    def mri_path_constructor(self, sid: str) -&gt; str | Path:\n        \"\"\"\n        Construct the path to the MRI of a given subject for MyStudy.\n\n        MRI data will be loaded using nibabel from given paths.\n\n        :param sid: subject ID\n        :return: absolute file path to MRI of the subject with the given ID\n        \"\"\"\n        return Path(\"PATH/TO/MRI\", sid, f\"MNI/2mm/{self.mri_sequence.upper()}w_brain.nii.gz\")\n</code></pre> About **kwargs in <code>BaseDataSet.__init__()</code> <p>Find details to additional <code>kwargs</code> in docs of <code>_load_data_as_full_array()</code> or <code>_load_data_as_file_paths()</code> in <code>xai4mri.dataloader.mri_dataloader</code>.</p> <p><code>BaseDataSet</code> provides several attributes and methods, see details in API reference</p> MRI pruning for model efficiency <p>The <code>prune_mode</code> parameter is used to minimize the background in MRIs. This is useful for training deep learning models, since the models can become substantially smaller, avoiding redundant parameters. Set <code>prune_mode</code> to <code>None</code> if this is not desired. In how far MRIs are pruned can be adjusted with the <code>PruneConfig</code> object:</p> <p><pre><code>from xai4mri.dataloader.prune_image import PruneConfig\n\n# Check the defeault size of the \"largest brain\"\nprint(PruneConfig.largest_brain_max_axes)\n\n# Adapt the size of the \"largest brain\" to your dataset\nPruneConfig.largest_brain_max_axes = (185, 185, 220)  # always use 1mm isotropic resolution here\n# Note that xai4mri uses the 'LIA' orientation.\n</code></pre> Image pruning will adhere to the settings in <code>PruneConfig.largest_brain_max_axes</code>. During pruning <code>xai4mri</code> automatically adjusts the axes lengths to the resolution of the given MRI dataset. To reverse this process, see Reverse pruning</p> <p>If you are note sure, which values to use for your case, you can use the default values, or run the <code>get_brain_axes_length()</code> in the <code>xai4mri.dataloader.prune_image</code> submodule over your MRI dataset. Then, choose the largest values you found such that all brains will get pruned without cutting off any brain voxels.</p>"},{"location":"dataloading/#instantiate-your-dataset-class","title":"Instantiate your dataset class","text":"<p>Use your project-specific dataset class to process and load data:</p> <pre><code>mydata = MyStudy()\n</code></pre> <p>Processing data might require some time. To get an estimate of cache storage and processing time, use the following:</p> <pre><code>mydata.get_size_of_prospective_mri_set()\n</code></pre> <p>Then get the data. If the data has not been processed yet, this will take some time. After that, the whole data set can be loaded within seconds.</p> <pre><code>volume_data, sid_list = mydata.get_data(**kwargs)\n</code></pre> One more time about **kwargs <p>As mentioned above, <code>**kwargs</code> are passed to the <code>_load_data_as_file_paths</code> or <code>_load_data_as_full_array</code> in <code>xai4mri.Dataloader.mri_dataloader</code> method.</p> <p>If values that were set at the implementation <code>MyStudy()</code> are not desired, they can be passed to <code>get_data()</code>; e.g., getting data with normalization would be archived with <code>mydata.get_data(norm=True)</code>, this overwrites the initially set <code>norm=False</code> (see above).</p>"},{"location":"dataloading/#create-a-data-split-for-model-training-and-evaluation","title":"Create a data split for model training and evaluation","text":"<p>For the training of deep learning models, we need to prepare the data split:</p> <pre><code>split_dict, train_data_gen, val_data_gen, test_data_gen = mydata.create_data_split(\n    target=\"age\",\n    batch_size=4,\n    split_ratio=(0.8, 0.1, 0.1),\n    split_dict=None\n)\n</code></pre> <p>Note</p> <p>The <code>target</code> variable must be a column in the study table.</p> <p>The returned data generators can be used directly for the training of deep learning models based on <code>TensorFlow</code> / <code>Keras</code>.</p> <p>Also, ideally use a small batch size (<code>batch_size</code>) when GPUs are used, since their memory is easily exhausted with relatively big MRIs as model input.</p>"},{"location":"dataloading/#keep-track-of-data-splits","title":"Keep track of data splits","text":"<p><code>split_dict</code> can be used when specific subject ID's shall reside in specific splits. For instance, if you are interested in model predictions for specific subjects, put their ID's (SID's) in the test set:</p> <p>Example</p> <pre><code>split_dict = {\n    \"train\": [\"sid_45\", \"sid_33\", ...],\n    \"validation\": [\"sid_29\", \"sid_11\", ...],\n    \"test\": [\"sid_1\", \"sid_99\", ...]\n}\n</code></pre> <p>If <code>split_dict</code> is provided to the function above, the <code>split_ratio</code> is ignored. Therefore, choose the respective lists of SID's (train, validation, test) such that a desired ratio is achieved.</p>"},{"location":"dataloading/#save-data-splits","title":"Save data splits","text":"<p>If a split dictionary should be saved, use the following:</p> <pre><code># Save latest data split\nsave_path = mydata.save_split_dict()  # this outputs the path to the saved split dictionary\n\n# Alternatively, save a data split to a specified path\nsave_path = \"PATH/TO/SAVE/SPLIT/TO\"  # Optional: define your own path, otherwise None for the default path\nmydata.save_split_dict(split_dict=split_dict, save_path=save_path)\n</code></pre> <p>Keep track of your data splits</p> <p>For later reproducibility, but also model interpretation, it is essential that you know which subject data was used for training and evaluation. Usually, the XAI-based interpretation of model predictions is done on the test set.</p>"},{"location":"dataloading/#load-data-splits","title":"Load data splits","text":"<p>Loading a split dictionary is done with:</p> <pre><code>split_dict = mydata.load_split_dict(split_dict_path=save_path)\n</code></pre>"},{"location":"examples/","title":"Examples of using the <code>xai4mri</code> package","text":"<p>More to come</p> <p>This page is under construction and will be updated with more examples soon.</p> <p>For now, refer to the Usage section, which contains some code snippets already.</p>"},{"location":"installation/","title":"Installation of <code>xai4mri</code>","text":""},{"location":"installation/#python-versions","title":"Python versions","text":"<p><code>xai4mri</code> requires <code>Python 3.9</code> or later, but smaller than <code>&lt;3.12</code>.</p>"},{"location":"installation/#pre-requisites","title":"Pre-requisites","text":"<p>As a first step, it is always recommended to create a new virtual environment.</p> <p><code>xai4mri</code> is specifically developed for MRI-based research. Check out the <code>scilaunch</code> package, which helps to set up new research projects including virtual environments, data management, and more.</p> <p>Virtual environments can also be creating using <code>venv</code>:</p> <pre><code>python -m venv \"myenv_3.11\" --python=python3.11\nsource myenv_3.11/bin/activate\n</code></pre> <p>Or using <code>conda</code>:</p> <pre><code>conda create -n \"myenv_3.11\" python=3.11\nconda activate myenv_3.11\n</code></pre>"},{"location":"installation/#installation","title":"Installation","text":"<p>To install the package, simply use <code>pip</code>:</p> <pre><code>pip install -U xai4mri\n</code></pre> <p></p> <p>You are now ready to use <code>xai4mri</code> in your Python environment.</p>"},{"location":"interpretation/","title":"Explaining MRI-based predictions of deep learning models","text":"<p>Deep learning models have become an essential tool in image analysis, including medical image analysis, and MRI research in general. However, these models are often considered as black boxes, as they are built upon huge parameter spaces and non-linear processing steps. These make their decision-making process hard to explain.</p> <p>New methods have been developed to interpret the predictions of deep learning models and to provide insights into their decision-making process. These methods are summarized under the term explainable artificial intelligence (XAI).</p> <p>The <code>xai4mri</code> package offers a set of tools to apply XAI methods to analyze the predictions of deep learning models for MRI-based tasks.</p>"},{"location":"interpretation/#apply-xai-analyzer-and-interpret-model-predictions","title":"Apply XAI analyzer and interpret model predictions","text":"<p>The <code>model.interpreter</code> submodule of <code>xai4mri</code> is built around the <code>iNNvestigate</code> package. Moreover, there is a strong focus on  Layer-wise Relevance Propagation (LRP), since it has shown to overcome some limitations of other post-hoc XAI methods.</p> <p>The API of the <code>model.interpreter</code> submodule is designed to be straightforward and intuitive, and hides some of the complexity behind these sophisticated methods.</p> <p>To analyze the predictions of a deep learning model, use the <code>analyze_model()</code> to generate a relevance map for a given input MRI. The relevance map highlights the regions of the MRI that are most relevant for the model's prediction. Then, use the <code>plot_heatmap()</code> function to visualize the relevance map:</p> <pre><code>import tensorflow as tf\ntf.compat.v1.disable_eager_execution()  # required for iNNvestigate\n\nfrom xai4mri.model.interpreter import analyze_model\nfrom xai4mri.visualizer import plot_heatmap\n\n# Load your trained model\nmodel: tf.keras.Sequential = ...\n\n# Get your research data\nsplit_dict = mydata.load_split_dict(split_dict_path=\"PATH/TO/SAVED/SPLIT\")\n# ideally, use the same data split as during training\n\n_, train_data_gen, val_data_gen, test_data_gen = mydata.create_data_split(\n    target=\"age\",  # the prediction target\n    batch_size=1,  # here we analyze one MRI at a time\n    split_dict=split_dict,\n)\n\n# Now iterate over images in the test set\nfor input_img, y in test_data_gen:\n    # Compute XAI-based relevance map\n    relevance_map = analyze_model(\n        model=model,\n        ipt=input_img,  # a single MRI\n        norm=True,  # normalize the relevance object\n        neuron_selection=None,  # relevant for classification models\n    )\n\n    # Get model prediction\n    prediction = model.predict(input_img)[0][0]\n    print(f\"prediction = {prediction:.2f} | ground truth = {y[0]:.2f}\")\n\n    # Plot (mid) slice of each axis\n    plot_heatmap(\n        ipt=input_img,\n        analyser_obj=relevance_map,\n        mode=\"triplet\",  # plot one slice of each axis, see doc-string for other options\n        # slice_idx=(15, 60, 45),  # uncomment: specify which slices to plot, otherwise take mid-slices\n        fig_name=f\"Relevance map of {y[0]:.0f}-years old, predicted as {prediction:.1f} from \"\n                 f\"{mydata.mri_sequence.upper()}-MRIs\",\n    )\n</code></pre> <p>Using test set data for explaining model predictions</p> <p>Similar to evaluating the performance of a model, it is recommended to use the test set data for explaining model predictions. You can consider using the validation set as well. However, training set data should be avoided. In the end, this depends on the contex of course (e.g., one could be interested in analyzing the training process with the help of XAI methods).</p>"},{"location":"interpretation/#reverse-pruning-bringing-model-input-and-relevance-maps-back-to-the-nifti-format","title":"Reverse pruning: Bringing model input and relevance maps back to the NIfTI format","text":"<p>Reverse pruning</p> <p>Reverse pruning is useful to compare relevance maps with other statistical maps or atlases in the form of NIfTIs.</p> <p>If MR images have been pruned for more efficient model training (see Implement your own dataset class), the image pruning can be reversed in hindsight. This can be done both for the MRI (model input) and for the computed relevance maps.</p> <p>To reverse the pruning, use a combination of <code>reverse_pruning()</code> in the <code>xai4mri.dataloader.prune_image</code> submodule, and <code>get_unpruned_mri()</code> as a method of the dataset class. See the following for how this is done for the model input image and the relevance map:</p> <pre><code>from xai4mri.dataloader.prune_image import reverse_pruning\n\n# Iterate over images in the test set\nfor input_img, y in test_data_gen:  # here, a batch size of 1 is assumed\n    # Do something with input_img and y, create a relevance map ...\n    relevance_map = analyze_model(model=model, ipt=input_img, ...)\n\n    # Get current SID in the test set\n    current_sid = mydata.sid_list[test_data_gen.current_indices][0]\n\n    # Get the original MRI of the SID (as nib.Nifti1Image)\n    org_img_nii = mydata.get_unpruned_mri(sid=current_sid)\n\n    # Reverse pruning for the input image\n    input_img_nii = reverse_pruning(\n        original_mri=org_img_nii,  # alternatively, an np.ndarray can be passed\n        pruned_mri=input_img.squeeze(),  # (1, x, y, z, 1) -&gt; (x, y, z)\n        pruned_stats_map=None\n    )\n    # if np.ndarray is passed, then reverse_pruning will return a np.ndarray of the original MRI\n\n    # Reverse pruning for the relevance map\n    relevance_map_nii = reverse_pruning(\n        original_mri=org_img_nii,  # reverse pruning for heatmap\n        pruned_mri=input_img.squeeze(),\n        pruned_stats_map=relevance_map.squeeze()  # \u2190 this must be given here\n    )\n</code></pre> <p>Now, both the model input image and the relevance map can be analyzed and plotted with other packages, which can handle the data of type <code>nibabel.Nifti1Image</code>.</p> Exploring relevance maps outside of <code>xai4mri</code> <p>After reverse pruning, and having the relevance map in the NIfTI format, one can use, for instance, the <code>nilearn</code> package to plot the relevance map on top of the MRI:</p> <pre><code>from nilearn import plotting\n\nplotting.plot_stat_map(stat_map_img=relevance_map_nii, bg_img=input_img_nii, ...).\n</code></pre> <p>Or just save the NIfTI files to disk and use other MRI software for further analysis.</p>"},{"location":"license/","title":"License","text":"<p>MIT License for xai4mri</p> <p>Copyright (c) 2024 Simon M. Hofmann</p> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p> <p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p> <p>Cite this repository in your publications if you use this code.</p> <p>THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>"},{"location":"models/","title":"Deep learning models for MRI prediction","text":"<p><code>xai4mri</code> provides deep learning models for MRI-based prediction tasks.</p> <p>You can find out-of-the-box models in the submodule <code>xai4mri.model.mrinets</code>. The models are designed for 3D MRI data specifically (future support for 4D fMRI data is planned), and can be used for both regression or classification tasks.</p> <p>Moreover, there are pretrained models available for some model architectures.</p> <p>Models are built on top of the <code>TensorFlow</code> <code>Keras</code> API. This is necessary to ensure compatibility with the <code>iNNvestigate</code> toolbox for model interpretability.</p>"},{"location":"models/#choose-a-model-architecture","title":"Choose a model architecture","text":"<p>Get an overview of the available deep learning model architectures for MRI prediction tasks:</p> <pre><code>from xai4mri.model.mrinets import OutOfTheBoxModels\n\n# List available model architectures\nOutOfTheBoxModels.show()\n</code></pre> <p>The <code>xai4mri</code> toolbox is an offspring from the work in Hofmann et al. (2022, NeuroImage). While several model architectures are provided, the most stable model type is <code>MRInet</code>. which was introduced in this work.</p> <p>To get a fresh, untrained model use the following:</p> <pre><code>from xai4mri.model.mrinets import get_model, OutOfTheBoxModels, MRInet\n\nMODEL_NAME = \"MyMRInet\"  # name your model, keep for later reference\n\n# Create fresh model\nmodel = MRInet.create(\n                name=\"MyMRInet\",\n                n_classes=40,  # number of classes for classification tasks\n                input_shape=(91, 91, 109),\n                # other parameters are optional\n)\n\n# Alternatively, you can use the get_model function\nmodel = get_model(\n                model_type=OutOfTheBoxModels.MRINET,  # or pass a string \"mrinet\"\n                name=MODEL_NAME,\n                n_classes=False,  # False for regression tasks\n                input_shape=(91, 91, 109),  # shape of one (pruned) MRI in your dataset after processing\n                target_bias=None,  # in a regression task, this could be set to the mean of the target variable\n                learning_rate=5e-4,  # learning rate for the optimizer\n                leaky_relu=False,  # use leaky ReLU instead (but, currently interference with `iNNvestigate`)\n                batch_norm=False,  # use batch normalization (only usefully for models trained on larger batches)\n)\n</code></pre> <p>Shape of the model input</p> <p>The <code>input_shape</code> parameter should be the shape of one MRI in your dataset after processing (including pruning).</p> <p>All models are <code>TensorFlow</code> / <code>Keras</code> models (<code>keras.Sequential</code>) and can be used as such.</p>"},{"location":"models/#train-a-model-for-mri-prediction","title":"Train a model for MRI prediction","text":"<p>To train a model, we follow the standard procedure of <code>TensorFlow</code> / <code>Keras</code> models. Using the <code>xai4mri</code> data loader, you can load your MRI data and train the model (see Create a data split for model training and evaluation).</p> <pre><code>from pathlib import Path\n\nimport tensorflow as tf\n\nPATH_TO_MODEL: str = \"PATH/TO/SAVE/MODEL/TO/{model_name}\"\nEPOCHS: int = 100\n\n# Define checkpoint callbacks (see tf.Keras documentation for details)\nmodel_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n    filepath=str(\n        Path(\n            PATH_TO_MODEL.format(model_name=model.name),\n            \"ckpt\",\n            \"cp-{epoch:03d}\",\n        )\n    ),\n    save_weights_only=True,\n    monitor='val_loss',\n    mode='min',  # 'min' for loss, 'max' for accuracy, OR 'auto'\n    save_best_only=True,\n    save_freq=\"epoch\"\n)\n\ncsv_logger_callback = tf.keras.callbacks.CSVLogger(\n    filename=Path(\n        PATH_TO_MODEL.format(model_name=model.name), \"training_log.csv\"\n    ),\n    separator=\",\",\n)\n\n# Train model\nmodel.fit(\n    train_data_gen,\n    epochs=EPOCHS,\n    validation_data=val_data_gen,\n    callbacks=[model_checkpoint_callback, csv_logger_callback]\n)\n</code></pre> Simplify model training with <code>mono_phase_model_training()</code> <p>To simplify the training process, you can use the <code>mono_phase_model_training()</code> function in <code>xai4mri.model</code>.</p> <pre><code>from xai4mri.model.mrinets import MRInet\nfrom xai4mri.model import mono_phase_model_training\nfrom xai4mri.dataloader.data import BaseDataSet\n\n# Define your dataset\nclass MyDataset(BaseDataSet):\n    ...\n\nmydata = MyDataset()\n\n# Create fresh model\nmodel = MRInet.create(name=MODEL_NAME, n_classes=False, input_shape=(91, 91, 109))\n\n# Train model\ntrained_model = mono_phase_model_training(\n                    model=model,\n                    epochs=40,\n                    data=mydata,\n                    target=\"age\",\n                    model_parent_path=\"PATH/TO/SAVE/MODEL/\",\n                    split_dict=None,\n                    callbacks=None,\n)\n</code></pre>"},{"location":"models/#load-a-trained-model","title":"Load a trained model","text":"<p>After training a model, you can load it from memory using the following code:</p> <pre><code># Create the same model architecture as it was used for model training\nmodel = get_model(\n    model_type=OutOfTheBoxModels.MRINET,\n    name=MODEL_NAME,\n    input_shape=(91, 91, 109),  # shape of one MRI\n    n_classes=False,\n    target_bias=None,\n    learning_rate=5e-4,\n    leaky_relu=False,\n    batch_norm=False\n)\n\n# Load weights of the trained model (see `tf.keras` documentation for details)\nlatest = tf.train.latest_checkpoint(\n    Path(PATH_TO_MODEL.format(model_name=model.name), \"ckpt\")\n)\nmodel.load_weights(latest)\n</code></pre>"},{"location":"models/#get-a-pretrained-model","title":"Get a pretrained model","text":"<p><code>xai4mri</code> ships with pretrained deep learning models for MRI predictions.</p> <p>To check which model architectures have pretrained models available, use the following code:</p> <pre><code>from xai4mri.model.mrinets import OutOfTheBoxModels\n\nOutOfTheBoxModels.MRINET.pretrained_models().show()\n</code></pre> <p>Available pretrained models</p> <p>Currently, there are only pretrained models for <code>MRInet</code> from Hofmann et al. (2022, NeuroImage). There are more pretrained models planned for future releases of <code>xai4mri</code>.</p> <p>To load a pretrained model, use the following code:</p> <pre><code>from xai4mri.model.mrinets import PretrainedMRInetFLAIR\n\n# Load pretrained model\nmodel = PretrainedMRInetFLAIR.load_model(parent_folder=\"PATH/TO/STORE/MODEL/\")\n</code></pre> <p>Loading pretrained models</p> <p><code>load_model()</code> will first check the <code>parent_folder</code> for the model. If the model is not found, it will download the model from the <code>xai4mri</code> repository. Hence, you can use the same code to download and load a pretrained model from memory. However, note, in case you apply the model to a new prediction task, the transferred model should be saved at a different location (see the <code>tf.keras.callback</code> approach in Train a model for MRI prediction).</p> <p>See Model transfer for more details how to transfer a pretrained model to a new dataset.</p>"},{"location":"overview/","title":"Quick overview","text":"<p>The package can be loaded with:</p> <pre><code>import xai4mri as xai\n</code></pre>"},{"location":"overview/#loader-for-mri-datasets","title":"Loader for MRI datasets","text":"<p>Functions to effectively load MRI data for model training and evaluation are in the <code>dataloader</code> submodule.</p> <p>Build your own dataset class. For this, inherit from the <code>BaseDataSet</code> class:</p> <pre><code>from xai4mri.dataloader import BaseDataSet\n</code></pre> <p>See Loading data for more information.</p>"},{"location":"overview/#deep-learning-models-for-mri-prediction","title":"Deep learning models for MRI prediction","text":"<p>Deep learning models are implemented in <code>Keras</code>. This is required for the model analyzer to work, which is based on the <code>iNNvestigate</code> package.</p> <p>Models provided by <code>xai4mri</code> can be trained from scratch or loaded with pretrained weights.</p> <p>Among others, the package offers models based on Hofmann et al. (2022, NeuroImage), i.e., 3D-CNNs (<code>MRInet</code>) that are trained to predict age from various MRI modalities (<code>T1w</code>, <code>FLAIR</code>, <code>SWI</code>).</p> <p>For instance, get the <code>MRInet</code> model with:</p> <pre><code>from xai4mri.model.mrinets import MRInet\n</code></pre> <p>See Model training for more information.</p>"},{"location":"overview/#transfer-pretrained-models-to-new-mri-datasets-and-prediction-tasks","title":"Transfer pretrained models to new MRI datasets and prediction tasks","text":"<p>When using pretrained models, transfer learning can be applied. Find the relevant methods in</p> <pre><code>from xai4mri.model.transfer import *\n</code></pre> <p>Under construction</p> <p>However, note that functions for transfer learning are not fully implemented yet.</p> <p>See Model transfer for more information.</p>"},{"location":"overview/#model-interpretation","title":"Model interpretation","text":"<p>Code for model interpretation using explainable A.I. (XAI) methods can be found in the <code>interpreter</code> submodule.</p> <p>To analyze the predictions of a model, import the following:</p> <pre><code>from xai4mri.model.interpreter import analyze_model\n</code></pre> <p>This is built on top of the XAI package <code>iNNvestigate</code>. The provided methods should work also with CNN architectures other than those offered by <code>xai4mri</code>, given that the models are implemented in <code>Keras</code>.</p> <p></p> <p>See Model interpretation for more information.</p>"},{"location":"overview/#examples-tutorials","title":"Examples &amp; tutorials","text":"<p>For examples and tutorials, see the Examples page.</p>"},{"location":"overview/#citation","title":"Citation","text":"<p>When using <code>xai4mri</code>, please cite the following papers: [<code>toolbox paper in prep</code>] and Hofmann et al. (2022, NeuroImage).</p>"},{"location":"transfer/","title":"Transfer pretrained models to new MRI datasets","text":""},{"location":"transfer/#motivation","title":"Motivation","text":"<p>One major motivator to develop <code>xai4mri</code> is to enable MRI analysis using deep learning models on relatively small datasets.</p> <p>To this end, transfer learning is a promising technique to leverage models, which have been pretrained on large MRI datasets (N &gt;&gt; 2,000, such as the <code>ukbiobank</code>, <code>LIFE Adult study</code>, <code>NAKO</code>, etc.), and apply them to new datasets with fewer samples.</p> <p>Foundation models</p> <p>One major issue with transfer learning is that deep learning models often do not generalize well to new datasets using different MR scanners and recording sequences. To overcome this, the imaging community should develop foundation models. That is, large models that are trained on diverse MRI datasets.</p>"},{"location":"transfer/#application","title":"Application","text":"<p>Under construction</p> <p>Note that functions for transfer learning are not fully implemented yet and still in their infancy.</p> <p>Already existing functionality has been developed using the <code>MRInet</code> architecture. The application to other models architectures is not yet tested.</p> <p><code>xai4mri</code> has some initial functions to transfer pretrained models to new datasets.</p>"},{"location":"transfer/#analyze-a-dataset-and-a-candidate-model","title":"Analyze a dataset and a candidate model","text":"<p>The training of deep learning models can be a time-consuming process, and involves a lot of trial-and-errors to find the best hyperparameters.</p> <p>Building upon heuristics, experiences, and empirical evidence from the literature, there are the following goals for <code>xai4mri</code>:</p> <ol> <li>to estimate the success of transfer learning to new and small MRI datasets, and</li> <li>to suggest training strategies for model transfer</li> </ol> <p>To analyze models and datasets, with the goal to estimate training parameters for transfer learning, use the following function:</p> <pre><code>from xai4mri.model.transfer import analyse_model_and_data\nfrom xai4mri.dataloader.datasets import BaseDataSet\n\n# Get a promising pretrained model\npretrained_model: tf.keras.Sequential = ...\n\n# Define your dataset\nclass MyDataset(BaseDataSet):\n    ...\n\nmydata = MyDataset()\n\n# Now analyze the model and the dataset\nanalyse_model_and_data(model=pretrained_model, data=mydata)\n</code></pre> <p>Not implemented yet</p> <p>This is, unfortunately, not implemented yet. But since it is a promising feature, it is mentioned here already. Feel invited to contribute to this feature, see Contributing.</p>"},{"location":"transfer/#reconstruct-an-existing-model","title":"Reconstruct an existing model","text":"<p>To apply a pretrained model to a new dataset might require reconstructing the model. That is, to adapt its output layer to the requirements of the new prediction task.</p> <p>For this, use the following function:</p> <pre><code>from xai4mri.model.transfer import adapt_model\n\n# Get a pretrained model\npretrained_model: tf.keras.Sequential = ...\n# for instance, this could be a model trained to predict 40 classes in a large MRI dataset\n\nadapted_model = adapt_model(\n    model=pretrained_model,\n    learning_rate=0.01,\n    n_classes=2,  # number of classes in the new dataset\n)\n</code></pre>"},{"location":"transfer/#run-transfer-learning","title":"Run transfer learning","text":"<p>Mono-phase model training</p> <p>The function <code>mono_phase_model_training()</code> in <code>xai4mri.model.transfer</code> can also be used to train a new (i.e., untrained) model on a dataset (see Train a model for MRI prediction).</p> <p>Currently, there are two experimental ways to run transfer learning: Mono-phase and dual-phase training. The former classically trains a model on a dataset from the beginning to the end. The latter trains a model in two phases: first, all layers of the model are trained. Then, the first layers get frozen, and only the last layers get fine-tuned.</p> <p>Since these functions are still in an experimental phase, refer to the doc-strings in the Code section: See <code>mono_phase_model_training()</code> and <code>dual_phase_model_training ()</code> in <code>xai4mri.model.transfer</code> for more information.</p>"},{"location":"reference/","title":"Index","text":""},{"location":"reference/#xai4mri","title":"xai4mri","text":"<p>Init of the <code>xai4mri</code> package.</p> <p>This package provides tools for explainable AI (XAI) in MRI research using deep learning.</p> <pre><code>Author: Simon M. Hofmann\nYears: 2023-2024\n</code></pre>"},{"location":"reference/utils/","title":"<code class=\"doc-symbol doc-symbol-nav doc-symbol-module\"></code> utils","text":""},{"location":"reference/utils/#xai4mri.utils","title":"utils","text":"<p>Collection of utility functions for <code>xai4mri</code>.</p> <pre><code>Author: Simon M. Hofmann\nYears: 2023\n</code></pre>"},{"location":"reference/utils/#xai4mri.utils.Bcolors","title":"Bcolors","text":"<p>Use for color print-commands in console.</p> <p>Usage</p> <pre><code>print(Bcolors.HEADER + \"Warning: No active frommets remain. Continue?\" + Bcolors.ENDC)\nprint(Bcolors.OKBLUE + \"Warning: No active frommets remain. Continue?\" + Bcolors.ENDC)\n</code></pre> For more colors: Name Color Code CSELECTED \\33[7m CBLACK \\33[30m CRED \\33[31m CGREEN \\33[32m CYELLOW \\33[33m CBLUE \\33[34m CVIOLET \\33[35m CBEIGE \\33[36m CWHITE \\33[37m CBLACKBG \\33[40m CREDBG \\33[41m CGREENBG \\33[42m CYELLOWBG \\33[43m CBLUEBG \\33[44m CVIOLETBG \\33[45m CBEIGEBG \\33[46m CWHITEBG \\33[47m CGREY \\33[90m CBEIGE2 \\33[96m CWHITE2 \\33[97m CGREYBG \\33[100m CREDBG2 \\33[101m CGREENBG2 \\33[102m CYELLOWBG2 \\33[103m CBLUEBG2 \\33[104m CVIOLETBG2 \\33[105m CBEIGEBG2 \\33[106m CWHITEBG2 \\33[107m For preview use: <pre><code>for i in (\n    [1, 4, 7] + list(range(30, 38)) + list(range(40, 48)) + list(range(90, 98)) + list(range(100, 108))\n):  # range(107+1)\n    print(i, \"\\33[{}m\".format(i) + \"ABC &amp; abc\" + \"\\33[0m\")\n</code></pre>"},{"location":"reference/utils/#xai4mri.utils.ask_true_false","title":"ask_true_false","text":"<pre><code>ask_true_false(question: str, col: str = 'b') -&gt; None\n</code></pre> <p>Ask user for input for a given <code>True</code>-or-<code>False</code> question.</p> <p>Parameters:</p> Name Type Description Default <code>question</code> <code>str</code> <p>Question to be asked to the user.</p> required <code>col</code> <code>str</code> <p>Print-color of question ['b'(lue), 'g'(reen), 'y'(ellow), 'r'(ed)]</p> <code>'b'</code> <p>Returns:</p> Type Description <code>None</code> <p>Answer to the question.</p> Source code in <code>src/xai4mri/utils.py</code> <pre><code>@_true_false_request\ndef ask_true_false(question: str, col: str = \"b\") -&gt; None:\n    \"\"\"\n    Ask user for input for a given `True`-or-`False` question.\n\n    :param question: Question to be asked to the user.\n    :param col: Print-color of question ['b'(lue), 'g'(reen), 'y'(ellow), 'r'(ed)]\n    :return: Answer to the question.\n    \"\"\"\n    cprint(string=question, col=col)\n</code></pre>"},{"location":"reference/utils/#xai4mri.utils.browse_files","title":"browse_files","text":"<pre><code>browse_files(\n    initialdir: str | None = None,\n    filetypes: str | None = None,\n) -&gt; str\n</code></pre> <p>Interactively browse and choose a file from the finder.</p> <p>This function is a wrapper around the <code>tkinter.filedialog.askopenfilename</code> function and uses a GUI to select a file.</p> Note <p>ARGS MUST BE NAMED 'initialdir' and 'filetypes'.</p> <p>Parameters:</p> Name Type Description Default <code>initialdir</code> <code>str | None</code> <p>Directory, where the search should start</p> <code>None</code> <code>filetypes</code> <code>str | None</code> <p>What type of file-ending is searched for (suffix, e.g., <code>*.jpg</code>)</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>Path to the chosen file.</p> Source code in <code>src/xai4mri/utils.py</code> <pre><code>def browse_files(initialdir: str | None = None, filetypes: str | None = None) -&gt; str:\n    \"\"\"\n    Interactively browse and choose a file from the finder.\n\n    This function is a wrapper around the `tkinter.filedialog.askopenfilename` function\n    and uses a GUI to select a file.\n\n    ??? note\n        ARGS MUST BE NAMED 'initialdir' and 'filetypes'.\n\n    :param initialdir: Directory, where the search should start\n    :param filetypes: What type of file-ending is searched for (suffix, e.g., `*.jpg`)\n    :return: Path to the chosen file.\n    \"\"\"\n    import tkinter  # noqa: PLC0415, RUF100\n\n    root = tkinter.Tk()\n    root.withdraw()\n\n    kwargs = {}\n    if initialdir:\n        kwargs.update({\"initialdir\": initialdir})\n    if filetypes:\n        kwargs.update({\"filetypes\": [(filetypes + \" File\", \"*.\" + filetypes.lower())]})\n\n    return tkinter.filedialog.askopenfilename(parent=root, title=\"Choose the file\", **kwargs)\n</code></pre>"},{"location":"reference/utils/#xai4mri.utils.bytes_to_rep_string","title":"bytes_to_rep_string","text":"<pre><code>bytes_to_rep_string(number_of_bytes: int) -&gt; str\n</code></pre> <p>Convert the number of bytes into representative string.</p> <p>The function is used to convert the number of bytes into a human-readable format.</p> <p>The function rounds the number of bytes to two decimal places.</p> <p>Example</p> <pre><code>print(bytes_to_rep_string(1_500_000))  # 1.5 MB\nprint(bytes_to_rep_string(1_005_500_000))  # 1.01 GB\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>number_of_bytes</code> <code>int</code> <p>Number of bytes.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Representative string of the given bytes number.</p> Source code in <code>src/xai4mri/utils.py</code> <pre><code>def bytes_to_rep_string(number_of_bytes: int) -&gt; str:\n    \"\"\"\n    Convert the number of bytes into representative string.\n\n    The function is used to convert the number of bytes into a human-readable format.\n\n    !!! note \"The function rounds the number of bytes to two decimal places.\"\n\n    !!! example\n        ```python\n        print(bytes_to_rep_string(1_500_000))  # 1.5 MB\n        print(bytes_to_rep_string(1_005_500_000))  # 1.01 GB\n        ```\n\n    :param number_of_bytes: Number of bytes.\n    :return: Representative string of the given bytes number.\n    \"\"\"\n    size_name = (\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\", \"EB\", \"ZB\", \"YB\")\n    i = int(math.floor(math.log(number_of_bytes, 10**3)))\n    p = math.pow(10**3, i)\n    size_ = round(number_of_bytes / p, 2)\n\n    return f\"{size_} {size_name[i]}\"\n</code></pre>"},{"location":"reference/utils/#xai4mri.utils.check_storage_size","title":"check_storage_size","text":"<pre><code>check_storage_size(obj: Any, verbose: bool = True) -&gt; int\n</code></pre> <p>Return the storage size of a given object in an appropriate unit.</p> <p>Example</p> <pre><code>import numpy as np\n\na = np.random.rand(500, 500)\nsize_in_bytes = check_storage_size(obj=a, verbose=True)  # \"Size of given object: 2.0 MB\"\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>Any</code> <p>Any object in the workspace.</p> required <code>verbose</code> <code>bool</code> <p>Print human-readable size of the object and additional information.</p> <code>True</code> <p>Returns:</p> Type Description <code>int</code> <p>Object size in bytes.</p> Source code in <code>src/xai4mri/utils.py</code> <pre><code>def check_storage_size(obj: Any, verbose: bool = True) -&gt; int:\n    \"\"\"\n    Return the storage size of a given object in an appropriate unit.\n\n    !!! example\n        ```python\n        import numpy as np\n\n        a = np.random.rand(500, 500)\n        size_in_bytes = check_storage_size(obj=a, verbose=True)  # \"Size of given object: 2.0 MB\"\n        ```\n\n    :param obj: Any object in the workspace.\n    :param verbose: Print human-readable size of the object and additional information.\n    :return: Object size in bytes.\n    \"\"\"\n    if isinstance(obj, np.ndarray):\n        size_bytes = obj.nbytes\n        message = \"\"\n    else:\n        size_bytes = sys.getsizeof(obj)\n        message = \"Only trustworthy for pure python objects, otherwise returns size of view object.\"\n\n    if size_bytes == 0:\n        if verbose:\n            print(\"Size of given object equals 0 B\")\n        return 0\n\n    if verbose:\n        print(f\"Size of given object: {bytes_to_rep_string(number_of_bytes=size_bytes)} {message}\")\n\n    return size_bytes\n</code></pre>"},{"location":"reference/utils/#xai4mri.utils.chop_microseconds","title":"chop_microseconds","text":"<pre><code>chop_microseconds(delta: timedelta) -&gt; timedelta\n</code></pre> <p>Chop microseconds from given time delta.</p> <p>Parameters:</p> Name Type Description Default <code>delta</code> <code>timedelta</code> <p>time delta</p> required <p>Returns:</p> Type Description <code>timedelta</code> <p>time delta without microseconds</p> Source code in <code>src/xai4mri/utils.py</code> <pre><code>def chop_microseconds(delta: timedelta) -&gt; timedelta:\n    \"\"\"\n    Chop microseconds from given time delta.\n\n    :param delta: time delta\n    :return: time delta without microseconds\n    \"\"\"\n    return delta - timedelta(microseconds=delta.microseconds)\n</code></pre>"},{"location":"reference/utils/#xai4mri.utils.compute_array_size","title":"compute_array_size","text":"<pre><code>compute_array_size(\n    shape: tuple[int, ...] | list[int, ...],\n    dtype: dtype | int | float,\n    verbose: bool = False,\n) -&gt; int\n</code></pre> <p>Compute the theoretical size of a NumPy array with the given shape and data type.</p> <p>The idea is to compute the size of the array before creating it to avoid potential memory issues.</p> <p>Parameters:</p> Name Type Description Default <code>shape</code> <code>tuple[int, ...] | list[int, ...]</code> <p>Shape of the array, e.g., <code>(n_samples, x, y, z)</code>.</p> required <code>dtype</code> <code>dtype | int | float</code> <p>Data type of the array elements (e.g., np.float32, np.int64, np.uint8, int, float)</p> required <code>verbose</code> <code>bool</code> <p>Print the size of the array in readable format or not.</p> <code>False</code> <p>Returns:</p> Type Description <code>int</code> <p>Size of the array in bytes.</p> Source code in <code>src/xai4mri/utils.py</code> <pre><code>def compute_array_size(\n    shape: tuple[int, ...] | list[int, ...], dtype: np.dtype | int | float, verbose: bool = False\n) -&gt; int:\n    \"\"\"\n    Compute the theoretical size of a NumPy array with the given shape and data type.\n\n    The idea is to compute the size of the array before creating it to avoid potential memory issues.\n\n    :param shape: Shape of the array, e.g., `(n_samples, x, y, z)`.\n    :param dtype: Data type of the array elements (e.g., np.float32, np.int64, np.uint8, int, float)\n    :param verbose: Print the size of the array in readable format or not.\n    :return: Size of the array in bytes.\n    \"\"\"\n    # Get the size of each element in bytes\n    element_size = np.dtype(dtype).itemsize\n    # Compute the total number of elements\n    num_elements = np.prod(shape)\n    # Compute the total size in bytes\n    total_size_in_bytes = num_elements * element_size\n    if verbose:\n        print(f\"Size of {dtype.__name__}-array of shape {shape}: {bytes_to_rep_string(total_size_in_bytes)}\")\n    return total_size_in_bytes\n</code></pre>"},{"location":"reference/utils/#xai4mri.utils.cprint","title":"cprint","text":"<pre><code>cprint(\n    string: str,\n    col: str | None = None,\n    fm: str | None = None,\n    ts: bool = False,\n) -&gt; None\n</code></pre> <p>Colorize and format print-out.</p> <p>Add leading time-stamp (fs) if required.</p> <p>Parameters:</p> Name Type Description Default <code>string</code> <code>str</code> <p>Print message.</p> required <code>col</code> <code>str | None</code> <p>Color:'p'(ink), 'b'(lue), 'g'(reen), 'y'(ellow), OR 'r'(ed).</p> <code>None</code> <code>fm</code> <code>str | None</code> <p>Format: 'ul'(:underline) OR 'bo'(:bold).</p> <code>None</code> <code>ts</code> <code>bool</code> <p>Add leading time-stamp.</p> <code>False</code> Source code in <code>src/xai4mri/utils.py</code> <pre><code>def cprint(string: str, col: str | None = None, fm: str | None = None, ts: bool = False) -&gt; None:\n    \"\"\"\n    Colorize and format print-out.\n\n    Add leading time-stamp (fs) if required.\n\n    :param string: Print message.\n    :param col: Color:'p'(ink), 'b'(lue), 'g'(reen), 'y'(ellow), OR 'r'(ed).\n    :param fm: Format: 'ul'(:underline) OR 'bo'(:bold).\n    :param ts: Add leading time-stamp.\n    \"\"\"\n    if col:\n        col = col[0].lower()\n        if col not in {\"p\", \"b\", \"g\", \"y\", \"r\"}:\n            msg = \"col must be 'p'(ink), 'b'(lue), 'g'(reen), 'y'(ellow), 'r'(ed)\"\n            raise ValueError(msg)\n        col = Bcolors.DICT[col]\n\n    if fm:\n        fm = fm[0:2].lower()\n        if fm not in {\"ul\", \"bo\"}:\n            msg = \"fm must be 'ul'(:underline), 'bo'(:bold)\"\n            raise ValueError(msg)\n        fm = Bcolors.DICT[fm]\n\n    if ts:\n        pfx = \"\"  # collecting leading indent or new line\n        while string.startswith(\"\\n\") or string.startswith(\"\\t\"):\n            pfx += string[:1]\n            string = string[1:]\n        string = f\"{pfx}{datetime.now():%Y-%m-%d %H:%M:%S} | \" + string\n\n    print(f\"{col if col else ''}{fm if fm else ''}{string}{Bcolors.ENDC}\")\n</code></pre>"},{"location":"reference/utils/#xai4mri.utils.function_timed","title":"function_timed","text":"<pre><code>function_timed(\n    dry_funct: Callable[..., Any] | None = None,\n    ms: bool | None = None,\n) -&gt; Callable[..., Any]\n</code></pre> <p>Time the processing duration of wrapped function.</p> <p>How to use the <code>function_timed</code></p> <p>The following returns the duration of the function call without micro-seconds: <pre><code># Implement a function to be timed\n@function_timed\ndef abc():\n    return 2 + 2\n\n\n# Call the function and get the processing time\nabc()\n</code></pre></p> <p>The following returns micro-seconds as well: <pre><code>@function_timed(ms=True)\ndef abcd():\n    return 2 + 2\n</code></pre></p> <p>Parameters:</p> Name Type Description Default <code>dry_funct</code> <code>Callable[..., Any] | None</code> <p>Parameter can be ignored. Results in output without micro-seconds.</p> <code>None</code> <code>ms</code> <code>bool | None</code> <p>If micro-seconds should be printed, set to <code>True</code>.</p> <code>None</code> <p>Returns:</p> Type Description <code>Callable[..., Any]</code> <p>Wrapped function with processing time.</p> Source code in <code>src/xai4mri/utils.py</code> <pre><code>def function_timed(dry_funct: Callable[..., Any] | None = None, ms: bool | None = None) -&gt; Callable[..., Any]:\n    \"\"\"\n    Time the processing duration of wrapped function.\n\n    !!! example \"How to use the `function_timed`\"\n\n        The following returns the duration of the function call without micro-seconds:\n        ```python\n        # Implement a function to be timed\n        @function_timed\n        def abc():\n            return 2 + 2\n\n\n        # Call the function and get the processing time\n        abc()\n        ```\n\n        The following returns micro-seconds as well:\n        ```python\n        @function_timed(ms=True)\n        def abcd():\n            return 2 + 2\n        ```\n\n    :param dry_funct: *Parameter can be ignored*. Results in output without micro-seconds.\n    :param ms: If micro-seconds should be printed, set to `True`.\n    :return: Wrapped function with processing time.\n    \"\"\"\n\n    def _function_timed(funct):\n        @wraps(funct)\n        def wrapper(*args, **kwargs):\n            \"\"\"Wrap function to time the processing duration of wrapped function.\"\"\"\n            start_timer = datetime.now()\n\n            # whether to suppress wrapper: use functimer=False in main funct\n            w = kwargs.pop(\"functimer\", True)\n\n            output = funct(*args, **kwargs)\n\n            duration = datetime.now() - start_timer\n\n            if w:\n                if ms:\n                    print(f\"\\nProcessing time of {funct.__name__}: {duration} [h:m:s:ms]\")\n\n                else:\n                    print(f\"\\nProcessing time of {funct.__name__}: {chop_microseconds(duration)} [h:m:s]\")\n\n            return output\n\n        return wrapper\n\n    if dry_funct:\n        return _function_timed(dry_funct)\n\n    return _function_timed\n</code></pre>"},{"location":"reference/utils/#xai4mri.utils.get_string_overlap","title":"get_string_overlap","text":"<pre><code>get_string_overlap(s1: str, s2: str) -&gt; str\n</code></pre> <p>Find the longest overlap between two strings, starting from the left.</p> <p>Example</p> <pre><code>get_string_overlap(\"Hello there Bob\", \"Hello there Alice\")  # \"Hello there \"\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>s1</code> <code>str</code> <p>First string.</p> required <code>s2</code> <code>str</code> <p>Second string.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Longest overlap between the two strings.</p> Source code in <code>src/xai4mri/utils.py</code> <pre><code>def get_string_overlap(s1: str, s2: str) -&gt; str:\n    \"\"\"\n    Find the longest overlap between two strings, starting from the left.\n\n    !!! example\n        ```python\n        get_string_overlap(\"Hello there Bob\", \"Hello there Alice\")  # \"Hello there \"\n        ```\n    :param s1: First string.\n    :param s2: Second string.\n    :return: Longest overlap between the two strings.\n    \"\"\"\n    s = difflib.SequenceMatcher(None, s1, s2)\n    pos_a, _, size = s.find_longest_match(0, len(s1), 0, len(s2))  # _ = pos_b\n\n    return s1[pos_a : pos_a + size]\n</code></pre>"},{"location":"reference/utils/#xai4mri.utils.normalize","title":"normalize","text":"<pre><code>normalize(\n    array: ndarray,\n    lower_bound: int | float,\n    upper_bound: int | float,\n    global_min: int | float | None = None,\n    global_max: int | float | None = None,\n) -&gt; ndarray\n</code></pre> <p>Min-max-scaling: Normalize an input array to lower and upper bounds.</p> <p>Parameters:</p> Name Type Description Default <code>array</code> <code>ndarray</code> <p>Array to be transformed.</p> required <code>lower_bound</code> <code>int | float</code> <p>Lower bound <code>a</code>.</p> required <code>upper_bound</code> <code>int | float</code> <p>Upper bound <code>b</code>.</p> required <code>global_min</code> <code>int | float | None</code> <p>Global minimum. If the array is part of a larger tensor, normalize w.r.t. global min and ...</p> <code>None</code> <code>global_max</code> <code>int | float | None</code> <p>Global maximum. If the array is part of a larger tensor, normalize w.r.t. ... and global max (i.e., tensor min/max)</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Normalized array.</p> Source code in <code>src/xai4mri/utils.py</code> <pre><code>def normalize(\n    array: np.ndarray,\n    lower_bound: int | float,\n    upper_bound: int | float,\n    global_min: int | float | None = None,\n    global_max: int | float | None = None,\n) -&gt; np.ndarray:\n    \"\"\"\n    Min-max-scaling: Normalize an input array to lower and upper bounds.\n\n    :param array: Array to be transformed.\n    :param lower_bound: Lower bound `a`.\n    :param upper_bound: Upper bound `b`.\n    :param global_min: Global minimum.\n                       If the array is part of a larger tensor, normalize w.r.t. global min and ...\n    :param global_max: Global maximum.\n                       If the array is part of a larger tensor, normalize w.r.t. ... and global max\n                       (i.e., tensor min/max)\n    :return: Normalized array.\n    \"\"\"\n    if lower_bound &gt;= upper_bound:\n        msg = \"lower_bound must be &lt; upper_bound\"\n        raise ValueError(msg)\n\n    array = np.array(array)\n    a, b = lower_bound, upper_bound\n\n    if global_min is not None:\n        if not np.isclose(global_min, np.nanmin(array)) and global_min &gt; np.nanmin(array):\n            # Allow a small tolerance for global_min\n            msg = \"global_min must be &lt;= np.nanmin(array)\"\n            raise ValueError(msg)\n        mini = global_min\n    else:\n        mini = np.nanmin(array)\n\n    if global_max is not None:\n        if not np.isclose(global_max, np.nanmax(array)) and global_max &lt; np.nanmax(array):\n            # Allow a small tolerance for global_max\n            msg = \"global_max must be &gt;= np.nanmax(array)\"\n            raise ValueError(msg)\n        maxi = global_max\n    else:\n        maxi = np.nanmax(array)\n\n    return (b - a) * ((array - mini) / (maxi - mini)) + a\n</code></pre>"},{"location":"reference/utils/#xai4mri.utils.run_gpu_test","title":"run_gpu_test","text":"<pre><code>run_gpu_test(log_device_placement: bool = False) -&gt; bool\n</code></pre> <p>Test GPU implementation.</p> <p>Parameters:</p> Name Type Description Default <code>log_device_placement</code> <code>bool</code> <p>Log device placement.</p> <code>False</code> <p>Returns:</p> Type Description <code>bool</code> <p>GPU available or not.</p> Source code in <code>src/xai4mri/utils.py</code> <pre><code>def run_gpu_test(log_device_placement: bool = False) -&gt; bool:\n    \"\"\"\n    Test GPU implementation.\n\n    :param log_device_placement: Log device placement.\n    :return: GPU available or not.\n    \"\"\"\n    import tensorflow as tf  # noqa: PLC0415, RUF100\n\n    n_gpus = len(tf.config.list_physical_devices(\"GPU\"))\n    gpu_available = n_gpus &gt; 0\n    cprint(string=f\"\\nNumber of GPU device(s) available: {n_gpus}\", col=\"g\" if gpu_available else \"r\", fm=\"bo\")\n\n    # Run some operations on the GPU/CPU\n    device_name = [\"/gpu:0\", \"/cpu:0\"] if gpu_available else [\"/cpu:0\"]\n    tf.debugging.set_log_device_placement(log_device_placement)\n    for device in device_name:\n        for shape in [6000, 12000]:\n            cprint(string=f\"\\nRun operations on device: {device} using tensor with shape: {shape}\", col=\"b\", fm=\"ul\")\n            with tf.device(device):\n                # Create some tensors and perform an operation\n                start_time = datetime.now()\n                a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n                b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n                c = tf.matmul(a, b)\n                print(f\"{c = }\")\n\n                # Create some more complex tensors and perform an operation\n                random_matrix = tf.compat.v1.random_uniform(shape=(shape, shape), minval=0, maxval=1)\n                dot_operation = tf.matmul(random_matrix, tf.transpose(random_matrix))\n                sum_operation = tf.reduce_sum(dot_operation)\n                print(f\"{sum_operation = }\")\n\n            print(\"\\n\")\n            cprint(string=f\"Shape: {(shape, shape)} | Device: {device}\", col=\"y\")\n            cprint(string=f\"Time taken: {datetime.now() - start_time}\", col=\"y\")\n            print(\"\\n\" + \"*&lt;o&gt;\" * 15)\n\n    cprint(string=f\"\\nGPU available: {gpu_available}\", col=\"g\" if gpu_available else \"y\", fm=\"bo\")\n    return gpu_available\n</code></pre>"},{"location":"reference/utils/#xai4mri.utils.tree","title":"tree","text":"<pre><code>tree(directory: str | Path) -&gt; None\n</code></pre> <p>Print the directory tree starting at <code>directory</code>.</p> <p>Use the same way as <code>shell</code> command <code>tree</code>.</p> <p>This leads to output such as:</p> <pre><code>directory/\n\u251c\u2500\u2500 _static/\n\u2502   \u251c\u2500\u2500 embedded/\n\u2502   \u2502   \u251c\u2500\u2500 deep_file\n\u2502   \u2502   \u2514\u2500\u2500 very/\n\u2502   \u2502       \u2514\u2500\u2500 deep/\n\u2502   \u2502           \u2514\u2500\u2500 folder/\n\u2502   \u2502               \u2514\u2500\u2500 very_deep_file\n\u2502   \u2514\u2500\u2500 less_deep_file\n\u251c\u2500\u2500 about.rst\n\u251c\u2500\u2500 conf.py\n\u2514\u2500\u2500 index.rst\n</code></pre> Source code in <code>src/xai4mri/utils.py</code> <pre><code>def tree(directory: str | Path) -&gt; None:\n    \"\"\"\n    Print the directory tree starting at `directory`.\n\n    Use the same way as `shell` command `tree`.\n\n    !!! example \"This leads to output such as:\"\n        ```plaintext\n        directory/\n        \u251c\u2500\u2500 _static/\n        \u2502   \u251c\u2500\u2500 embedded/\n        \u2502   \u2502   \u251c\u2500\u2500 deep_file\n        \u2502   \u2502   \u2514\u2500\u2500 very/\n        \u2502   \u2502       \u2514\u2500\u2500 deep/\n        \u2502   \u2502           \u2514\u2500\u2500 folder/\n        \u2502   \u2502               \u2514\u2500\u2500 very_deep_file\n        \u2502   \u2514\u2500\u2500 less_deep_file\n        \u251c\u2500\u2500 about.rst\n        \u251c\u2500\u2500 conf.py\n        \u2514\u2500\u2500 index.rst\n        ```\n    \"\"\"\n    paths = _DisplayablePath.make_tree(Path(directory))\n    for path in paths:\n        print(path.displayable())\n</code></pre>"},{"location":"reference/dataloader/","title":"Index","text":""},{"location":"reference/dataloader/#xai4mri.dataloader","title":"dataloader","text":"<p>Init <code>dataloader</code> submodule of <code>xai4mri</code>.</p>"},{"location":"reference/dataloader/#xai4mri.dataloader.BaseDataSet","title":"BaseDataSet","text":"<pre><code>BaseDataSet(\n    study_table_or_path: DataFrame | str | Path,\n    project_id: str,\n    mri_sequence: str,\n    register_to_mni: int | None = None,\n    cache_dir: str | Path = CACHE_DIR,\n    load_mode: str = \"full_array\",\n    **kwargs\n)\n</code></pre> <p>               Bases: <code>ABC</code></p> <p>Base class for an MRI dataset.</p> <p>In the case of a research project with multiple MRI sequences, each sequence must have its own dataset class that inherits from the BaseDataSet class.</p> <p>Initialize BaseDataSet.</p> <p>Usage</p> <pre><code># Create a study-specific dataset class\nclass MyStudyData(BaseDataSet):\n    def __init__(self):\n        super().__init__(\n            study_table_or_path=\"PATH/TO/STUDY_TABLE.csv\",  # one column must be 'sid' (subject ID)\n            project_id=\"MyProjectID\",\n            mri_sequence=\"t1w\",  # this is of descriptive nature, for projects with multiple MRI sequences\n            load_mode=\"full_array\",  # or 'file_paths' for very large datasets\n        )\n\n    # Define mri_path_constructor\n    def mri_path_constructor(sid: str) -&gt; str | Path:\n        return f\"/path/to/mri/{sid}.nii.gz\"\n\n\n# Instantiate the dataset class\nmy_study_data = MyStudyData()\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>study_table_or_path</code> <code>DataFrame | str | Path</code> <p>The study table, OR the absolute or relative path to the table [<code>*.csv</code> | <code>*.tsv</code>]. The table must have 'sid' as the index column, containing subject IDs.</p> required <code>project_id</code> <code>str</code> <p>The project ID.</p> required <code>mri_sequence</code> <code>str</code> <p>MRI sequence ('t1_mni_1mm', 't2', 'dwi', or similar). This is of a descriptive nature for projects with multiple MRI sequences, hence multiple offsprings of <code>BaseDataSet</code>.</p> required <code>register_to_mni</code> <code>int | None</code> <p>Register MRIs to the MNI space (1 mm, 2 mm) using <code>ANTs</code>, OR not [<code>None</code>].</p> <code>None</code> <code>cache_dir</code> <code>str | Path</code> <p>Path to the cache directory, where intermediate and processed data is stored.</p> <code>CACHE_DIR</code> <code>load_mode</code> <code>str</code> <p>Load mode for the dataset: 'file_paths': Load the MRI data from file paths (recommended for very large datasets). 'full_array': Load the MRI data as a full array (default).</p> <code>'full_array'</code> <code>kwargs</code> <p>Additional keyword arguments for MRI processing. Find details to <code>kwargs</code> in docs of <code>xai4mri.dataloader.mri_dataloader._load_data_as_full_array()</code> or <code>_load_data_as_file_paths()</code>.</p> <code>{}</code> Source code in <code>src/xai4mri/dataloader/datasets.py</code> <pre><code>def __init__(\n    self,\n    study_table_or_path: pd.DataFrame | str | Path,\n    project_id: str,\n    mri_sequence: str,\n    register_to_mni: int | None = None,\n    cache_dir: str | Path = CACHE_DIR,\n    load_mode: str = \"full_array\",\n    **kwargs,\n):\n    \"\"\"\n    Initialize BaseDataSet.\n\n    !!! example \"Usage\"\n        ```python\n        # Create a study-specific dataset class\n        class MyStudyData(BaseDataSet):\n            def __init__(self):\n                super().__init__(\n                    study_table_or_path=\"PATH/TO/STUDY_TABLE.csv\",  # one column must be 'sid' (subject ID)\n                    project_id=\"MyProjectID\",\n                    mri_sequence=\"t1w\",  # this is of descriptive nature, for projects with multiple MRI sequences\n                    load_mode=\"full_array\",  # or 'file_paths' for very large datasets\n                )\n\n            # Define mri_path_constructor\n            def mri_path_constructor(sid: str) -&gt; str | Path:\n                return f\"/path/to/mri/{sid}.nii.gz\"\n\n\n        # Instantiate the dataset class\n        my_study_data = MyStudyData()\n        ```\n\n    :param study_table_or_path: The study table, OR the absolute or relative path to the table [`*.csv` | `*.tsv`].\n                                The table must have 'sid' as the index column, containing subject IDs.\n    :param project_id: The project ID.\n    :param mri_sequence: MRI sequence ('t1_mni_1mm', 't2', 'dwi', or similar).\n                         This is of a descriptive nature for projects with multiple MRI sequences,\n                         hence multiple offsprings of `BaseDataSet`.\n    :param register_to_mni: Register MRIs to the MNI space (1 mm, 2 mm)\n                            using [`ANTs`](https://antspyx.readthedocs.io/en/latest/),\n                            OR not [`None`].\n    :param cache_dir: Path to the cache directory, where intermediate and processed data is stored.\n    :param load_mode: Load mode for the dataset:\n                      'file_paths': Load the MRI data from file paths (recommended for very large datasets).\n                      'full_array': Load the MRI data as a full array (default).\n    :param kwargs: Additional keyword arguments for MRI processing.\n                   Find details to `kwargs` in docs of\n                   `xai4mri.dataloader.mri_dataloader._load_data_as_full_array()`\n                   or `_load_data_as_file_paths()`.\n    \"\"\"\n    self._study_table = None  # init\n    self._study_table_path: str | Path | None = None  # init\n\n    self.study_table = study_table_or_path\n    self.project_id = project_id\n    self.mri_sequence = mri_sequence\n    self.cache_dir = cache_dir\n    self.load_mode = load_mode\n\n    self._sid_list = None  # init\n    self._split_dict: dict[str, np.ndarray] | None = None  # init\n\n    # Following variables should ideally remain untouched after dataset class is instantiated.\n    # They get passed via self.get_data to .mri_dataloader._load_data_as_full_array() (find kwargs details there)\n    self._regis_mni: int | None = register_to_mni\n    self._norm: bool = kwargs.pop(\"norm\", True)\n    self._path_brain_mask: str | None = kwargs.pop(\"path_brain_mask\", None)\n    self._compress: bool = kwargs.pop(\"compress\", True)\n    self._prune_mode: str | None = kwargs.pop(\"prune_mode\", \"max\")  # None: no pruning, OR \"max\" or \"cube\"\n    self._path_to_dataset: str | None = kwargs.pop(\"path_to_dataset\", None)  # if set not in cache dir\n    self._cache_files: bool = kwargs.pop(\"cache_files\", True)\n    self._save_after_processing: bool = kwargs.pop(\"save_after_processing\", self.load_mode != \"file_paths\")\n    # **save_kwargs # as_npy, as_zip in get_mri_set_path() &amp;\n\n    # Run check\n    if not kwargs.pop(\"ignore_checks\", False):\n        self._check_mri_path_constructor()\n\n    # Print unknown kwargs\n    if kwargs:\n        cprint(\n            f\"At init of the DataSet class, unknown kwargs were passed: {kwargs}, which will be ignored!\", col=\"y\"\n        )\n</code></pre>"},{"location":"reference/dataloader/#xai4mri.dataloader.BaseDataSet.current_split_dict","title":"current_split_dict  <code>property</code>","text":"<pre><code>current_split_dict: dict[str, ndarray[str]] | None\n</code></pre> <p>Return the current split dictionary.</p> <p>The split dictionary is created by calling <code>create_data_split()</code>, and has the following structure:</p> <pre><code>{'train': np.ndarray[str], 'validation': np.ndarray[str], 'test': np.ndarray[str]}\n</code></pre> <p>Returns:</p> Type Description <code>dict[str, ndarray[str]] | None</code> <p>split dictionary</p>"},{"location":"reference/dataloader/#xai4mri.dataloader.BaseDataSet.load_mode","title":"load_mode  <code>property</code> <code>writable</code>","text":"<pre><code>load_mode: str\n</code></pre> <p>Return the load mode for the dataset.</p> <p>The load mode can be either 'file_paths' or 'full_array'.</p> <ul> <li>'file_paths': Load the MRI data from file paths.                 That is, individual files are stored separately.</li> <li>'full_array': Load the MRI data as a full array. Data is saved as a single large file.</li> </ul>"},{"location":"reference/dataloader/#xai4mri.dataloader.BaseDataSet.sid_list","title":"sid_list  <code>property</code> <code>writable</code>","text":"<pre><code>sid_list: ndarray[str]\n</code></pre> <p>Return the list of subject IDs.</p> <p>Returns:</p> Type Description <code>np.ndarray[str]</code> <p>list of subject IDs</p>"},{"location":"reference/dataloader/#xai4mri.dataloader.BaseDataSet.study_table","title":"study_table  <code>property</code> <code>writable</code>","text":"<pre><code>study_table: DataFrame\n</code></pre> <p>Get the study table.</p> <p>Ideally, each BaseDataSet has its own study table, except if for all participants of a research project all MRI sequences are available. In this case, the study table can be the same for all MRI sequences and derivatives.</p> <p>Returns:</p> Type Description <code>pd.DataFrame</code> <p>study table</p>"},{"location":"reference/dataloader/#xai4mri.dataloader.BaseDataSet.study_table_path","title":"study_table_path  <code>property</code> <code>writable</code>","text":"<pre><code>study_table_path: str | None\n</code></pre> <p>Return the path to the study table if it has been provided.</p> <p>Can be provided as <code>study_table_or_path</code> at initialization, or it can be set later.</p> <p>Returns:</p> Type Description <code>str | None</code> <p>path to the study table</p>"},{"location":"reference/dataloader/#xai4mri.dataloader.BaseDataSet.create_data_split","title":"create_data_split","text":"<pre><code>create_data_split(\n    target: str,\n    batch_size: int = 1,\n    split_ratio: tuple[float, float, float] | None = (\n        0.8,\n        0.1,\n        0.1,\n    ),\n    split_dict: dict[str, str] | None = None,\n    **get_data_kwargs\n) -&gt; tuple[\n    dict[str, ndarray],\n    _DataSetGenerator,\n    _DataSetGenerator,\n    _DataSetGenerator,\n]\n</code></pre> <p>Create data split with a training, validation, and test set.</p> <p>The data subsets are provided as generator objects, and can be used for model training and evaluation.</p> <p>Usage</p> <pre><code># Create a data split for model training and evaluation\nsplit_dict, train_gen, val_gen, test_gen = mydata.create_data_split(target=\"age\")\n\n# Train a model\nmodel.fit(train_gen, validation_data=val_gen, ...)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>target</code> <code>str</code> <p>Prediction target. <code>target</code> must match a column in the study table.</p> required <code>batch_size</code> <code>int</code> <p>Batch size in the returned data generators per data split. MRIs are arther large files; hence, it is recommended to keep batches rather small.</p> <code>1</code> <code>split_ratio</code> <code>tuple[float, float, float] | None</code> <p>Ratio of the data split (train, validation, test). Must add up to 1.</p> <code>(0.8, 0.1, 0.1)</code> <code>split_dict</code> <code>dict[str, str] | None</code> <p>Dictionary with 'train', 'validation', &amp; 'test' as keys, and subject IDs as values. If a <code>split_dict</code> is provided, it overrules <code>split_ratio</code>. Providing <code>split_dict</code> is useful when specific subject data shall be used in a split.</p> <code>None</code> <p>Returns:</p> Type Description <code>tuple[dict[str, ndarray], _DataSetGenerator, _DataSetGenerator, _DataSetGenerator]</code> <p>split_dict, and the data generators for the training, validation, and test set</p> Source code in <code>src/xai4mri/dataloader/datasets.py</code> <pre><code>def create_data_split(\n    self,\n    target: str,\n    batch_size: int = 1,\n    split_ratio: tuple[float, float, float] | None = (0.8, 0.1, 0.1),\n    split_dict: dict[str, str] | None = None,\n    **get_data_kwargs,\n) -&gt; tuple[dict[str, np.ndarray], _DataSetGenerator, _DataSetGenerator, _DataSetGenerator]:\n    \"\"\"\n    Create data split with a training, validation, and test set.\n\n    The data subsets are provided as generator objects, and can be used for model training and evaluation.\n\n    !!! example \"Usage\"\n        ```python\n        # Create a data split for model training and evaluation\n        split_dict, train_gen, val_gen, test_gen = mydata.create_data_split(target=\"age\")\n\n        # Train a model\n        model.fit(train_gen, validation_data=val_gen, ...)\n        ```\n\n    :param target: Prediction target.\n                   `target` must match a column in the study table.\n    :param batch_size: Batch size in the returned data generators per data split.\n                       MRIs are arther large files; hence, it is recommended to keep batches rather small.\n    :param split_ratio: Ratio of the data split (train, validation, test).\n                        Must add up to 1.\n    :param split_dict: Dictionary with 'train', 'validation', &amp; 'test' as keys, and subject IDs as values.\n                       If a `split_dict` is provided, it overrules `split_ratio`.\n                       Providing `split_dict` is useful when specific subject data shall be used in a split.\n    :return: split_dict, and the data generators for the training, validation, and test set\n    \"\"\"\n    # Load subject data\n    volume_data, sid_list = self.get_data(mmap_mode=\"r\", **get_data_kwargs)  # 'r' does not load data to RAM\n    sid_list = np.array(sid_list)\n\n    if split_dict is None:\n        if not (split_ratio is not None and round(sum(split_ratio), 3) == 1):\n            msg = \"Either split_dict or split_ratio must be provided. split_ratio must sum to 1.\"\n            raise ValueError(msg)\n\n        # Create split indices\n        indices = list(range(len(sid_list)))\n        random.shuffle(indices)\n        n_train = round(len(sid_list) * split_ratio[0])\n        train_indices = indices[:n_train]\n        n_val = round(len(sid_list) * split_ratio[1])\n        val_indices = indices[n_train : n_train + n_val]\n        n_test = len(sid_list) - n_train - n_val\n        test_indices = indices[-n_test:]\n\n        split_dict = {\n            \"train\": sid_list[train_indices],\n            \"validation\": sid_list[val_indices],\n            \"test\": sid_list[test_indices],\n        }\n\n    else:\n        all_sids = [item for sublist in split_dict.values() for item in sublist]\n        if not set(all_sids).issubset(set(sid_list)):\n            msg = \"All SID's in split_dict must be part of the dataset!\"\n            raise ValueError(msg)\n        if len(set(all_sids)) != len(all_sids):\n            msg = \"SID's must only appear once in the split!\"\n            raise ValueError(msg)\n        if split_dict.keys() != {\"train\", \"validation\", \"test\"}:\n            msg = \"split_dict must have keys 'train', 'validation', 'test'!\"\n            raise ValueError(msg)\n\n        # Create split indices\n        train_indices = [list(sid_list).index(sid) for sid in split_dict[\"train\"]]\n        val_indices = [list(sid_list).index(sid) for sid in split_dict[\"validation\"]]\n        test_indices = [list(sid_list).index(sid) for sid in split_dict[\"test\"]]\n\n    # Prepare target (y) data\n    if target not in self.study_table.columns:\n        msg = \"target variable must be in study table!\"\n        raise ValueError(msg)\n    ydata = self.study_table[target]\n\n    # Save split dict\n    self._split_dict = split_dict\n\n    # Define preprocessor\n    if self.load_mode == \"full_array\":\n        # Data is preprocessed already in the full array mode\n        preprocessor = None\n    else:\n        # Set arguments for compress_and_norm() function\n        metadata_table = self.get_metadata_table()\n\n        clip_min, clip_max, global_norm_min, global_norm_max, self._norm = _extract_values_from_metadata(\n            table=metadata_table,\n            compress=self._compress,\n            norm=self._norm,\n        )\n\n        # Set preprocessor\n        preprocessor = partial(\n            compress_and_norm,\n            clip_min=clip_min,\n            clip_max=clip_max,\n            norm=self._norm,\n            global_norm_min=global_norm_min,\n            global_norm_max=global_norm_max,\n        )\n\n    return (\n        split_dict,\n        _DataSetGeneratorFactory.create_generator(\n            name=\"train\",  # training set\n            x_data=volume_data[train_indices],\n            y_data=ydata.loc[sid_list[train_indices]].to_numpy(),\n            batch_size=batch_size,\n            data_indices=train_indices,\n            preprocess=preprocessor,\n        ),\n        _DataSetGeneratorFactory.create_generator(\n            name=\"validation\",  # validation set\n            x_data=volume_data[val_indices],\n            y_data=ydata.loc[sid_list[val_indices]].to_numpy(),\n            batch_size=batch_size,\n            data_indices=val_indices,\n            preprocess=preprocessor,\n        ),\n        _DataSetGeneratorFactory.create_generator(\n            name=\"test\",  # test set\n            x_data=volume_data[test_indices],\n            y_data=ydata.loc[sid_list[test_indices]].to_numpy(),\n            batch_size=1,\n            data_indices=test_indices,\n            preprocess=preprocessor,\n        ),\n    )\n</code></pre>"},{"location":"reference/dataloader/#xai4mri.dataloader.BaseDataSet.get_data","title":"get_data","text":"<pre><code>get_data(**kwargs) -&gt; tuple[ndarray, ndarray[str]]\n</code></pre> <p>Load dataset into workspace.</p> <p>Parameters:</p> Name Type Description Default <code>kwargs</code> <p>Additional keyword arguments for MRI processing. Find details to <code>kwargs</code> in docs of <code>xai4mri.dataloader.mri_dataloader._load_data_as_full_array()</code> or <code>_load_data_as_file_paths()</code>. Note, these <code>kwargs</code> should only be used if the deviation from the <code>__init__</code>-<code>kwargs</code> is intended.</p> <code>{}</code> <p>Returns:</p> Type Description <code>tuple[ndarray, ndarray[str]]</code> <p>Processed MRI data: either 5D data array of shape <code>[n_subjects, x,y,z, channel=1]</code> for <code>self.load_mode='full_array'</code>, or 1D array (paths to processed MRIs) for <code>self.load_mode='file_paths'</code>, and ordered list of corresponding subject ID's</p> Source code in <code>src/xai4mri/dataloader/datasets.py</code> <pre><code>def get_data(self, **kwargs) -&gt; tuple[np.ndarray, np.ndarray[str]]:\n    \"\"\"\n    Load dataset into workspace.\n\n    :param kwargs: Additional keyword arguments for MRI processing.\n                   Find details to `kwargs` in docs of\n                   `xai4mri.dataloader.mri_dataloader._load_data_as_full_array()`\n                    or `_load_data_as_file_paths()`.\n                    Note, these `kwargs` should only be used\n                    if the deviation from the `__init__`-`kwargs` is intended.\n    :return: Processed MRI data: either 5D data array of shape `[n_subjects, x,y,z, channel=1]`\n                       for `self.load_mode='full_array'`,\n                       or 1D array (paths to processed MRIs) for `self.load_mode='file_paths'`,\n             and ordered list of corresponding subject ID's\n    \"\"\"\n    # Unpack kwargs and update class attributes accordingly\n    self._norm = kwargs.pop(\"norm\", self._norm)\n    self._path_brain_mask = kwargs.pop(\"path_brain_mask\", self._path_brain_mask)\n    self._compress = kwargs.pop(\"compress\", self._compress)\n    self._regis_mni = kwargs.pop(\"regis_mni\", self._regis_mni)\n    self._prune_mode = kwargs.pop(\"prune_mode\", self._prune_mode)\n    self._path_to_dataset = kwargs.pop(\"path_to_dataset\", self._path_to_dataset)\n    self._cache_files = kwargs.pop(\"cache_files\", self._cache_files)\n    self._save_after_processing = kwargs.pop(\"save_after_processing\", self._save_after_processing)\n\n    # Load data\n    load_volume_data = _load_data_as_file_paths if self.load_mode == \"file_paths\" else _load_data_as_full_array\n\n    volume_data, sid_list = load_volume_data(\n        sid_list=self.sid_list,\n        project_id=self.project_id,\n        mri_path_constructor=self.mri_path_constructor,\n        mri_seq=self.mri_sequence,\n        cache_dir=self.cache_dir,\n        norm=self._norm,\n        path_brain_mask=self._path_brain_mask,\n        compress=self._compress,\n        regis_mni=self._regis_mni,\n        prune_mode=self._prune_mode,\n        path_to_dataset=self._path_to_dataset,\n        cache_files=self._cache_files,\n        save_after_processing=self._save_after_processing,\n        **kwargs,  # == **save_kwargs remain, see _load_data_as_full_array() for details\n    )\n\n    if self.load_mode == \"file_paths\" and self._save_after_processing:\n        # Reset to default for load_mode == \"file_paths\"\n        self._save_after_processing = False\n\n    sids_without_data = set(self.sid_list) - set(sid_list)\n    if sids_without_data:\n        msg = (\n            f\"No MRI data found for following subjects (ID's): {sids_without_data}.\\n\"\n            f\"Please locate data or remove SIDs from study table to proceed!\"\n        )\n        raise ValueError(msg)\n\n    return volume_data, sid_list\n</code></pre>"},{"location":"reference/dataloader/#xai4mri.dataloader.BaseDataSet.get_metadata_table","title":"get_metadata_table","text":"<pre><code>get_metadata_table()\n</code></pre> <p>Get the metadata table for the MRIs of the project dataset.</p> Source code in <code>src/xai4mri/dataloader/datasets.py</code> <pre><code>def get_metadata_table(self):\n    \"\"\"Get the metadata table for the MRIs of the project dataset.\"\"\"\n    path_to_metadata = get_metadata_path(\n        project_id=self.project_id,\n        mri_seq=self.mri_sequence,\n        regis_mni=self._regis_mni,\n        path_brain_mask=self._path_brain_mask,\n        norm=self._norm,\n        prune_mode=self._prune_mode,\n        path_to_dataset=self._path_to_dataset\n        if isinstance(self._path_to_dataset, (str, Path))\n        else self.cache_dir,\n    )\n\n    if Path(path_to_metadata).is_file():\n        return pd.read_csv(path_to_metadata, index_col=\"sid\", dtype={\"sid\": str})\n    msg = f\"Metadata table not found at '{path_to_metadata}'.\\nRun data processing to create metadata table.\"\n    raise FileNotFoundError(msg)\n</code></pre>"},{"location":"reference/dataloader/#xai4mri.dataloader.BaseDataSet.get_size_of_prospective_mri_set","title":"get_size_of_prospective_mri_set","text":"<pre><code>get_size_of_prospective_mri_set(\n    estimate_with_n: int = 3,\n    estimate_processing_time: bool = True,\n    **process_mri_kwargs\n) -&gt; None\n</code></pre> <p>Estimate the prospective storage sized, which is necessary to save the pre-processed project data.</p> <p>Additionally, estimate the time needed to process the entire dataset.</p> <p>Parameters:</p> Name Type Description Default <code>estimate_with_n</code> <code>int</code> <p>use n samples to approximate the size of the whole processed dataset. If approx_with &gt;= N, the entire dataset will be taken.</p> <code>3</code> <code>estimate_processing_time</code> <code>bool</code> <p>estimate the time needed to process the entire dataset.</p> <code>True</code> <code>process_mri_kwargs</code> <p><code>kwargs</code> for <code>process_single_mri()</code>, e.g., <code>prune_mode</code>. These should overlap with or be equal to the <code>kwargs</code> for <code>self.get_data()</code>. Note, these <code>kwargs</code> should only be used if the deviation from the <code>__init__</code>-<code>kwargs</code> is intended.</p> <code>{}</code> Source code in <code>src/xai4mri/dataloader/datasets.py</code> <pre><code>def get_size_of_prospective_mri_set(\n    self,\n    estimate_with_n: int = 3,\n    estimate_processing_time: bool = True,\n    **process_mri_kwargs,\n) -&gt; None:\n    \"\"\"\n    Estimate the prospective storage sized, which is necessary to save the pre-processed project data.\n\n    Additionally, estimate the time needed to process the entire dataset.\n\n    :param estimate_with_n: use n samples to approximate the size of the whole processed dataset.\n                            If approx_with &gt;= N, the entire dataset will be taken.\n    :param estimate_processing_time: estimate the time needed to process the entire dataset.\n    :param process_mri_kwargs: `kwargs` for `process_single_mri()`, e.g., `prune_mode`.\n                               These should overlap with or be equal to the `kwargs` for `self.get_data()`.\n                               Note, these `kwargs` should only be used\n                               if the deviation from the `__init__`-`kwargs` is intended.\n    \"\"\"\n    max_n = 10\n    if estimate_with_n &gt; max_n:\n        cprint(\n            string=f\"estimate_with_n is set down to {max_n}. \"\n            f\"Too many samples make the calculation unnecessarily slow.\",\n            col=\"y\",\n        )\n    estimate_with_n = np.clip(estimate_with_n, a_min=1, a_max=max_n)\n\n    # Prep temporary sid_list\n    full_sid_list = self.study_table.index.to_list()\n    np.random.shuffle(full_sid_list)  # noqa: NPY002\n\n    def print_estimated_size(size_in_bytes: int, cached_single_files: bool) -&gt; None:\n        \"\"\"Print the estimated size of the pre-processed data.\"\"\"\n        cprint(\n            string=f\"\\nEstimated size of all pre-processed {self.project_id.upper()} \"\n            f\"data{' (mri-set + cached single files)' if cached_single_files else ''}: \"\n            f\"{bytes_to_rep_string(size_in_bytes)}\",\n            col=\"b\",\n        )\n\n    # Extract kwargs\n    cache_files = process_mri_kwargs.pop(\"cache_files\", self._cache_files)  # bool\n    if not (cache_files or estimate_processing_time or process_mri_kwargs.get(\"register_to_mni\", self._regis_mni)):\n        # This is the fastest way to estimate the size of the processed data.\n        # However, it only works if single files are not cached and no processing time is to be estimated\n        from .prune_image import PruneConfig\n\n        # Get shape\n        temp_mri = get_nifti(self.mri_path_constructor(sid=full_sid_list[0]), reorient=True)\n        resolution = np.round(temp_mri.header[\"pixdim\"][1:4], decimals=3)  # image resolution per axis\n        if process_mri_kwargs.get(\"prune_mode\", self._prune_mode) is None:\n            mri_shape = temp_mri.shape\n        else:\n            # If self._prune_mode == \"max\" or \"cube\"\n            mri_shape = np.round(PruneConfig.largest_brain_max_axes // resolution).astype(int)  # \"max\"\n            if process_mri_kwargs.get(\"prune_mode\", self._prune_mode) == \"cube\":\n                mri_shape = (int(mri_shape.max()),) * 3\n\n        # Get dtype\n        dtype = (\n            np.uint8\n            if process_mri_kwargs.get(\"compress\", self._compress) and process_mri_kwargs.get(\"norm\", self._norm)\n            else temp_mri.get_fdata().dtype\n        )\n        # Compute size\n        total_bytes = compute_array_size(shape=(len(full_sid_list), *mri_shape), dtype=dtype, verbose=False)\n        print_estimated_size(size_in_bytes=total_bytes, cached_single_files=cache_files)\n\n    else:\n        # Prepare the path to the temporary cache directory\n        cache_dir_parent = Path(process_mri_kwargs.pop(\"cache_dir\", self.cache_dir))\n        cache_dir_existed = cache_dir_parent.exists()  # init\n        if not cache_dir_existed:\n            cache_dir_parent.mkdir(parents=True, exist_ok=True)\n        with TemporaryDirectory(dir=cache_dir_parent) as temp_cache_dir:\n            try:\n                start_time = perf_counter()\n                # Prepare and load temp data\n                load_volume_data = (\n                    _load_data_as_file_paths if self.load_mode == \"file_paths\" else _load_data_as_full_array\n                )\n                _, _ = load_volume_data(  # _, _ == volume_data, sid_list\n                    sid_list=full_sid_list[:estimate_with_n],\n                    project_id=self.project_id,\n                    mri_path_constructor=self.mri_path_constructor,\n                    mri_seq=self.mri_sequence,\n                    cache_dir=temp_cache_dir,\n                    norm=process_mri_kwargs.pop(\"norm\", self._norm),\n                    path_brain_mask=process_mri_kwargs.pop(\"path_brain_mask\", self._path_brain_mask),\n                    compress=process_mri_kwargs.pop(\"compress\", self._compress),\n                    regis_mni=process_mri_kwargs.pop(\"regis_mni\", self._regis_mni),\n                    prune_mode=process_mri_kwargs.pop(\"prune_mode\", self._prune_mode),\n                    path_to_dataset=None,  # must be temp cache dir\n                    cache_files=cache_files,\n                    save_after_processing=process_mri_kwargs.pop(\n                        \"save_after_processing\", self._save_after_processing\n                    ),\n                    force=True,  # force processing (ignores ask_true_false in _load_data_as_full_array())\n                    **process_mri_kwargs,  # &lt;- dtype, verbose, path_cached_mni\n                )\n\n                # Take average time (in seconds) per sample and multiply with total population size\n                total_time = perf_counter() - start_time  # in seconds\n                time_per_sample = total_time / estimate_with_n\n                total_time = time_per_sample * len(full_sid_list)  # time for all\n                total_time = timedelta(seconds=total_time)  # convert seconds into timedelta object\n\n                # Take the average size per sample and multiply with the total population size\n                total_bytes = sum(f.stat().st_size for f in Path(temp_cache_dir).glob(\"**/*\") if f.is_file())\n                total_bytes *= len(full_sid_list) / estimate_with_n\n\n                data_suffix = \"\"\n                if self.load_mode == \"full_array\" and cache_files:\n                    data_suffix = \"(mri-set + cached single files)\"\n                elif self.load_mode == \"file_paths\" and cache_files:\n                    data_suffix = \" (cached single files)\"\n                cprint(\n                    string=f\"\\nEstimated size of all pre-processed {self.project_id.upper()} \"\n                    f\"data{data_suffix}: {bytes_to_rep_string(total_bytes)}\",\n                    col=\"b\",\n                )\n                cprint(\n                    string=f\"Estimated time to process all data: {chop_microseconds(total_time)} [hh:mm:ss]\\n\",\n                    col=\"b\",\n                )\n            except Exception as e:  # noqa: BLE001\n                # Catch any Exception here, such that temp data will be deleted afterward.\n                cprint(str(e), col=\"r\")\n\n            if not cache_dir_existed:\n                sleep(0.5)\n                shutil.rmtree(cache_dir_parent)\n</code></pre>"},{"location":"reference/dataloader/#xai4mri.dataloader.BaseDataSet.get_unpruned_mri","title":"get_unpruned_mri","text":"<pre><code>get_unpruned_mri(sid: str) -&gt; Nifti1Image\n</code></pre> <p>Get the processed MRI data for a given subject ID, in the state before the image is pruned.</p> <p>Parameters:</p> Name Type Description Default <code>sid</code> <code>str</code> <p>subject ID</p> required <p>Returns:</p> Type Description <code>Nifti1Image</code> <p>Non-pruned MRI data as a NIfTI image</p> Source code in <code>src/xai4mri/dataloader/datasets.py</code> <pre><code>def get_unpruned_mri(self, sid: str) -&gt; nib.Nifti1Image:\n    \"\"\"\n    Get the processed MRI data for a given subject ID, in the state before the image is pruned.\n\n    :param sid: subject ID\n    :return: Non-pruned MRI data as a NIfTI image\n    \"\"\"\n    if isinstance(self._regis_mni, int) and not self._cache_files:\n        msg = \"MNI NIfTI files were not cached during processing!\"\n        raise ValueError(msg)\n\n    return _get_unpruned_mri(\n        sid=sid,\n        project_id=self.project_id,\n        mri_path_constructor=self.mri_path_constructor,\n        regis_mni=self._regis_mni,\n        cache_dir=self.cache_dir,\n    )\n</code></pre>"},{"location":"reference/dataloader/#xai4mri.dataloader.BaseDataSet.load_split_dict","title":"load_split_dict  <code>staticmethod</code>","text":"<pre><code>load_split_dict(\n    split_dict_path: str | Path,\n) -&gt; dict[str, ndarray[str]]\n</code></pre> <p>Load the split dictionary from the given file path.</p> <p>Parameters:</p> Name Type Description Default <code>split_dict_path</code> <code>str | Path</code> <p>path to split dictionary file</p> required <p>Returns:</p> Type Description <code>dict[str, ndarray[str]]</code> <p>split dictionary</p> Source code in <code>src/xai4mri/dataloader/datasets.py</code> <pre><code>@staticmethod\ndef load_split_dict(split_dict_path: str | Path) -&gt; dict[str, np.ndarray[str]]:\n    \"\"\"\n    Load the split dictionary from the given file path.\n\n    :param split_dict_path: path to split dictionary file\n    :return: split dictionary\n    \"\"\"\n    # Add .npy-extension if it is not provided\n    split_dict_path = Path(split_dict_path).with_suffix(\".npy\")\n    split_dict = np.load(split_dict_path, allow_pickle=True).item()\n    if not isinstance(split_dict, dict):\n        msg = f\"split_dict should be a dict, but is of type {type(split_dict)}\"\n        raise TypeError(msg)\n    return split_dict\n</code></pre>"},{"location":"reference/dataloader/#xai4mri.dataloader.BaseDataSet.mri_path_constructor","title":"mri_path_constructor  <code>abstractmethod</code> <code>staticmethod</code>","text":"<pre><code>mri_path_constructor(sid: str) -&gt; str | Path\n</code></pre> <p>Construct the path to the original MRI file of a subject given its ID (sid).</p> <p>Define this function in the dataset class which inherits from BaseDataSet.</p> <p>Parameters:</p> Name Type Description Default <code>sid</code> <code>str</code> <p>subject ID</p> required <p>Returns:</p> Type Description <code>str | Path</code> <p>path to the original MRI file of the subject</p> Source code in <code>src/xai4mri/dataloader/datasets.py</code> <pre><code>@staticmethod\n@abstractmethod\ndef mri_path_constructor(sid: str) -&gt; str | Path:\n    \"\"\"\n    Construct the path to the original MRI file of a subject given its ID (sid).\n\n    Define this function in the dataset class which inherits from BaseDataSet.\n\n    :param sid: subject ID\n    :return: path to the original MRI file of the subject\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/dataloader/#xai4mri.dataloader.BaseDataSet.save_split_dict","title":"save_split_dict","text":"<pre><code>save_split_dict(\n    split_dict: dict[str, ndarray[str]] | None = None,\n    save_path: str | Path | None = None,\n) -&gt; str\n</code></pre> <p>Save a split dictionary to a file.</p> <p>If no split dictionary is given, the <code>self.current_split_dict</code> is saved. <code>self.current_split_dict</code> is set after calling <code>self.create_data_split()</code>.</p> <p>Parameters:</p> Name Type Description Default <code>split_dict</code> <code>dict[str, ndarray[str]] | None</code> <p>data split dictionary: {'train': ['sub-42', ...], 'validation': [...], 'test': [...]}</p> <code>None</code> <code>save_path</code> <code>str | Path | None</code> <p>path to file</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>the path to the file</p> Source code in <code>src/xai4mri/dataloader/datasets.py</code> <pre><code>def save_split_dict(\n    self, split_dict: dict[str, np.ndarray[str]] | None = None, save_path: str | Path | None = None\n) -&gt; str:\n    \"\"\"\n    Save a split dictionary to a file.\n\n    If no split dictionary is given, the `self.current_split_dict` is saved.\n    `self.current_split_dict` is set after calling `self.create_data_split()`.\n\n    :param split_dict: data split dictionary: {'train': ['sub-42', ...], 'validation': [...], 'test': [...]}\n    :param save_path: path to file\n    :return: the path to the file\n    \"\"\"\n    # Use the default path if no path is given\n    if save_path is None:\n        save_path = Path(\n            self.cache_dir,\n            \"data_splits\",\n            f\"{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}_{self.project_id}_{self.mri_sequence}_\"\n            f\"split_dict.npy\",\n        )\n    else:\n        save_path = Path(save_path)\n\n    # Use current data split dict if no split dict is given\n    split_dict = self._split_dict if split_dict is None else split_dict\n\n    if split_dict is None:\n        raise ValueError(\"No split dictionary provided!\")\n\n    # Create directory if it does not exist\n    save_path.parent.mkdir(exist_ok=True, parents=True)\n\n    # Save split dictionary\n    np.save(save_path, split_dict, allow_pickle=True)\n    print(f\"Saved split dictionary to {save_path}.\")\n\n    return str(save_path)\n</code></pre>"},{"location":"reference/dataloader/#xai4mri.dataloader.reverse_pruning","title":"reverse_pruning","text":"<pre><code>reverse_pruning(\n    original_mri: ndarray | Nifti1Image,\n    pruned_mri: ndarray,\n    pruned_stats_map: ndarray | None = None,\n) -&gt; ndarray | Nifti1Image\n</code></pre> <p>Reverse the pruning of an MRI or its corresponding statistical map.</p> <p>If a statistical map is given, both the original MRI and the pruned MRI are necessary to find the edges of the cut-off during pruning. If no statistical map is given, only the original MRI and the pruned MRI are required. Note, in this case <code>reverse_pruning()</code> is applied to a processed and pruned version of the original MRI.</p> <p>Make sure that the original MRI and the pruned MRI have the same orientation.</p> <p>Parameters:</p> Name Type Description Default <code>original_mri</code> <code>ndarray | Nifti1Image</code> <p>Original (i.e., non-pruned) MRI.</p> required <code>pruned_mri</code> <code>ndarray</code> <p>Pruned MRI.</p> required <code>pruned_stats_map</code> <code>ndarray | None</code> <p>[Optional] pruned statistical map.</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray | Nifti1Image</code> <p>MRI with original size (if original_mri is given as Nifti1Image, returns Nifti1Image).</p> Source code in <code>src/xai4mri/dataloader/prune_image.py</code> <pre><code>def reverse_pruning(\n    original_mri: np.ndarray | nib.Nifti1Image,\n    pruned_mri: np.ndarray,\n    pruned_stats_map: np.ndarray | None = None,\n) -&gt; np.ndarray | nib.Nifti1Image:\n    \"\"\"\n    Reverse the pruning of an MRI or its corresponding statistical map.\n\n    If a statistical map is given, both the original MRI and the pruned MRI are necessary to find the edges of\n    the cut-off during pruning.\n    If no statistical map is given, only the original MRI and the pruned MRI are required.\n    Note, in this case `reverse_pruning()` is applied to a processed and pruned version of the original MRI.\n\n    Make sure that the original MRI and the pruned MRI have the same orientation.\n\n    :param original_mri: Original (i.e., non-pruned) MRI.\n    :param pruned_mri: Pruned MRI.\n    :param pruned_stats_map: [Optional] pruned statistical map.\n    :return: MRI with original size (if original_mri is given as Nifti1Image, returns Nifti1Image).\n    \"\"\"\n    # Check whether original_mri is Nifti1Image\n    is_nifti = isinstance(original_mri, nib.Nifti1Image)\n\n    # Define which volume to use for reverse pruning\n    volume_to_reverse_pruning = pruned_mri if pruned_stats_map is None else pruned_stats_map\n\n    # Initialize the MRI to fill\n    volume_to_fill = np.zeros(shape=original_mri.shape)\n    volume_to_fill[...] = BG_VALUE  # set background\n\n    # Find the edges of the brain (slice format)\n    original_mri_edge_slices = find_brain_edges(x3d=original_mri.get_fdata() if is_nifti else original_mri, sl=True)\n    pruned_mri_edge_slices = find_brain_edges(x3d=pruned_mri, sl=True)\n\n    # Use the edges to place the brain data at the right spot\n    volume_to_fill[original_mri_edge_slices] = volume_to_reverse_pruning[pruned_mri_edge_slices]\n\n    if is_nifti:\n        return nib.Nifti1Image(\n            dataobj=volume_to_fill,\n            affine=original_mri.affine,\n            header=original_mri.header if pruned_stats_map is None else None,\n            extra=original_mri.extra if pruned_stats_map is None else None,\n            dtype=original_mri.get_data_dtype() if pruned_stats_map is None else None,\n        )\n\n    return volume_to_fill\n</code></pre>"},{"location":"reference/dataloader/datasets/","title":"<code class=\"doc-symbol doc-symbol-nav doc-symbol-module\"></code> datasets","text":""},{"location":"reference/dataloader/datasets/#xai4mri.dataloader.datasets","title":"datasets","text":"<p>Use <code>BaseDataSet</code> for creating a project-specific dataset class.</p> <pre><code>Authors: Simon M. Hofmann | Hannah S. Heinrichs\nYears: 2021-2023\n</code></pre>"},{"location":"reference/dataloader/datasets/#xai4mri.dataloader.datasets.BaseDataSet","title":"BaseDataSet","text":"<pre><code>BaseDataSet(\n    study_table_or_path: DataFrame | str | Path,\n    project_id: str,\n    mri_sequence: str,\n    register_to_mni: int | None = None,\n    cache_dir: str | Path = CACHE_DIR,\n    load_mode: str = \"full_array\",\n    **kwargs\n)\n</code></pre> <p>               Bases: <code>ABC</code></p> <p>Base class for an MRI dataset.</p> <p>In the case of a research project with multiple MRI sequences, each sequence must have its own dataset class that inherits from the BaseDataSet class.</p> <p>Initialize BaseDataSet.</p> <p>Usage</p> <pre><code># Create a study-specific dataset class\nclass MyStudyData(BaseDataSet):\n    def __init__(self):\n        super().__init__(\n            study_table_or_path=\"PATH/TO/STUDY_TABLE.csv\",  # one column must be 'sid' (subject ID)\n            project_id=\"MyProjectID\",\n            mri_sequence=\"t1w\",  # this is of descriptive nature, for projects with multiple MRI sequences\n            load_mode=\"full_array\",  # or 'file_paths' for very large datasets\n        )\n\n    # Define mri_path_constructor\n    def mri_path_constructor(sid: str) -&gt; str | Path:\n        return f\"/path/to/mri/{sid}.nii.gz\"\n\n\n# Instantiate the dataset class\nmy_study_data = MyStudyData()\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>study_table_or_path</code> <code>DataFrame | str | Path</code> <p>The study table, OR the absolute or relative path to the table [<code>*.csv</code> | <code>*.tsv</code>]. The table must have 'sid' as the index column, containing subject IDs.</p> required <code>project_id</code> <code>str</code> <p>The project ID.</p> required <code>mri_sequence</code> <code>str</code> <p>MRI sequence ('t1_mni_1mm', 't2', 'dwi', or similar). This is of a descriptive nature for projects with multiple MRI sequences, hence multiple offsprings of <code>BaseDataSet</code>.</p> required <code>register_to_mni</code> <code>int | None</code> <p>Register MRIs to the MNI space (1 mm, 2 mm) using <code>ANTs</code>, OR not [<code>None</code>].</p> <code>None</code> <code>cache_dir</code> <code>str | Path</code> <p>Path to the cache directory, where intermediate and processed data is stored.</p> <code>CACHE_DIR</code> <code>load_mode</code> <code>str</code> <p>Load mode for the dataset: 'file_paths': Load the MRI data from file paths (recommended for very large datasets). 'full_array': Load the MRI data as a full array (default).</p> <code>'full_array'</code> <code>kwargs</code> <p>Additional keyword arguments for MRI processing. Find details to <code>kwargs</code> in docs of <code>xai4mri.dataloader.mri_dataloader._load_data_as_full_array()</code> or <code>_load_data_as_file_paths()</code>.</p> <code>{}</code> Source code in <code>src/xai4mri/dataloader/datasets.py</code> <pre><code>def __init__(\n    self,\n    study_table_or_path: pd.DataFrame | str | Path,\n    project_id: str,\n    mri_sequence: str,\n    register_to_mni: int | None = None,\n    cache_dir: str | Path = CACHE_DIR,\n    load_mode: str = \"full_array\",\n    **kwargs,\n):\n    \"\"\"\n    Initialize BaseDataSet.\n\n    !!! example \"Usage\"\n        ```python\n        # Create a study-specific dataset class\n        class MyStudyData(BaseDataSet):\n            def __init__(self):\n                super().__init__(\n                    study_table_or_path=\"PATH/TO/STUDY_TABLE.csv\",  # one column must be 'sid' (subject ID)\n                    project_id=\"MyProjectID\",\n                    mri_sequence=\"t1w\",  # this is of descriptive nature, for projects with multiple MRI sequences\n                    load_mode=\"full_array\",  # or 'file_paths' for very large datasets\n                )\n\n            # Define mri_path_constructor\n            def mri_path_constructor(sid: str) -&gt; str | Path:\n                return f\"/path/to/mri/{sid}.nii.gz\"\n\n\n        # Instantiate the dataset class\n        my_study_data = MyStudyData()\n        ```\n\n    :param study_table_or_path: The study table, OR the absolute or relative path to the table [`*.csv` | `*.tsv`].\n                                The table must have 'sid' as the index column, containing subject IDs.\n    :param project_id: The project ID.\n    :param mri_sequence: MRI sequence ('t1_mni_1mm', 't2', 'dwi', or similar).\n                         This is of a descriptive nature for projects with multiple MRI sequences,\n                         hence multiple offsprings of `BaseDataSet`.\n    :param register_to_mni: Register MRIs to the MNI space (1 mm, 2 mm)\n                            using [`ANTs`](https://antspyx.readthedocs.io/en/latest/),\n                            OR not [`None`].\n    :param cache_dir: Path to the cache directory, where intermediate and processed data is stored.\n    :param load_mode: Load mode for the dataset:\n                      'file_paths': Load the MRI data from file paths (recommended for very large datasets).\n                      'full_array': Load the MRI data as a full array (default).\n    :param kwargs: Additional keyword arguments for MRI processing.\n                   Find details to `kwargs` in docs of\n                   `xai4mri.dataloader.mri_dataloader._load_data_as_full_array()`\n                   or `_load_data_as_file_paths()`.\n    \"\"\"\n    self._study_table = None  # init\n    self._study_table_path: str | Path | None = None  # init\n\n    self.study_table = study_table_or_path\n    self.project_id = project_id\n    self.mri_sequence = mri_sequence\n    self.cache_dir = cache_dir\n    self.load_mode = load_mode\n\n    self._sid_list = None  # init\n    self._split_dict: dict[str, np.ndarray] | None = None  # init\n\n    # Following variables should ideally remain untouched after dataset class is instantiated.\n    # They get passed via self.get_data to .mri_dataloader._load_data_as_full_array() (find kwargs details there)\n    self._regis_mni: int | None = register_to_mni\n    self._norm: bool = kwargs.pop(\"norm\", True)\n    self._path_brain_mask: str | None = kwargs.pop(\"path_brain_mask\", None)\n    self._compress: bool = kwargs.pop(\"compress\", True)\n    self._prune_mode: str | None = kwargs.pop(\"prune_mode\", \"max\")  # None: no pruning, OR \"max\" or \"cube\"\n    self._path_to_dataset: str | None = kwargs.pop(\"path_to_dataset\", None)  # if set not in cache dir\n    self._cache_files: bool = kwargs.pop(\"cache_files\", True)\n    self._save_after_processing: bool = kwargs.pop(\"save_after_processing\", self.load_mode != \"file_paths\")\n    # **save_kwargs # as_npy, as_zip in get_mri_set_path() &amp;\n\n    # Run check\n    if not kwargs.pop(\"ignore_checks\", False):\n        self._check_mri_path_constructor()\n\n    # Print unknown kwargs\n    if kwargs:\n        cprint(\n            f\"At init of the DataSet class, unknown kwargs were passed: {kwargs}, which will be ignored!\", col=\"y\"\n        )\n</code></pre>"},{"location":"reference/dataloader/datasets/#xai4mri.dataloader.datasets.BaseDataSet.current_split_dict","title":"current_split_dict  <code>property</code>","text":"<pre><code>current_split_dict: dict[str, ndarray[str]] | None\n</code></pre> <p>Return the current split dictionary.</p> <p>The split dictionary is created by calling <code>create_data_split()</code>, and has the following structure:</p> <pre><code>{'train': np.ndarray[str], 'validation': np.ndarray[str], 'test': np.ndarray[str]}\n</code></pre> <p>Returns:</p> Type Description <code>dict[str, ndarray[str]] | None</code> <p>split dictionary</p>"},{"location":"reference/dataloader/datasets/#xai4mri.dataloader.datasets.BaseDataSet.load_mode","title":"load_mode  <code>property</code> <code>writable</code>","text":"<pre><code>load_mode: str\n</code></pre> <p>Return the load mode for the dataset.</p> <p>The load mode can be either 'file_paths' or 'full_array'.</p> <ul> <li>'file_paths': Load the MRI data from file paths.                 That is, individual files are stored separately.</li> <li>'full_array': Load the MRI data as a full array. Data is saved as a single large file.</li> </ul>"},{"location":"reference/dataloader/datasets/#xai4mri.dataloader.datasets.BaseDataSet.sid_list","title":"sid_list  <code>property</code> <code>writable</code>","text":"<pre><code>sid_list: ndarray[str]\n</code></pre> <p>Return the list of subject IDs.</p> <p>Returns:</p> Type Description <code>np.ndarray[str]</code> <p>list of subject IDs</p>"},{"location":"reference/dataloader/datasets/#xai4mri.dataloader.datasets.BaseDataSet.study_table","title":"study_table  <code>property</code> <code>writable</code>","text":"<pre><code>study_table: DataFrame\n</code></pre> <p>Get the study table.</p> <p>Ideally, each BaseDataSet has its own study table, except if for all participants of a research project all MRI sequences are available. In this case, the study table can be the same for all MRI sequences and derivatives.</p> <p>Returns:</p> Type Description <code>pd.DataFrame</code> <p>study table</p>"},{"location":"reference/dataloader/datasets/#xai4mri.dataloader.datasets.BaseDataSet.study_table_path","title":"study_table_path  <code>property</code> <code>writable</code>","text":"<pre><code>study_table_path: str | None\n</code></pre> <p>Return the path to the study table if it has been provided.</p> <p>Can be provided as <code>study_table_or_path</code> at initialization, or it can be set later.</p> <p>Returns:</p> Type Description <code>str | None</code> <p>path to the study table</p>"},{"location":"reference/dataloader/datasets/#xai4mri.dataloader.datasets.BaseDataSet.create_data_split","title":"create_data_split","text":"<pre><code>create_data_split(\n    target: str,\n    batch_size: int = 1,\n    split_ratio: tuple[float, float, float] | None = (\n        0.8,\n        0.1,\n        0.1,\n    ),\n    split_dict: dict[str, str] | None = None,\n    **get_data_kwargs\n) -&gt; tuple[\n    dict[str, ndarray],\n    _DataSetGenerator,\n    _DataSetGenerator,\n    _DataSetGenerator,\n]\n</code></pre> <p>Create data split with a training, validation, and test set.</p> <p>The data subsets are provided as generator objects, and can be used for model training and evaluation.</p> <p>Usage</p> <pre><code># Create a data split for model training and evaluation\nsplit_dict, train_gen, val_gen, test_gen = mydata.create_data_split(target=\"age\")\n\n# Train a model\nmodel.fit(train_gen, validation_data=val_gen, ...)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>target</code> <code>str</code> <p>Prediction target. <code>target</code> must match a column in the study table.</p> required <code>batch_size</code> <code>int</code> <p>Batch size in the returned data generators per data split. MRIs are arther large files; hence, it is recommended to keep batches rather small.</p> <code>1</code> <code>split_ratio</code> <code>tuple[float, float, float] | None</code> <p>Ratio of the data split (train, validation, test). Must add up to 1.</p> <code>(0.8, 0.1, 0.1)</code> <code>split_dict</code> <code>dict[str, str] | None</code> <p>Dictionary with 'train', 'validation', &amp; 'test' as keys, and subject IDs as values. If a <code>split_dict</code> is provided, it overrules <code>split_ratio</code>. Providing <code>split_dict</code> is useful when specific subject data shall be used in a split.</p> <code>None</code> <p>Returns:</p> Type Description <code>tuple[dict[str, ndarray], _DataSetGenerator, _DataSetGenerator, _DataSetGenerator]</code> <p>split_dict, and the data generators for the training, validation, and test set</p> Source code in <code>src/xai4mri/dataloader/datasets.py</code> <pre><code>def create_data_split(\n    self,\n    target: str,\n    batch_size: int = 1,\n    split_ratio: tuple[float, float, float] | None = (0.8, 0.1, 0.1),\n    split_dict: dict[str, str] | None = None,\n    **get_data_kwargs,\n) -&gt; tuple[dict[str, np.ndarray], _DataSetGenerator, _DataSetGenerator, _DataSetGenerator]:\n    \"\"\"\n    Create data split with a training, validation, and test set.\n\n    The data subsets are provided as generator objects, and can be used for model training and evaluation.\n\n    !!! example \"Usage\"\n        ```python\n        # Create a data split for model training and evaluation\n        split_dict, train_gen, val_gen, test_gen = mydata.create_data_split(target=\"age\")\n\n        # Train a model\n        model.fit(train_gen, validation_data=val_gen, ...)\n        ```\n\n    :param target: Prediction target.\n                   `target` must match a column in the study table.\n    :param batch_size: Batch size in the returned data generators per data split.\n                       MRIs are arther large files; hence, it is recommended to keep batches rather small.\n    :param split_ratio: Ratio of the data split (train, validation, test).\n                        Must add up to 1.\n    :param split_dict: Dictionary with 'train', 'validation', &amp; 'test' as keys, and subject IDs as values.\n                       If a `split_dict` is provided, it overrules `split_ratio`.\n                       Providing `split_dict` is useful when specific subject data shall be used in a split.\n    :return: split_dict, and the data generators for the training, validation, and test set\n    \"\"\"\n    # Load subject data\n    volume_data, sid_list = self.get_data(mmap_mode=\"r\", **get_data_kwargs)  # 'r' does not load data to RAM\n    sid_list = np.array(sid_list)\n\n    if split_dict is None:\n        if not (split_ratio is not None and round(sum(split_ratio), 3) == 1):\n            msg = \"Either split_dict or split_ratio must be provided. split_ratio must sum to 1.\"\n            raise ValueError(msg)\n\n        # Create split indices\n        indices = list(range(len(sid_list)))\n        random.shuffle(indices)\n        n_train = round(len(sid_list) * split_ratio[0])\n        train_indices = indices[:n_train]\n        n_val = round(len(sid_list) * split_ratio[1])\n        val_indices = indices[n_train : n_train + n_val]\n        n_test = len(sid_list) - n_train - n_val\n        test_indices = indices[-n_test:]\n\n        split_dict = {\n            \"train\": sid_list[train_indices],\n            \"validation\": sid_list[val_indices],\n            \"test\": sid_list[test_indices],\n        }\n\n    else:\n        all_sids = [item for sublist in split_dict.values() for item in sublist]\n        if not set(all_sids).issubset(set(sid_list)):\n            msg = \"All SID's in split_dict must be part of the dataset!\"\n            raise ValueError(msg)\n        if len(set(all_sids)) != len(all_sids):\n            msg = \"SID's must only appear once in the split!\"\n            raise ValueError(msg)\n        if split_dict.keys() != {\"train\", \"validation\", \"test\"}:\n            msg = \"split_dict must have keys 'train', 'validation', 'test'!\"\n            raise ValueError(msg)\n\n        # Create split indices\n        train_indices = [list(sid_list).index(sid) for sid in split_dict[\"train\"]]\n        val_indices = [list(sid_list).index(sid) for sid in split_dict[\"validation\"]]\n        test_indices = [list(sid_list).index(sid) for sid in split_dict[\"test\"]]\n\n    # Prepare target (y) data\n    if target not in self.study_table.columns:\n        msg = \"target variable must be in study table!\"\n        raise ValueError(msg)\n    ydata = self.study_table[target]\n\n    # Save split dict\n    self._split_dict = split_dict\n\n    # Define preprocessor\n    if self.load_mode == \"full_array\":\n        # Data is preprocessed already in the full array mode\n        preprocessor = None\n    else:\n        # Set arguments for compress_and_norm() function\n        metadata_table = self.get_metadata_table()\n\n        clip_min, clip_max, global_norm_min, global_norm_max, self._norm = _extract_values_from_metadata(\n            table=metadata_table,\n            compress=self._compress,\n            norm=self._norm,\n        )\n\n        # Set preprocessor\n        preprocessor = partial(\n            compress_and_norm,\n            clip_min=clip_min,\n            clip_max=clip_max,\n            norm=self._norm,\n            global_norm_min=global_norm_min,\n            global_norm_max=global_norm_max,\n        )\n\n    return (\n        split_dict,\n        _DataSetGeneratorFactory.create_generator(\n            name=\"train\",  # training set\n            x_data=volume_data[train_indices],\n            y_data=ydata.loc[sid_list[train_indices]].to_numpy(),\n            batch_size=batch_size,\n            data_indices=train_indices,\n            preprocess=preprocessor,\n        ),\n        _DataSetGeneratorFactory.create_generator(\n            name=\"validation\",  # validation set\n            x_data=volume_data[val_indices],\n            y_data=ydata.loc[sid_list[val_indices]].to_numpy(),\n            batch_size=batch_size,\n            data_indices=val_indices,\n            preprocess=preprocessor,\n        ),\n        _DataSetGeneratorFactory.create_generator(\n            name=\"test\",  # test set\n            x_data=volume_data[test_indices],\n            y_data=ydata.loc[sid_list[test_indices]].to_numpy(),\n            batch_size=1,\n            data_indices=test_indices,\n            preprocess=preprocessor,\n        ),\n    )\n</code></pre>"},{"location":"reference/dataloader/datasets/#xai4mri.dataloader.datasets.BaseDataSet.get_data","title":"get_data","text":"<pre><code>get_data(**kwargs) -&gt; tuple[ndarray, ndarray[str]]\n</code></pre> <p>Load dataset into workspace.</p> <p>Parameters:</p> Name Type Description Default <code>kwargs</code> <p>Additional keyword arguments for MRI processing. Find details to <code>kwargs</code> in docs of <code>xai4mri.dataloader.mri_dataloader._load_data_as_full_array()</code> or <code>_load_data_as_file_paths()</code>. Note, these <code>kwargs</code> should only be used if the deviation from the <code>__init__</code>-<code>kwargs</code> is intended.</p> <code>{}</code> <p>Returns:</p> Type Description <code>tuple[ndarray, ndarray[str]]</code> <p>Processed MRI data: either 5D data array of shape <code>[n_subjects, x,y,z, channel=1]</code> for <code>self.load_mode='full_array'</code>, or 1D array (paths to processed MRIs) for <code>self.load_mode='file_paths'</code>, and ordered list of corresponding subject ID's</p> Source code in <code>src/xai4mri/dataloader/datasets.py</code> <pre><code>def get_data(self, **kwargs) -&gt; tuple[np.ndarray, np.ndarray[str]]:\n    \"\"\"\n    Load dataset into workspace.\n\n    :param kwargs: Additional keyword arguments for MRI processing.\n                   Find details to `kwargs` in docs of\n                   `xai4mri.dataloader.mri_dataloader._load_data_as_full_array()`\n                    or `_load_data_as_file_paths()`.\n                    Note, these `kwargs` should only be used\n                    if the deviation from the `__init__`-`kwargs` is intended.\n    :return: Processed MRI data: either 5D data array of shape `[n_subjects, x,y,z, channel=1]`\n                       for `self.load_mode='full_array'`,\n                       or 1D array (paths to processed MRIs) for `self.load_mode='file_paths'`,\n             and ordered list of corresponding subject ID's\n    \"\"\"\n    # Unpack kwargs and update class attributes accordingly\n    self._norm = kwargs.pop(\"norm\", self._norm)\n    self._path_brain_mask = kwargs.pop(\"path_brain_mask\", self._path_brain_mask)\n    self._compress = kwargs.pop(\"compress\", self._compress)\n    self._regis_mni = kwargs.pop(\"regis_mni\", self._regis_mni)\n    self._prune_mode = kwargs.pop(\"prune_mode\", self._prune_mode)\n    self._path_to_dataset = kwargs.pop(\"path_to_dataset\", self._path_to_dataset)\n    self._cache_files = kwargs.pop(\"cache_files\", self._cache_files)\n    self._save_after_processing = kwargs.pop(\"save_after_processing\", self._save_after_processing)\n\n    # Load data\n    load_volume_data = _load_data_as_file_paths if self.load_mode == \"file_paths\" else _load_data_as_full_array\n\n    volume_data, sid_list = load_volume_data(\n        sid_list=self.sid_list,\n        project_id=self.project_id,\n        mri_path_constructor=self.mri_path_constructor,\n        mri_seq=self.mri_sequence,\n        cache_dir=self.cache_dir,\n        norm=self._norm,\n        path_brain_mask=self._path_brain_mask,\n        compress=self._compress,\n        regis_mni=self._regis_mni,\n        prune_mode=self._prune_mode,\n        path_to_dataset=self._path_to_dataset,\n        cache_files=self._cache_files,\n        save_after_processing=self._save_after_processing,\n        **kwargs,  # == **save_kwargs remain, see _load_data_as_full_array() for details\n    )\n\n    if self.load_mode == \"file_paths\" and self._save_after_processing:\n        # Reset to default for load_mode == \"file_paths\"\n        self._save_after_processing = False\n\n    sids_without_data = set(self.sid_list) - set(sid_list)\n    if sids_without_data:\n        msg = (\n            f\"No MRI data found for following subjects (ID's): {sids_without_data}.\\n\"\n            f\"Please locate data or remove SIDs from study table to proceed!\"\n        )\n        raise ValueError(msg)\n\n    return volume_data, sid_list\n</code></pre>"},{"location":"reference/dataloader/datasets/#xai4mri.dataloader.datasets.BaseDataSet.get_metadata_table","title":"get_metadata_table","text":"<pre><code>get_metadata_table()\n</code></pre> <p>Get the metadata table for the MRIs of the project dataset.</p> Source code in <code>src/xai4mri/dataloader/datasets.py</code> <pre><code>def get_metadata_table(self):\n    \"\"\"Get the metadata table for the MRIs of the project dataset.\"\"\"\n    path_to_metadata = get_metadata_path(\n        project_id=self.project_id,\n        mri_seq=self.mri_sequence,\n        regis_mni=self._regis_mni,\n        path_brain_mask=self._path_brain_mask,\n        norm=self._norm,\n        prune_mode=self._prune_mode,\n        path_to_dataset=self._path_to_dataset\n        if isinstance(self._path_to_dataset, (str, Path))\n        else self.cache_dir,\n    )\n\n    if Path(path_to_metadata).is_file():\n        return pd.read_csv(path_to_metadata, index_col=\"sid\", dtype={\"sid\": str})\n    msg = f\"Metadata table not found at '{path_to_metadata}'.\\nRun data processing to create metadata table.\"\n    raise FileNotFoundError(msg)\n</code></pre>"},{"location":"reference/dataloader/datasets/#xai4mri.dataloader.datasets.BaseDataSet.get_size_of_prospective_mri_set","title":"get_size_of_prospective_mri_set","text":"<pre><code>get_size_of_prospective_mri_set(\n    estimate_with_n: int = 3,\n    estimate_processing_time: bool = True,\n    **process_mri_kwargs\n) -&gt; None\n</code></pre> <p>Estimate the prospective storage sized, which is necessary to save the pre-processed project data.</p> <p>Additionally, estimate the time needed to process the entire dataset.</p> <p>Parameters:</p> Name Type Description Default <code>estimate_with_n</code> <code>int</code> <p>use n samples to approximate the size of the whole processed dataset. If approx_with &gt;= N, the entire dataset will be taken.</p> <code>3</code> <code>estimate_processing_time</code> <code>bool</code> <p>estimate the time needed to process the entire dataset.</p> <code>True</code> <code>process_mri_kwargs</code> <p><code>kwargs</code> for <code>process_single_mri()</code>, e.g., <code>prune_mode</code>. These should overlap with or be equal to the <code>kwargs</code> for <code>self.get_data()</code>. Note, these <code>kwargs</code> should only be used if the deviation from the <code>__init__</code>-<code>kwargs</code> is intended.</p> <code>{}</code> Source code in <code>src/xai4mri/dataloader/datasets.py</code> <pre><code>def get_size_of_prospective_mri_set(\n    self,\n    estimate_with_n: int = 3,\n    estimate_processing_time: bool = True,\n    **process_mri_kwargs,\n) -&gt; None:\n    \"\"\"\n    Estimate the prospective storage sized, which is necessary to save the pre-processed project data.\n\n    Additionally, estimate the time needed to process the entire dataset.\n\n    :param estimate_with_n: use n samples to approximate the size of the whole processed dataset.\n                            If approx_with &gt;= N, the entire dataset will be taken.\n    :param estimate_processing_time: estimate the time needed to process the entire dataset.\n    :param process_mri_kwargs: `kwargs` for `process_single_mri()`, e.g., `prune_mode`.\n                               These should overlap with or be equal to the `kwargs` for `self.get_data()`.\n                               Note, these `kwargs` should only be used\n                               if the deviation from the `__init__`-`kwargs` is intended.\n    \"\"\"\n    max_n = 10\n    if estimate_with_n &gt; max_n:\n        cprint(\n            string=f\"estimate_with_n is set down to {max_n}. \"\n            f\"Too many samples make the calculation unnecessarily slow.\",\n            col=\"y\",\n        )\n    estimate_with_n = np.clip(estimate_with_n, a_min=1, a_max=max_n)\n\n    # Prep temporary sid_list\n    full_sid_list = self.study_table.index.to_list()\n    np.random.shuffle(full_sid_list)  # noqa: NPY002\n\n    def print_estimated_size(size_in_bytes: int, cached_single_files: bool) -&gt; None:\n        \"\"\"Print the estimated size of the pre-processed data.\"\"\"\n        cprint(\n            string=f\"\\nEstimated size of all pre-processed {self.project_id.upper()} \"\n            f\"data{' (mri-set + cached single files)' if cached_single_files else ''}: \"\n            f\"{bytes_to_rep_string(size_in_bytes)}\",\n            col=\"b\",\n        )\n\n    # Extract kwargs\n    cache_files = process_mri_kwargs.pop(\"cache_files\", self._cache_files)  # bool\n    if not (cache_files or estimate_processing_time or process_mri_kwargs.get(\"register_to_mni\", self._regis_mni)):\n        # This is the fastest way to estimate the size of the processed data.\n        # However, it only works if single files are not cached and no processing time is to be estimated\n        from .prune_image import PruneConfig\n\n        # Get shape\n        temp_mri = get_nifti(self.mri_path_constructor(sid=full_sid_list[0]), reorient=True)\n        resolution = np.round(temp_mri.header[\"pixdim\"][1:4], decimals=3)  # image resolution per axis\n        if process_mri_kwargs.get(\"prune_mode\", self._prune_mode) is None:\n            mri_shape = temp_mri.shape\n        else:\n            # If self._prune_mode == \"max\" or \"cube\"\n            mri_shape = np.round(PruneConfig.largest_brain_max_axes // resolution).astype(int)  # \"max\"\n            if process_mri_kwargs.get(\"prune_mode\", self._prune_mode) == \"cube\":\n                mri_shape = (int(mri_shape.max()),) * 3\n\n        # Get dtype\n        dtype = (\n            np.uint8\n            if process_mri_kwargs.get(\"compress\", self._compress) and process_mri_kwargs.get(\"norm\", self._norm)\n            else temp_mri.get_fdata().dtype\n        )\n        # Compute size\n        total_bytes = compute_array_size(shape=(len(full_sid_list), *mri_shape), dtype=dtype, verbose=False)\n        print_estimated_size(size_in_bytes=total_bytes, cached_single_files=cache_files)\n\n    else:\n        # Prepare the path to the temporary cache directory\n        cache_dir_parent = Path(process_mri_kwargs.pop(\"cache_dir\", self.cache_dir))\n        cache_dir_existed = cache_dir_parent.exists()  # init\n        if not cache_dir_existed:\n            cache_dir_parent.mkdir(parents=True, exist_ok=True)\n        with TemporaryDirectory(dir=cache_dir_parent) as temp_cache_dir:\n            try:\n                start_time = perf_counter()\n                # Prepare and load temp data\n                load_volume_data = (\n                    _load_data_as_file_paths if self.load_mode == \"file_paths\" else _load_data_as_full_array\n                )\n                _, _ = load_volume_data(  # _, _ == volume_data, sid_list\n                    sid_list=full_sid_list[:estimate_with_n],\n                    project_id=self.project_id,\n                    mri_path_constructor=self.mri_path_constructor,\n                    mri_seq=self.mri_sequence,\n                    cache_dir=temp_cache_dir,\n                    norm=process_mri_kwargs.pop(\"norm\", self._norm),\n                    path_brain_mask=process_mri_kwargs.pop(\"path_brain_mask\", self._path_brain_mask),\n                    compress=process_mri_kwargs.pop(\"compress\", self._compress),\n                    regis_mni=process_mri_kwargs.pop(\"regis_mni\", self._regis_mni),\n                    prune_mode=process_mri_kwargs.pop(\"prune_mode\", self._prune_mode),\n                    path_to_dataset=None,  # must be temp cache dir\n                    cache_files=cache_files,\n                    save_after_processing=process_mri_kwargs.pop(\n                        \"save_after_processing\", self._save_after_processing\n                    ),\n                    force=True,  # force processing (ignores ask_true_false in _load_data_as_full_array())\n                    **process_mri_kwargs,  # &lt;- dtype, verbose, path_cached_mni\n                )\n\n                # Take average time (in seconds) per sample and multiply with total population size\n                total_time = perf_counter() - start_time  # in seconds\n                time_per_sample = total_time / estimate_with_n\n                total_time = time_per_sample * len(full_sid_list)  # time for all\n                total_time = timedelta(seconds=total_time)  # convert seconds into timedelta object\n\n                # Take the average size per sample and multiply with the total population size\n                total_bytes = sum(f.stat().st_size for f in Path(temp_cache_dir).glob(\"**/*\") if f.is_file())\n                total_bytes *= len(full_sid_list) / estimate_with_n\n\n                data_suffix = \"\"\n                if self.load_mode == \"full_array\" and cache_files:\n                    data_suffix = \"(mri-set + cached single files)\"\n                elif self.load_mode == \"file_paths\" and cache_files:\n                    data_suffix = \" (cached single files)\"\n                cprint(\n                    string=f\"\\nEstimated size of all pre-processed {self.project_id.upper()} \"\n                    f\"data{data_suffix}: {bytes_to_rep_string(total_bytes)}\",\n                    col=\"b\",\n                )\n                cprint(\n                    string=f\"Estimated time to process all data: {chop_microseconds(total_time)} [hh:mm:ss]\\n\",\n                    col=\"b\",\n                )\n            except Exception as e:  # noqa: BLE001\n                # Catch any Exception here, such that temp data will be deleted afterward.\n                cprint(str(e), col=\"r\")\n\n            if not cache_dir_existed:\n                sleep(0.5)\n                shutil.rmtree(cache_dir_parent)\n</code></pre>"},{"location":"reference/dataloader/datasets/#xai4mri.dataloader.datasets.BaseDataSet.get_unpruned_mri","title":"get_unpruned_mri","text":"<pre><code>get_unpruned_mri(sid: str) -&gt; Nifti1Image\n</code></pre> <p>Get the processed MRI data for a given subject ID, in the state before the image is pruned.</p> <p>Parameters:</p> Name Type Description Default <code>sid</code> <code>str</code> <p>subject ID</p> required <p>Returns:</p> Type Description <code>Nifti1Image</code> <p>Non-pruned MRI data as a NIfTI image</p> Source code in <code>src/xai4mri/dataloader/datasets.py</code> <pre><code>def get_unpruned_mri(self, sid: str) -&gt; nib.Nifti1Image:\n    \"\"\"\n    Get the processed MRI data for a given subject ID, in the state before the image is pruned.\n\n    :param sid: subject ID\n    :return: Non-pruned MRI data as a NIfTI image\n    \"\"\"\n    if isinstance(self._regis_mni, int) and not self._cache_files:\n        msg = \"MNI NIfTI files were not cached during processing!\"\n        raise ValueError(msg)\n\n    return _get_unpruned_mri(\n        sid=sid,\n        project_id=self.project_id,\n        mri_path_constructor=self.mri_path_constructor,\n        regis_mni=self._regis_mni,\n        cache_dir=self.cache_dir,\n    )\n</code></pre>"},{"location":"reference/dataloader/datasets/#xai4mri.dataloader.datasets.BaseDataSet.load_split_dict","title":"load_split_dict  <code>staticmethod</code>","text":"<pre><code>load_split_dict(\n    split_dict_path: str | Path,\n) -&gt; dict[str, ndarray[str]]\n</code></pre> <p>Load the split dictionary from the given file path.</p> <p>Parameters:</p> Name Type Description Default <code>split_dict_path</code> <code>str | Path</code> <p>path to split dictionary file</p> required <p>Returns:</p> Type Description <code>dict[str, ndarray[str]]</code> <p>split dictionary</p> Source code in <code>src/xai4mri/dataloader/datasets.py</code> <pre><code>@staticmethod\ndef load_split_dict(split_dict_path: str | Path) -&gt; dict[str, np.ndarray[str]]:\n    \"\"\"\n    Load the split dictionary from the given file path.\n\n    :param split_dict_path: path to split dictionary file\n    :return: split dictionary\n    \"\"\"\n    # Add .npy-extension if it is not provided\n    split_dict_path = Path(split_dict_path).with_suffix(\".npy\")\n    split_dict = np.load(split_dict_path, allow_pickle=True).item()\n    if not isinstance(split_dict, dict):\n        msg = f\"split_dict should be a dict, but is of type {type(split_dict)}\"\n        raise TypeError(msg)\n    return split_dict\n</code></pre>"},{"location":"reference/dataloader/datasets/#xai4mri.dataloader.datasets.BaseDataSet.mri_path_constructor","title":"mri_path_constructor  <code>abstractmethod</code> <code>staticmethod</code>","text":"<pre><code>mri_path_constructor(sid: str) -&gt; str | Path\n</code></pre> <p>Construct the path to the original MRI file of a subject given its ID (sid).</p> <p>Define this function in the dataset class which inherits from BaseDataSet.</p> <p>Parameters:</p> Name Type Description Default <code>sid</code> <code>str</code> <p>subject ID</p> required <p>Returns:</p> Type Description <code>str | Path</code> <p>path to the original MRI file of the subject</p> Source code in <code>src/xai4mri/dataloader/datasets.py</code> <pre><code>@staticmethod\n@abstractmethod\ndef mri_path_constructor(sid: str) -&gt; str | Path:\n    \"\"\"\n    Construct the path to the original MRI file of a subject given its ID (sid).\n\n    Define this function in the dataset class which inherits from BaseDataSet.\n\n    :param sid: subject ID\n    :return: path to the original MRI file of the subject\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/dataloader/datasets/#xai4mri.dataloader.datasets.BaseDataSet.save_split_dict","title":"save_split_dict","text":"<pre><code>save_split_dict(\n    split_dict: dict[str, ndarray[str]] | None = None,\n    save_path: str | Path | None = None,\n) -&gt; str\n</code></pre> <p>Save a split dictionary to a file.</p> <p>If no split dictionary is given, the <code>self.current_split_dict</code> is saved. <code>self.current_split_dict</code> is set after calling <code>self.create_data_split()</code>.</p> <p>Parameters:</p> Name Type Description Default <code>split_dict</code> <code>dict[str, ndarray[str]] | None</code> <p>data split dictionary: {'train': ['sub-42', ...], 'validation': [...], 'test': [...]}</p> <code>None</code> <code>save_path</code> <code>str | Path | None</code> <p>path to file</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>the path to the file</p> Source code in <code>src/xai4mri/dataloader/datasets.py</code> <pre><code>def save_split_dict(\n    self, split_dict: dict[str, np.ndarray[str]] | None = None, save_path: str | Path | None = None\n) -&gt; str:\n    \"\"\"\n    Save a split dictionary to a file.\n\n    If no split dictionary is given, the `self.current_split_dict` is saved.\n    `self.current_split_dict` is set after calling `self.create_data_split()`.\n\n    :param split_dict: data split dictionary: {'train': ['sub-42', ...], 'validation': [...], 'test': [...]}\n    :param save_path: path to file\n    :return: the path to the file\n    \"\"\"\n    # Use the default path if no path is given\n    if save_path is None:\n        save_path = Path(\n            self.cache_dir,\n            \"data_splits\",\n            f\"{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}_{self.project_id}_{self.mri_sequence}_\"\n            f\"split_dict.npy\",\n        )\n    else:\n        save_path = Path(save_path)\n\n    # Use current data split dict if no split dict is given\n    split_dict = self._split_dict if split_dict is None else split_dict\n\n    if split_dict is None:\n        raise ValueError(\"No split dictionary provided!\")\n\n    # Create directory if it does not exist\n    save_path.parent.mkdir(exist_ok=True, parents=True)\n\n    # Save split dictionary\n    np.save(save_path, split_dict, allow_pickle=True)\n    print(f\"Saved split dictionary to {save_path}.\")\n\n    return str(save_path)\n</code></pre>"},{"location":"reference/dataloader/mri_dataloader/","title":"<code class=\"doc-symbol doc-symbol-nav doc-symbol-module\"></code> mri_dataloader","text":""},{"location":"reference/dataloader/mri_dataloader/#xai4mri.dataloader.mri_dataloader","title":"mri_dataloader","text":"<p>Backend functions to load MRI and target data of different datasets.</p> <p>This is more or less the backend of the data loading process in <code>xai4mri.dataloader.datasets</code>.</p> <pre><code>Authors: Simon M. Hofmann | Hannah S. Heinrichs\nYears: 2023-2024\n</code></pre>"},{"location":"reference/dataloader/mri_dataloader/#xai4mri.dataloader.mri_dataloader.get_metadata_path","title":"get_metadata_path","text":"<pre><code>get_metadata_path(\n    project_id: str,\n    mri_seq: str,\n    regis_mni: int | None,\n    path_brain_mask: str | None,\n    norm: bool,\n    prune_mode: str | None,\n    path_to_dataset: str | Path | None,\n) -&gt; Path\n</code></pre> <p>Get the path to the metadata table of a project's dataset.</p> <p>Parameters:</p> Name Type Description Default <code>project_id</code> <code>str</code> <p>project ID</p> required <code>mri_seq</code> <code>str</code> <p>MRI sequence (e.g., 't1w')</p> required <code>regis_mni</code> <code>int | None</code> <p>set when data was transformed to MNI space (1 or 2 mm) or None</p> required <code>path_brain_mask</code> <code>str | None</code> <p>if used, path to the applied brain mask, else None</p> required <code>norm</code> <code>bool</code> <p>if images were normalized</p> required <code>prune_mode</code> <code>str | None</code> <p>if not used: None; else pruning mode: \"cube\" or \"max\".</p> required <code>path_to_dataset</code> <code>str | Path | None</code> <p>Optional path to folder containing project data (if not in globally set <code>cache_dir</code>)</p> required <p>Returns:</p> Type Description <code>Path</code> <p>path to the metadata table of the project dataset</p> Source code in <code>src/xai4mri/dataloader/mri_dataloader.py</code> <pre><code>def get_metadata_path(\n    project_id: str,\n    mri_seq: str,\n    regis_mni: int | None,\n    path_brain_mask: str | None,\n    norm: bool,\n    prune_mode: str | None,\n    path_to_dataset: str | Path | None,\n) -&gt; Path:\n    \"\"\"\n    Get the path to the metadata table of a project's dataset.\n\n    :param project_id: project ID\n    :param mri_seq: MRI sequence (e.g., 't1w')\n    :param regis_mni: set when data was transformed to MNI space (1 or 2 mm) or None\n    :param path_brain_mask: if used, path to the applied brain mask, else None\n    :param norm: if images were normalized\n    :param prune_mode: if not used: None; else pruning mode: \"cube\" or \"max\".\n    :param path_to_dataset: Optional path to folder containing project data (if not in globally set `cache_dir`)\n    :return: path to the metadata table of the project dataset\n    \"\"\"\n    mri_set_name = get_mri_set_name(\n        project_id=project_id,\n        mri_seq=mri_seq,\n        regis_mni=regis_mni,\n        brain_masked=isinstance(path_brain_mask, str),\n        norm=norm,\n        prune_mode=prune_mode,\n    )\n\n    return Path(\n        get_mri_set_path(\n            mri_set_name=mri_set_name + \"_metadata\",\n            path_to_folder=path_to_dataset,\n        ).replace(\".npy\", \".csv\")\n    )\n</code></pre>"},{"location":"reference/dataloader/mri_dataloader/#xai4mri.dataloader.mri_dataloader.get_mri_set_name","title":"get_mri_set_name","text":"<pre><code>get_mri_set_name(\n    project_id: str,\n    mri_seq: str,\n    regis_mni: int | None,\n    brain_masked: bool,\n    norm: bool,\n    prune_mode: str | None,\n) -&gt; str\n</code></pre> <p>Construct a name for the MRI set which is/will be saved as <code>*.pkl</code> object.</p> <p>The full name describes different pre-processing steps.</p> <p>Parameters:</p> Name Type Description Default <code>project_id</code> <code>str</code> <p>name of the project containing the data set, e.g., lemon, hcp, or other projects</p> required <code>mri_seq</code> <code>str</code> <p>MRI sequence</p> required <code>regis_mni</code> <code>int | None</code> <p>registered to MNI space in 1 or 2 mm resolution [int], or None for no registration</p> required <code>brain_masked</code> <code>bool</code> <p>brain mask has been applied</p> required <code>norm</code> <code>bool</code> <p>if data is normalized</p> required <code>prune_mode</code> <code>str | None</code> <p>if data is pruned: None OR \"cube\" OR \"max\"</p> required <p>Returns:</p> Type Description <code>str</code> <p>final name of MRI set</p> Source code in <code>src/xai4mri/dataloader/mri_dataloader.py</code> <pre><code>def get_mri_set_name(\n    project_id: str,\n    mri_seq: str,\n    regis_mni: int | None,\n    brain_masked: bool,\n    norm: bool,\n    prune_mode: str | None,\n) -&gt; str:\n    \"\"\"\n    Construct a name for the MRI set which is/will be saved as `*.pkl` object.\n\n    The full name describes different pre-processing steps.\n\n    :param project_id: name of the project containing the data set, e.g., lemon, hcp, or other projects\n    :param mri_seq: MRI sequence\n    :param regis_mni: registered to MNI space in 1 or 2 mm resolution [int], or None for no registration\n    :param brain_masked: brain mask has been applied\n    :param norm: if data is normalized\n    :param prune_mode: if data is pruned: None OR \"cube\" OR \"max\"\n    :return: final name of MRI set\n    \"\"\"\n    return (\n        f\"{project_id}_\"\n        f\"{mri_seq}\"\n        f'{f\"-mni{regis_mni}mm\" if _check_regis(regis_mni) else \"\"}'\n        f'{\"-bm\" if brain_masked else \"\"}'\n        f'{\"-n\" if norm else \"\"}'\n        f'{\"-p\" + f\"{prune_mode[0]}\" if isinstance(prune_mode, str) else \"\"}'\n    )\n</code></pre>"},{"location":"reference/dataloader/mri_dataloader/#xai4mri.dataloader.mri_dataloader.get_mri_set_path","title":"get_mri_set_path","text":"<pre><code>get_mri_set_path(\n    mri_set_name: str,\n    path_to_folder: str | Path | None = None,\n    as_npy: bool = True,\n    as_zip: bool = False,\n) -&gt; str\n</code></pre> <p>Get the absolute path to the MRI set.</p> <p>Parameters:</p> Name Type Description Default <code>mri_set_name</code> <code>str</code> <p>Name of MRI set (constructed by <code>get_mri_set_name()</code>).</p> required <code>path_to_folder</code> <code>str | Path | None</code> <p>The path where the MRI set is supposed to be located.</p> <code>None</code> <code>as_npy</code> <code>bool</code> <p>True: Save as a numpy (<code>*.npy</code>) else as a pickle (<code>*.pkl</code>) object</p> <code>True</code> <code>as_zip</code> <code>bool</code> <p>zipped file (<code>*.pkl.gz</code>; <code>*.npz</code>)</p> <code>False</code> <p>Returns:</p> Type Description <code>str</code> <p>absolute path to the MRI set</p> Source code in <code>src/xai4mri/dataloader/mri_dataloader.py</code> <pre><code>def get_mri_set_path(\n    mri_set_name: str,\n    path_to_folder: str | Path | None = None,\n    as_npy: bool = True,\n    as_zip: bool = False,\n) -&gt; str:\n    \"\"\"\n    Get the absolute path to the MRI set.\n\n    :param mri_set_name: Name of MRI set (constructed by `get_mri_set_name()`).\n    :param path_to_folder: The path where the MRI set is supposed to be located.\n    :param as_npy: True: Save as a numpy (`*.npy`) else as a pickle (`*.pkl`) object\n    :param as_zip: zipped file (`*.pkl.gz`; `*.npz`)\n    :return: absolute path to the MRI set\n    \"\"\"\n    suffix = (\".npz\" if as_zip else \".npy\") if as_npy else \".pkl.gz\" if as_zip else \".pkl\"\n    if path_to_folder is None:  # Default: look in cache dir\n        mri_set_path = Path(CACHE_DIR, mri_set_name).with_suffix(suffix)\n    elif isinstance(path_to_folder, (str, Path)):\n        if not Path(path_to_folder).is_dir():\n            cprint(string=f\"Note: the folder '{path_to_folder}' does not exist.\", col=\"y\")\n        mri_set_path = Path(path_to_folder, mri_set_name).with_suffix(suffix)\n    else:\n        raise ValueError(\"path_to_folder must be path to folder [str|Path] or None.\")\n    return str(mri_set_path)\n</code></pre>"},{"location":"reference/dataloader/mri_dataloader/#xai4mri.dataloader.mri_dataloader.get_nifti","title":"get_nifti","text":"<pre><code>get_nifti(\n    mri_path: str | Path, reorient: bool\n) -&gt; Nifti1Image\n</code></pre> <p>Get NIfTI image from its file path.</p> <p>This works for both NIfTI [<code>*.nii</code> | <code>*.nii.gz</code>] and MGH [<code>*.mgh</code> | <code>*.mgz</code>] files.</p> <p>Parameters:</p> Name Type Description Default <code>mri_path</code> <code>str | Path</code> <p>path to an MRI file</p> required <code>reorient</code> <code>bool</code> <p>reorient the image to the global project orientation space</p> required <p>Returns:</p> Type Description <code>Nifti1Image</code> <p>nibabel Nifti1Image object</p> Source code in <code>src/xai4mri/dataloader/mri_dataloader.py</code> <pre><code>def get_nifti(mri_path: str | Path, reorient: bool) -&gt; nib.nifti1.Nifti1Image:\n    \"\"\"\n    Get NIfTI image from its file path.\n\n    This works for both NIfTI [`*.nii` | `*.nii.gz`] and MGH [`*.mgh` | `*.mgz`] files.\n\n    :param mri_path: path to an MRI file\n    :param reorient: reorient the image to the global project orientation space\n    :return: nibabel Nifti1Image object\n    \"\"\"\n    nifti_img = nib.load(mri_path)\n    # Define input space\n    if isinstance(nifti_img, nib.freesurfer.mghformat.MGHImage):\n        nifti_img = mgz2nifti(nifti_img)\n\n    if reorient:\n        nifti_img = file_to_ref_orientation(image_file=nifti_img)\n\n    return nifti_img\n</code></pre>"},{"location":"reference/dataloader/mri_dataloader/#xai4mri.dataloader.mri_dataloader.load_file_paths_from_metadata","title":"load_file_paths_from_metadata","text":"<pre><code>load_file_paths_from_metadata(\n    sid_list: list[str] | ndarray[str],\n    path_to_metadata: str | Path,\n    exist_check: bool = True,\n) -&gt; tuple[\n    ndarray[Any, dtype[str | Path]],\n    ndarray[Any, dtype[str]],\n]\n</code></pre> <p>Load file paths to MRI data from a project's metadata table.</p> <p>Parameters:</p> Name Type Description Default <code>sid_list</code> <code>list[str] | ndarray[str]</code> <p>List of subject ID's.</p> required <code>path_to_metadata</code> <code>str | Path</code> <p>Path to the metadata table of a project dataset.</p> required <code>exist_check</code> <code>bool</code> <p>Check if image files exist.</p> <code>True</code> <p>Returns:</p> Type Description <code>tuple[ndarray[Any, dtype[str | Path]], ndarray[Any, dtype[str]]]</code> <p>Array of MRI file paths and ordered list of corresponding subject ID's.</p> Source code in <code>src/xai4mri/dataloader/mri_dataloader.py</code> <pre><code>def load_file_paths_from_metadata(\n    sid_list: list[str] | np.ndarray[str], path_to_metadata: str | Path, exist_check: bool = True\n) -&gt; tuple[np.ndarray[Any, np.dtype[str | Path]], np.ndarray[Any, np.dtype[str]]]:\n    \"\"\"\n    Load file paths to MRI data from a project's metadata table.\n\n    :param sid_list: List of subject ID's.\n    :param path_to_metadata: Path to the metadata table of a project dataset.\n    :param exist_check: Check if image files exist.\n    :return: Array of MRI file paths and ordered list of corresponding subject ID's.\n    \"\"\"\n    # Load metadata\n    metadata_table, processed_col = _prepare_metadata(path_to_metadata=path_to_metadata)\n    metadata_table = metadata_table.dropna()  # clean up the metadata table, when it has not been fully processed\n\n    # Check if all SIDs in metadata table\n    sids_not_in_metadata = set(sid_list).difference(metadata_table.index)\n    if len(sids_not_in_metadata) &gt; 0:\n        cprint(\n            string=f\"Metadata table does not contain all requested SIDs, missing: {sids_not_in_metadata}.\\n\"\n            f\"Return only SIDs data which are also in the metadata table.\",\n            col=\"y\",\n        )\n        sid_list = [sid for sid in sid_list if sid not in sids_not_in_metadata]\n\n    # Load data\n    all_mri_paths = metadata_table.loc[sid_list, processed_col].to_numpy()\n\n    if exist_check and not all(Path(p).is_file() for p in all_mri_paths):\n        msg = f\"Not all requested files exist in: '{path_to_metadata}' (column: ['{processed_col}'])!\"\n        raise FileNotFoundError(msg)\n\n    return all_mri_paths, np.array(sid_list)\n</code></pre>"},{"location":"reference/dataloader/mri_dataloader/#xai4mri.dataloader.mri_dataloader.load_files_from_metadata","title":"load_files_from_metadata","text":"<pre><code>load_files_from_metadata(\n    sid_list: list[str] | ndarray[str],\n    path_to_metadata: str | Path,\n) -&gt; tuple[\n    ndarray[Any, dtype[uint8 | float32]],\n    ndarray[Any, dtype[str]],\n]\n</code></pre> <p>Load MRI data from a project's metadata table.</p> <p>Parameters:</p> Name Type Description Default <code>sid_list</code> <code>list[str] | ndarray[str]</code> <p>List of subject ID's.</p> required <code>path_to_metadata</code> <code>str | Path</code> <p>Path to the metadata table of a project dataset.</p> required <p>Returns:</p> Type Description <code>tuple[ndarray[Any, dtype[uint8 | float32]], ndarray[Any, dtype[str]]]</code> <p>Array of MRI files with the shape <code>[n_subjects, x, y, z, 1]</code>, and an ordered list of corresponding subject ID's.</p> Source code in <code>src/xai4mri/dataloader/mri_dataloader.py</code> <pre><code>def load_files_from_metadata(\n    sid_list: list[str] | np.ndarray[str], path_to_metadata: str | Path\n) -&gt; tuple[np.ndarray[Any, np.dtype[np.uint8 | np.float32]], np.ndarray[Any, np.dtype[str]]]:\n    \"\"\"\n    Load MRI data from a project's metadata table.\n\n    :param sid_list: List of subject ID's.\n    :param path_to_metadata: Path to the metadata table of a project dataset.\n    :return: Array of MRI files with the shape `[n_subjects, x, y, z, 1]`,\n             and an ordered list of corresponding subject ID's.\n    \"\"\"\n    # Load metadata\n    metadata_table, processed_col = _prepare_metadata(path_to_metadata=path_to_metadata)\n    compress = len([c for c in metadata_table.columns if \"clip\" in c]) &gt; 0\n    norm = \"-n-\" in Path(path_to_metadata).name\n    metadata_table = metadata_table.dropna()  # this cleans up the metadata table, when it has not been fully processed\n\n    # Check if all SIDs in metadata table\n    sids_not_in_metadata = set(sid_list).difference(metadata_table.index)\n    if len(sids_not_in_metadata) &gt; 0:\n        cprint(\n            string=f\"Metadata table does not contain all given SIDs, missing: {sids_not_in_metadata}.\\n\"\n            f\"Return only SIDs data which are also in the metadata table.\",\n            col=\"y\",\n        )\n        sid_list = [sid for sid in sid_list if sid not in sids_not_in_metadata]\n\n    # Load data\n    all_mri = None\n    for sid_idx, sid in tqdm(\n        enumerate(sid_list),\n        total=len(sid_list),\n        desc=f\"Loading MRI data for {Path(path_to_metadata).name.split('_metadata.csv')[0]}\",\n    ):\n        path_to_mri = Path(metadata_table.loc[sid, processed_col])\n        single_data4d = _load_obj(name=path_to_mri.name, folder=path_to_mri.parent, functimer=False)\n        single_data4d = np.expand_dims(single_data4d, axis=0)\n\n        if all_mri is None:\n            all_mri = np.empty(\n                shape=(\n                    len(sid_list),\n                    single_data4d.shape[1],\n                    single_data4d.shape[2],\n                    single_data4d.shape[3],\n                ),\n                dtype=np.float32,\n            )  # init data set (to be filled)\n        all_mri[sid_idx, :, :, :] = single_data4d\n\n    # Clip, normalize and, or compress all images\n    clip_min = np.nanmean(metadata_table[f\"{processed_col}_min_clip\"]) if compress else None\n    clip_max = np.nanmean(metadata_table[f\"{processed_col}_max_clip\"]) if compress else None\n    all_mri = compress_and_norm(data=all_mri, clip_min=clip_min, clip_max=clip_max, norm=norm)\n\n    # expand to empty dimension (batch_size, x, y, z, channel=1)\n    all_mri = np.expand_dims(all_mri, axis=4)\n\n    return all_mri, np.array(sid_list)\n</code></pre>"},{"location":"reference/dataloader/mri_dataloader/#xai4mri.dataloader.mri_dataloader.mgz2nifti","title":"mgz2nifti","text":"<pre><code>mgz2nifti(nib_mgh: MGHImage) -&gt; Nifti1Image\n</code></pre> <p>Convert Freesurfer's MGH-NMR [<code>*.mgh</code> | <code>*.mgz</code>] file to NIfTI [<code>*.nii</code>].</p> <p>Parameters:</p> Name Type Description Default <code>nib_mgh</code> <code>MGHImage</code> <p><code>nibabel</code> <code>MGHImage</code> object</p> required <p>Returns:</p> Type Description <code>Nifti1Image</code> <p><code>nibabel</code> <code>Nifti1Image</code> object</p> Source code in <code>src/xai4mri/dataloader/mri_dataloader.py</code> <pre><code>def mgz2nifti(nib_mgh: nib.freesurfer.mghformat.MGHImage) -&gt; nib.nifti1.Nifti1Image:\n    \"\"\"\n    Convert Freesurfer's MGH-NMR [`*.mgh` | `*.mgz`] file to NIfTI [`*.nii`].\n\n    :param nib_mgh: `nibabel` `MGHImage` object\n    :return: `nibabel` `Nifti1Image` object\n    \"\"\"\n    return nib.Nifti1Image(dataobj=nib_mgh.get_fdata(caching=\"unchanged\"), affine=nib_mgh.affine)\n</code></pre>"},{"location":"reference/dataloader/mri_dataloader/#xai4mri.dataloader.mri_dataloader.process_single_mri","title":"process_single_mri","text":"<pre><code>process_single_mri(\n    mri_path: str | Path,\n    dtype: type = np.float32,\n    prune_mode: str | None = \"max\",\n    path_brain_mask: str | Path | None = None,\n    regis_mni: int | None = None,\n    path_cached_mni: str | Path | None = None,\n    verbose: bool = False,\n) -&gt; ndarray\n</code></pre> <p>Load an individual MRI of an individual subject as a numpy array.</p> <p>Parameters:</p> Name Type Description Default <code>mri_path</code> <code>str | Path</code> <p>path to the original NIfTI MRI file</p> required <code>dtype</code> <code>type</code> <p>data type of returned MRI (default: <code>np.float32</code>)</p> <code>float32</code> <code>prune_mode</code> <code>str | None</code> <p>if not use: <code>None</code>; image pruning reduces zero-padding around the brain: \"cube\": all axes have the same length; \"max\": maximally prune all axes independently</p> <code>'max'</code> <code>path_brain_mask</code> <code>str | Path | None</code> <p>path to the brain mask; if no mask should be applied use <code>None</code></p> <code>None</code> <code>regis_mni</code> <code>int | None</code> <p>transform MRI to MNI space in 1 or 2 mm resolution [int], or <code>None</code> for no registration</p> <code>None</code> <code>verbose</code> <code>bool</code> <p>be verbose about the process or not</p> <code>False</code> <code>path_cached_mni</code> <code>str | Path | None</code> <p>if a path is provided, save interim file in MNI space to this cache path</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>4D numpy array (MRI) of shape <code>[(empty), x, y, z]</code></p> Source code in <code>src/xai4mri/dataloader/mri_dataloader.py</code> <pre><code>def process_single_mri(\n    mri_path: str | Path,\n    dtype: type = np.float32,\n    prune_mode: str | None = \"max\",\n    path_brain_mask: str | Path | None = None,\n    regis_mni: int | None = None,\n    path_cached_mni: str | Path | None = None,\n    verbose: bool = False,\n) -&gt; np.ndarray:\n    \"\"\"\n    Load an individual MRI of an individual subject as a numpy array.\n\n    :param mri_path: path to the original NIfTI MRI file\n    :param dtype: data type of returned MRI (default: `np.float32`)\n    :param prune_mode: if not use: `None`; image pruning reduces zero-padding around the brain:\n                       \"cube\": all axes have the same length; \"max\": maximally prune all axes independently\n    :param path_brain_mask: path to the brain mask; if no mask should be applied use `None`\n    :param regis_mni: transform MRI to MNI space in 1 or 2 mm resolution [int], or `None` for no registration\n    :param verbose: be verbose about the process or not\n    :param path_cached_mni: if a path is provided, save interim file in MNI space to this cache path\n    :return: 4D numpy array (MRI) of shape `[(empty), x, y, z]`\n    \"\"\"\n    nifti_img = get_nifti(mri_path=mri_path, reorient=False)  # reorient after registration below\n\n    # Resample to MNI space with 1 or 2 mm resolution\n    if _check_regis(regis_mni):\n        nifti_img = register_to_mni(\n            moving_mri=nifti_img,\n            resolution=regis_mni,\n            save_path_mni=path_cached_mni,\n            type_of_transform=\"Rigid\" if is_mni(img=nifti_img) else \"SyN\",\n            verbose=verbose,\n        )\n\n    # Reorient image to global project orientation space\n    nifti_img = file_to_ref_orientation(image_file=nifti_img)\n\n    # Get image as numpy array\n    data3d = nifti_img.get_fdata(dtype=dtype, caching=\"unchanged\")\n\n    # Prune image, i.e. minimize zero-padding\n    if isinstance(prune_mode, str):\n        # Set max-axes lengths for pruning\n        global_max = get_global_max_axes(nifti_img=nifti_img, per_axis=prune_mode.lower() == \"max\")\n        try:\n            data3d = prune_mri(x3d=data3d, make_cube=prune_mode.lower() == \"cube\", max_axis=global_max)\n        except IndexError as e:\n            cprint(string=f\"\\nCould not prune MRI: {mri_path}\\n\", col=\"r\")\n            raise e\n\n    if isinstance(path_brain_mask, (str, Path)):\n        bm = nib.load(path_brain_mask).get_fdata(caching=\"unchanged\")  # could pass dtype=np.uint8\n        data3d = apply_mask(data=data3d, mask=bm)\n\n    return np.expand_dims(data3d, axis=0)  # now 4d: (*dims, 1)\n</code></pre>"},{"location":"reference/dataloader/mri_registration/","title":"<code class=\"doc-symbol doc-symbol-nav doc-symbol-module\"></code> mri_registration","text":""},{"location":"reference/dataloader/mri_registration/#xai4mri.dataloader.mri_registration","title":"mri_registration","text":"<p>Register MRIs to a new space and create corresponding brain masks.</p> <pre><code>Authors: Simon M. Hofmann | Hannah S. Heinrichs\nYears: 2023-2024\n</code></pre>"},{"location":"reference/dataloader/mri_registration/#xai4mri.dataloader.mri_registration.get_mni_template","title":"get_mni_template","text":"<pre><code>get_mni_template(\n    low_res: bool = True,\n    reorient: bool = True,\n    prune_mode: str | None = \"max\",\n    norm: tuple[int | float, int | float] = (0, 1),\n    mask: bool = False,\n    original_template: bool = True,\n    as_nii: bool = False,\n) -&gt; ndarray | Nifti1Image\n</code></pre> <p>Get the MNI template.</p> <p>Parameters:</p> Name Type Description Default <code>low_res</code> <code>bool</code> <p>True: 2 mm; False: 1 mm isotropic resolution.</p> <code>True</code> <code>reorient</code> <code>bool</code> <p>Whether to reorient the template to the project orientation space.</p> <code>True</code> <code>prune_mode</code> <code>str | None</code> <p>If not use <code>None</code>; image pruning reduces zero-padding around the brain: \"cube\": all axes have the same length; \"max\": maximally prune all axes independently Pruning asserts that MRI background to be zero.</p> <code>'max'</code> <code>norm</code> <code>tuple[int | float, int | float]</code> <p>Whether to normalize image values between 0-1.</p> <code>(0, 1)</code> <code>mask</code> <code>bool</code> <p>Whether to return a binary mask only.</p> <code>False</code> <code>original_template</code> <code>bool</code> <p>With <code>v.0.8.1</code> <code>nilearn</code> reshaped its MNI template (91,109,91) \u2192 (99,117,95). If toggled <code>True</code>: this functions uses the previous template.</p> <code>True</code> <code>as_nii</code> <code>bool</code> <p>Whether to return template as NIfTI image, else it will be a numpy array.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray | Nifti1Image</code> <p>MNI template image</p> Source code in <code>src/xai4mri/dataloader/mri_registration.py</code> <pre><code>def get_mni_template(\n    low_res: bool = True,\n    reorient: bool = True,\n    prune_mode: str | None = \"max\",\n    norm: tuple[int | float, int | float] = (0, 1),\n    mask: bool = False,\n    original_template: bool = True,\n    as_nii: bool = False,\n) -&gt; np.ndarray | nib.Nifti1Image:\n    \"\"\"\n    Get the MNI template.\n\n    :param low_res: True: 2 mm; False: 1 mm isotropic resolution.\n    :param reorient: Whether to reorient the template to the project orientation space.\n    :param prune_mode: If not use `None`; image pruning reduces zero-padding around the brain:\n                       \"cube\": all axes have the same length; \"max\": maximally prune all axes independently\n                       Pruning asserts that MRI background to be zero.\n    :param norm: Whether to normalize image values between 0-1.\n    :param mask: Whether to return a binary mask only.\n    :param original_template: With `v.0.8.1` `nilearn` reshaped its MNI template (91,109,91) \u2192 (99,117,95).\n                              If toggled `True`: this functions uses the previous template.\n    :param as_nii: Whether to return template as NIfTI image, else it will be a numpy array.\n    :return: MNI template image\n    \"\"\"\n    # MNI152 since 2009 (nonlinear version)\n    if norm[0] != BG_VALUE:\n        msg = \"Function works only for zero-background (i.e., min-value = 0)!\"\n        raise ValueError(msg)\n    if isinstance(prune_mode, str):\n        prune_mode = prune_mode.lower()\n        if prune_mode not in {\"cube\", \"max\"}:\n            msg = \"prune_mode must be 'cube' OR 'max' OR None\"\n            raise ValueError(msg)\n\n    if low_res:\n        # Nilearn has 2mm resolution\n        mni_temp = load_mni152_template(resolution=2)\n        if original_template:\n            # With v.0.8.1, nilearn:\n            #  1) reshaped (91, 109, 91) -&gt; (99, 117, 95) &amp;\n            #  2) changed the affine to np.array([[2., 0., 0., -98.],\n            #                                     [0., 2., 0., -134.],  # noqa: ERA001\n            #                                     [0., 0., 2., -72.],  # noqa: ERA001\n            #                                     [0., 0., 0., 1.]])\n            #  3) rescaled (0-8339) -&gt; (0-255) the MNI template\n            #  https://github.com/nilearn/nilearn/blob/d91545d9dd0f74ca884cc91dca751f8224f67d99/doc/changes/0.8.1.rst#enhancements\n            mni_temp = resample_img(\n                img=mni_temp,\n                target_affine=np.array([\n                    [-2.0, 0.0, 0.0, 90.0],\n                    [0.0, 2.0, 0.0, -126.0],\n                    [0.0, 0.0, 2.0, -72.0],\n                    [0.0, 0.0, 0.0, 1.0],\n                ]),\n                target_shape=(91, 109, 91),\n            )\n\n            # Remove very small values from interpolation\n            mni_temp = nib.Nifti1Image(\n                dataobj=np.round(mni_temp.get_fdata(), decimals=3),\n                affine=mni_temp.affine,\n                header=mni_temp.header,\n            )\n\n    else:\n        # ANTs template has 1 mm resolution\n        from ants import get_ants_data  # , image_read,\n\n        mni_path = get_ants_data(\"mni\")\n        mni_temp = nib.load(mni_path)  # ants.image_read(mni_path)\n\n    # Re-orient to global/project orientation space\n    if reorient:\n        mni_temp = file_to_ref_orientation(image_file=mni_temp)\n\n    if as_nii:\n        if isinstance(prune_mode, str) or mask:\n            cprint(string=\"No pruning or masking is done for MNI templates that are returned as NIfTI!\", col=\"r\")\n        return mni_temp\n\n    if isinstance(prune_mode, str):\n        prune_mode = prune_mode.lower()\n        global_max = get_global_max_axes(nifti_img=mni_temp, per_axis=prune_mode == \"max\")\n        mni_temp = prune_mri(x3d=mni_temp.get_fdata(), make_cube=prune_mode == \"cube\", max_axis=global_max)\n    else:\n        mni_temp = mni_temp.get_fdata()\n\n    # Normalize\n    mni_temp = normalize(array=mni_temp, lower_bound=norm[0], upper_bound=norm[1])\n\n    # Create a brain mask version\n    if mask:\n        mni_temp[mni_temp &gt; BG_VALUE] = 1\n\n    return mni_temp\n</code></pre>"},{"location":"reference/dataloader/mri_registration/#xai4mri.dataloader.mri_registration.is_mni","title":"is_mni","text":"<pre><code>is_mni(img: Nifti1Image | ndarray) -&gt; bool\n</code></pre> <p>Check if the given image is in any MNI space.</p> <p>Parameters:</p> Name Type Description Default <code>img</code> <code>Nifti1Image | ndarray</code> <p>MR image.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the image is in MNI space, else False</p> Source code in <code>src/xai4mri/dataloader/mri_registration.py</code> <pre><code>def is_mni(img: nib.nifti1.Nifti1Image | np.ndarray) -&gt; bool:\n    \"\"\"\n    Check if the given image is in any MNI space.\n\n    :param img: MR image.\n    :return: True if the image is in MNI space, else False\n    \"\"\"\n    img_shape = tuple(sorted(img.shape))\n\n    return img_shape in {\n        (91, 91, 109),  # sorted(get_mni_template(low_res=True, as_nii=True).shape)\n        (95, 99, 117),  # sorted(load_mni152_template(resolution=2).shape)\n        (182, 182, 218),  # sorted(get_mni_template(low_res=False, as_nii=True).shape)\n        (181, 181, 217),\n        (189, 197, 233),  # sorted(load_mni152_template(resolution=1).shape)\n        (260, 260, 311),  # sorted(HCP MNI format)\n    }\n</code></pre>"},{"location":"reference/dataloader/mri_registration/#xai4mri.dataloader.mri_registration.register_to_mni","title":"register_to_mni","text":"<pre><code>register_to_mni(\n    moving_mri: Nifti1Image,\n    resolution: int,\n    type_of_transform: str,\n    save_path_mni: str | Path | None = None,\n    verbose: bool = False,\n) -&gt; Nifti1Image\n</code></pre> <p>Register a NIfTI image to the MNI template.</p> <p>Note, if there are issues with file handling, functions of <code>antspyx</code>, which is used for registration (<code>ants.registration</code>), cannot handle <code>*.mgz</code> | <code>*.mgh</code> files, use <code>xai4mri.dataloader.mri_dataloader.mgz2nifti()</code> for conversion.</p> <p>Parameters:</p> Name Type Description Default <code>moving_mri</code> <code>Nifti1Image</code> <p>Input image to be registered to MNI space.</p> required <code>resolution</code> <code>int</code> <p>Either 1 or 2 mm isotropic resolution.</p> required <code>type_of_transform</code> <code>str</code> <p>Either linear registration: 'Rigid' OR non-linear warping: 'SyN'.</p> required <code>save_path_mni</code> <code>str | Path | None</code> <p>Path to registered MRI. If provided, save or fetch MRI in MNI space.</p> <code>None</code> <code>verbose</code> <code>bool</code> <p>Show output of the registration process.</p> <code>False</code> <p>Returns:</p> Type Description <code>Nifti1Image</code> <p>MRI in MNI space (NIfTI)</p> Source code in <code>src/xai4mri/dataloader/mri_registration.py</code> <pre><code>def register_to_mni(\n    moving_mri: nib.nifti1.Nifti1Image,\n    resolution: int,\n    type_of_transform: str,\n    save_path_mni: str | Path | None = None,\n    verbose: bool = False,\n) -&gt; nib.Nifti1Image:\n    \"\"\"\n    Register a NIfTI image to the MNI template.\n\n    Note, if there are issues with file handling,\n    functions of `antspyx`, which is used for registration (`ants.registration`),\n    cannot handle `*.mgz` | `*.mgh` files,\n    use `xai4mri.dataloader.mri_dataloader.mgz2nifti()` for conversion.\n\n    :param moving_mri: Input image to be registered to MNI space.\n    :param resolution: Either 1 or 2 mm isotropic resolution.\n    :param type_of_transform: Either linear registration: 'Rigid' OR non-linear warping: 'SyN'.\n    :param save_path_mni: Path to registered MRI.\n                          If provided, save or fetch MRI in MNI space.\n    :param verbose: Show output of the registration process.\n    :return: MRI in MNI space (NIfTI)\n    \"\"\"\n    if save_path_mni and Path(save_path_mni).is_file():\n        # Load file as a nibabel object\n        return nib.load(save_path_mni)  # ants.to_nibabel(mni_ants)\n\n    if resolution not in {1, 2}:\n        msg = \"resolution must be either 1 or 2\"\n        raise ValueError(msg)\n\n    # Create the file with registration to mni\n    mni_template = get_mni_template(\n        low_res=resolution == 2,  # noqa: PLR2004\n        reorient=False,\n        prune_mode=None,\n        original_template=True,\n        as_nii=True,\n    )  # 1mm, shape: (182, 218, 182) | 2mm, shape: (91, 109, 91)\n    mni_tx = ants.registration(\n        fixed=ants.from_nibabel(mni_template),  # reference MRI in MNI space\n        moving=ants.from_nibabel(moving_mri),\n        type_of_transform=type_of_transform,  # linear: 'Rigid' vs non-linear warping: 'SyN'\n        verbose=verbose,\n    )\n\n    # Save to the given path of the cache folder\n    if save_path_mni is not None:\n        save_path_mni = Path(save_path_mni)\n        save_path_mni.parent.mkdir(parents=True, exist_ok=True)\n        mni_tx[\"warpedmovout\"].to_file(save_path_mni)  # save image in MNI space\n\n        # Save transformation files to cache folder, too\n        save_path_transformers = save_path_mni.parent / \"transforms2mni\"\n        save_path_transformers.mkdir(parents=True, exist_ok=True)\n        save_ants_warpers(tx=mni_tx, folder_path=str(save_path_transformers), image_name=\"transform\")\n\n    mni_nib = mni_tx[\"warpedmovout\"].to_nibabel()\n\n    if verbose:\n        cprint(\n            string=f\"Given image with original shape {moving_mri.shape} is now in {resolution}mm MNI152 space with \"\n            f\"shape {mni_nib.shape}.\",\n            col=\"y\",\n        )\n\n    return mni_nib\n</code></pre>"},{"location":"reference/dataloader/prune_image/","title":"<code class=\"doc-symbol doc-symbol-nav doc-symbol-module\"></code> prune_image","text":""},{"location":"reference/dataloader/prune_image/#xai4mri.dataloader.prune_image","title":"prune_image","text":"<p>Pruning MRIs has the goal to remove background around brains / heads, i.e., reduce the size of a 3D image.</p> <p>One key objective is to find the smallest box in the whole dataset, which can surround each brain / head in it. That is, the space of the 'biggest' brain.</p> <pre><code>Author: Simon M. Hofmann\nYears: 2023-2024\n</code></pre>"},{"location":"reference/dataloader/prune_image/#xai4mri.dataloader.prune_image.find_brain_edges","title":"find_brain_edges","text":"<pre><code>find_brain_edges(\n    x3d: ndarray, sl: bool = False\n) -&gt; tuple[slice, slice, slice] | tuple[int, ...]\n</code></pre> <p>Find the on- &amp; the offset of brain (or head) voxels for each plane.</p> <p>This will find the tangential edges of the brain in the given 3D volume.</p> <pre><code>                    /      3D-volume    /\n                   +-------------------+\n                   |   +_____edge____+ |\n                   |   |    *****    | |\n                   |   |  **     **  | |\n                   |   | *  ** **  * | |\n                   |   |*    ***    *| |\n                   | Y |*    ***    *| |\n                   |   |*    ***    *| |  Z\n                   |   |*   ** **   *| | /\n                   |   | * **   ** * | |/  /\n                   |   |  **     **  | |  /\n                   |   |    *****    |/| /\n                   |   +\u2013\u2013\u2013\u2013\u2013 X \u2013\u2013\u2013\u2013\u2013+ |/\n                   +-------------------+\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>x3d</code> <code>ndarray</code> <p>3D data.</p> required <code>sl</code> <code>bool</code> <p>Whether to return <code>slice</code>'s. Instead, provide coordinates (if set to <code>False</code>, default).</p> <code>False</code> <p>Returns:</p> Type Description <code>tuple[slice, slice, slice] | tuple[int, ...]</code> <p>Tuple with six values of slices or coordinates, two values (lower, upper) per dimension / axis.</p> Source code in <code>src/xai4mri/dataloader/prune_image.py</code> <pre><code>def find_brain_edges(x3d: np.ndarray, sl: bool = False) -&gt; tuple[slice, slice, slice] | tuple[int, ...]:\n    \"\"\"\n    Find the on- &amp; the offset of brain (or head) voxels for each plane.\n\n    This will find the tangential edges of the brain in the given 3D volume.\n\n    ```text\n                        /      3D-volume    /\n                       +-------------------+\n                       |   +_____edge____+ |\n                       |   |    *****    | |\n                       |   |  **     **  | |\n                       |   | *  ** **  * | |\n                       |   |*    ***    *| |\n                       | Y |*    ***    *| |\n                       |   |*    ***    *| |  Z\n                       |   |*   ** **   *| | /\n                       |   | * **   ** * | |/  /\n                       |   |  **     **  | |  /\n                       |   |    *****    |/| /\n                       |   +\u2013\u2013\u2013\u2013\u2013 X \u2013\u2013\u2013\u2013\u2013+ |/\n                       +-------------------+\n    ```\n\n    :param x3d: 3D data.\n    :param sl: Whether to return `slice`'s.\n               Instead, provide coordinates (if set to `False`, default).\n    :return: Tuple with six values of slices or coordinates, two values (lower, upper) per dimension / axis.\n    \"\"\"\n    # Slice through image until first appearing brain-voxels are detected (i.e., no background)\n    # Find 'lower' planes (i.e., low, left, back, respectively)\n    il, jl, kl = 0, 0, 0  # initialize\n    while np.all(x3d[il, :, :] == BG_VALUE):  # sagittal slide\n        il += 1\n    while np.all(x3d[:, jl, :] == BG_VALUE):  # transverse slide\n        jl += 1\n    while np.all(x3d[:, :, kl] == BG_VALUE):  # coronal/posterior/frontal\n        kl += 1\n\n    # Now, find 'upper' planes (i.e., upper, right, front, respectively)\n    iu, ju, ku = np.array(x3d.shape) - 1\n    while np.all(x3d[iu, :, :] == BG_VALUE):  # sagittal/longitudinal\n        iu -= 1\n    while np.all(x3d[:, ju, :] == BG_VALUE):  # transverse/inferior/horizontal\n        ju -= 1\n    while np.all(x3d[:, :, ku] == BG_VALUE):  # coronal/posterior/frontal\n        ku -= 1\n\n    if sl:  # return slices\n        return slice(il, iu + 1), slice(jl, ju + 1), slice(kl, ku + 1)\n    # else return coordinates\n    return il, iu, jl, ju, kl, ku\n</code></pre>"},{"location":"reference/dataloader/prune_image/#xai4mri.dataloader.prune_image.get_brain_axes_length","title":"get_brain_axes_length","text":"<pre><code>get_brain_axes_length(x3d: ndarray) -&gt; Sequence[int]\n</code></pre> <p>Get the length of each brain axis (x,y,z) in voxels.</p> <p>This will find the tangential edges of the brain in the given 3D volume and measure their lengths.</p> <pre><code>                    /      3D-volume    /\n                   +-------------------+\n                   |   +_____edge____+ |\n                   |   |    *****    | |\n                   |   |  **     **  | |\n                   |   | *  ** **  * | |\n                   |   |*    ***    *| |\n                   | Y |*    ***    *| |\n                   |   |*    ***    *| |  Z\n                   |   |*   ** **   *| | /\n                   |   | * **   ** * | |/  /\n                   |   |  **     **  | |  /\n                   |   |    *****    |/| /\n                   |   +\u2013\u2013\u2013\u2013\u2013 X \u2013\u2013\u2013\u2013\u2013+ |/\n                   +-------------------+\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>x3d</code> <code>ndarray</code> <p>3D volume holding a brain / mask.</p> required <p>Returns:</p> Type Description <code>Sequence[int]</code> <p>The brain axes lengths.</p> Source code in <code>src/xai4mri/dataloader/prune_image.py</code> <pre><code>def get_brain_axes_length(x3d: np.ndarray) -&gt; Sequence[int]:\n    \"\"\"\n    Get the length of each brain axis (x,y,z) in voxels.\n\n    This will find the tangential edges of the brain in the given 3D volume and measure their lengths.\n\n    ```text\n                        /      3D-volume    /\n                       +-------------------+\n                       |   +_____edge____+ |\n                       |   |    *****    | |\n                       |   |  **     **  | |\n                       |   | *  ** **  * | |\n                       |   |*    ***    *| |\n                       | Y |*    ***    *| |\n                       |   |*    ***    *| |  Z\n                       |   |*   ** **   *| | /\n                       |   | * **   ** * | |/  /\n                       |   |  **     **  | |  /\n                       |   |    *****    |/| /\n                       |   +\u2013\u2013\u2013\u2013\u2013 X \u2013\u2013\u2013\u2013\u2013+ |/\n                       +-------------------+\n    ```\n\n    :param x3d: 3D volume holding a brain / mask.\n    :return: The brain axes lengths.\n    \"\"\"\n    il, iu, jl, ju, kl, ku = find_brain_edges(x3d)\n    return [iu + 1 - il, ju + 1 - jl, ku + 1 - kl]\n</code></pre>"},{"location":"reference/dataloader/prune_image/#xai4mri.dataloader.prune_image.get_global_max_axes","title":"get_global_max_axes","text":"<pre><code>get_global_max_axes(\n    nifti_img: Nifti1Image, per_axis: bool\n) -&gt; int | Sequence[int]\n</code></pre> <p>Get the global max axis-length(s) for the given brain.</p> <p>The global lengths are the maximum axis-length for all brain axes. It is globally defined for all brains in the dataset. The value can be set in the <code>PruneConfig</code> class (<code>PruneConfig.largest_brain_max_axes</code>). These values are used for pruning brain images.</p> <p>Parameters:</p> Name Type Description Default <code>nifti_img</code> <code>Nifti1Image</code> <p>NIfTI image.</p> required <code>per_axis</code> <code>bool</code> <p>True: return max axis-length for each axis (for <code>prune_mode='max'</code>); False: return max axis-length for all axes (for <code>prune_mode='cube'</code>).</p> required <p>Returns:</p> Type Description <code>int | Sequence[int]</code> <p>Global max axis-length(s).</p> Source code in <code>src/xai4mri/dataloader/prune_image.py</code> <pre><code>def get_global_max_axes(nifti_img: nib.Nifti1Image, per_axis: bool) -&gt; int | Sequence[int]:\n    \"\"\"\n    Get the global max axis-length(s) for the given brain.\n\n    The global lengths are the maximum axis-length for all brain axes.\n    It is globally defined for all brains in the dataset.\n    The value can be set in the `PruneConfig` class (`PruneConfig.largest_brain_max_axes`).\n    These values are used for pruning brain images.\n\n    :param nifti_img: NIfTI image.\n    :param per_axis: True: return max axis-length for each axis (for `prune_mode='max'`);\n                     False: return max axis-length for all axes (for `prune_mode='cube'`).\n    :return: Global max axis-length(s).\n    \"\"\"\n    if nib.orientations.aff2axcodes(nifti_img.affine) != tuple(GLOBAL_ORIENTATION_SPACE):\n        msg = (\n            f\"The orientation of the given NIfTI must match the GLOBAL_ORIENTATION_SPACE: \"\n            f\"'{GLOBAL_ORIENTATION_SPACE}'!\"\n        )\n        raise ValueError(msg)\n\n    # PruneConfig.largest_brain_max_axes is defined for 1 mm isotropic resolution\n    resolution = np.round(nifti_img.header[\"pixdim\"][1:4], decimals=3)  # image resolution per axis\n    # Adapt the global max axes to the resolution of the given image\n    global_max_axis = np.round(PruneConfig.largest_brain_max_axes // resolution).astype(int)\n    if not per_axis:\n        global_max_axis = int(global_max_axis.max())\n    return global_max_axis\n</code></pre>"},{"location":"reference/dataloader/prune_image/#xai4mri.dataloader.prune_image.permute_array","title":"permute_array","text":"<pre><code>permute_array(xd: ndarray) -&gt; ndarray\n</code></pre> <p>Swap all entries (e.g., voxels) in the given x-dimensional array (e.g., 3D-MRI).</p> <p>Parameters:</p> Name Type Description Default <code>xd</code> <code>ndarray</code> <p>x-dimensional array</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>permuted array</p> Source code in <code>src/xai4mri/dataloader/prune_image.py</code> <pre><code>def permute_array(xd: np.ndarray) -&gt; np.ndarray:\n    \"\"\"\n    Swap all entries (e.g., voxels) in the given x-dimensional array (e.g., 3D-MRI).\n\n    :param xd: x-dimensional array\n    :return: permuted array\n    \"\"\"\n    flat_xd = xd.flatten()\n    np.random.shuffle(flat_xd)  # noqa: NPY002\n    return flat_xd.reshape(xd.shape)\n</code></pre>"},{"location":"reference/dataloader/prune_image/#xai4mri.dataloader.prune_image.permute_nifti","title":"permute_nifti","text":"<pre><code>permute_nifti(nifti_img: Nifti1Image) -&gt; Nifti1Image\n</code></pre> <p>Swap all entries (e.g., voxels) in the given NIfTI image.</p> <p>Parameters:</p> Name Type Description Default <code>nifti_img</code> <code>Nifti1Image</code> <p>NIfTI image</p> required <p>Returns:</p> Type Description <code>Nifti1Image</code> <p>permuted NIfTI image (i.e., a noise image)</p> Source code in <code>src/xai4mri/dataloader/prune_image.py</code> <pre><code>def permute_nifti(nifti_img: nib.Nifti1Image) -&gt; nib.Nifti1Image:\n    \"\"\"\n    Swap all entries (e.g., voxels) in the given NIfTI image.\n\n    :param nifti_img: NIfTI image\n    :return: permuted NIfTI image (i.e., a noise image)\n    \"\"\"\n    xd = nifti_img.get_fdata()\n    flat_xd = xd.flatten()\n    np.random.shuffle(flat_xd)  # noqa: NPY002\n    xd = flat_xd.reshape(xd.shape)\n    return nib.Nifti1Image(dataobj=xd, affine=nifti_img.affine, header=nifti_img.header)\n</code></pre>"},{"location":"reference/dataloader/prune_image/#xai4mri.dataloader.prune_image.prune_mri","title":"prune_mri","text":"<pre><code>prune_mri(\n    x3d: ndarray,\n    make_cube: bool = False,\n    max_axis: (\n        int | Sequence[int] | ndarray[int] | None\n    ) = None,\n    padding: int = 0,\n) -&gt; ndarray | None\n</code></pre> <p>Prune given 3D MRI to (smaller) volume with side-length(s) == <code>max_axis</code> [<code>int</code> OR 3D tuple].</p> <p>If <code>max_axis</code> is <code>None</code>, find the smallest volume, which covers the brain (i.e., remove zero-padding). Works very fast. [Implementation with <code>np.pad</code> is possible, too].</p> <p>Compare to: <code>nilearn.image.crop_img()</code> for NIfTI's:     * This crops exactly along the brain only     * which is the same as: <code>mri[find_brain_edges(mri, sl=True)]</code>     * but it is slower</p> <p>Parameters:</p> Name Type Description Default <code>x3d</code> <code>ndarray</code> <p>3D MRI</p> required <code>max_axis</code> <code>int | Sequence[int] | ndarray[int] | None</code> <p>Either side-length [int] of a pruned cube; Or pruned side-length for each axis [3D-sequence: [int, int, int]].</p> <code>None</code> <code>make_cube</code> <code>bool</code> <p>True: pruned MRI will be a cube; False: each axis will be pruned to <code>max_axis</code></p> <code>False</code> <code>padding</code> <code>int</code> <p>Number of zero-padding layers that should remain around the brain [int &gt;= 0]</p> <code>0</code> <p>Returns:</p> Type Description <code>ndarray | None</code> <p>pruned brain image or <code>None</code> if <code>x3d</code> is not a numpy array</p> Source code in <code>src/xai4mri/dataloader/prune_image.py</code> <pre><code>def prune_mri(\n    x3d: np.ndarray,\n    make_cube: bool = False,\n    max_axis: int | Sequence[int] | np.ndarray[int] | None = None,\n    padding: int = 0,\n) -&gt; np.ndarray | None:\n    \"\"\"\n    Prune given 3D MRI to (smaller) volume with side-length(s) == `max_axis` [`int` OR 3D tuple].\n\n    If `max_axis` is `None`, find the smallest volume, which covers the brain (i.e., remove zero-padding).\n    Works very fast.\n    [Implementation with `np.pad` is possible, too].\n\n    Compare to: `nilearn.image.crop_img()` for NIfTI's:\n        * This crops exactly along the brain only\n        * which is the same as: `mri[find_brain_edges(mri, sl=True)]`\n        * but it is slower\n\n    :param x3d: 3D MRI\n    :param max_axis: Either side-length [int] of a pruned cube; Or\n                     pruned side-length for each axis [3D-sequence: [int, int, int]].\n    :param make_cube: True: pruned MRI will be a cube; False: each axis will be pruned to `max_axis`\n    :param padding: Number of zero-padding layers that should remain around the brain [int &gt;= 0]\n    :return: pruned brain image or `None` if `x3d` is not a numpy array\n    \"\"\"\n    # Check argument:\n    if max_axis is not None:\n        if make_cube:\n            if not isinstance(max_axis, (int, np.int_)):\n                msg = \"If the target volume suppose to be a cube, 'max_axis' must of type int!\"\n                raise TypeError(msg)\n        else:\n            msg = \"If the target volume suppose to be no cube, 'max_axis' must be a 3D-shaped tuple of integers!\"\n            if not isinstance(max_axis, (Sequence, np.ndarray)) or not all(\n                isinstance(e, (int, np.int_)) for e in max_axis\n            ):\n                raise TypeError(msg)\n            n_dims = 3\n            if len(max_axis) != n_dims:\n                raise ValueError(msg)\n\n    if not isinstance(padding, (int, np.int_)) or padding &lt; 0:\n        msg = \"'padding' must be an integer &gt;= 0!\"\n        raise ValueError(msg)\n\n    if isinstance(x3d, np.ndarray):\n        # Cut out\n        x3d_minimal = x3d[find_brain_edges(x3d, sl=True)]\n\n        # Prune to smaller volume\n        if max_axis is None:\n            # find the longest axis for cubing [int] OR take the shape of the minimal volume [3D-tuple]\n            max_axis = np.max(x3d_minimal.shape) if make_cube else np.array(x3d_minimal.shape)\n\n        # Add padding at the borders (if requested) &amp; make max_axis a 3D shape-tuple/list\n        max_axis = [max_axis + padding] * 3 if make_cube else np.array(max_axis) + padding\n\n        # Initialize an empty 3D target volume\n        x3d_small_vol = np.zeros(max_axis, dtype=x3d.dtype)\n        if x3d.min() != 0.0:\n            x3d_small_vol[x3d_small_vol == 0] = x3d.min()  # in case background is e.g. -1\n\n        x3d_small_vol, _ = _place_small_in_middle_of_big(big=x3d_small_vol, small=x3d_minimal)  # _ = cut\n\n    else:\n        cprint(string=\"'x3d' is not a numpy array!\", col=\"r\")\n        x3d_small_vol = None\n\n    return x3d_small_vol\n</code></pre>"},{"location":"reference/dataloader/prune_image/#xai4mri.dataloader.prune_image.reverse_pruning","title":"reverse_pruning","text":"<pre><code>reverse_pruning(\n    original_mri: ndarray | Nifti1Image,\n    pruned_mri: ndarray,\n    pruned_stats_map: ndarray | None = None,\n) -&gt; ndarray | Nifti1Image\n</code></pre> <p>Reverse the pruning of an MRI or its corresponding statistical map.</p> <p>If a statistical map is given, both the original MRI and the pruned MRI are necessary to find the edges of the cut-off during pruning. If no statistical map is given, only the original MRI and the pruned MRI are required. Note, in this case <code>reverse_pruning()</code> is applied to a processed and pruned version of the original MRI.</p> <p>Make sure that the original MRI and the pruned MRI have the same orientation.</p> <p>Parameters:</p> Name Type Description Default <code>original_mri</code> <code>ndarray | Nifti1Image</code> <p>Original (i.e., non-pruned) MRI.</p> required <code>pruned_mri</code> <code>ndarray</code> <p>Pruned MRI.</p> required <code>pruned_stats_map</code> <code>ndarray | None</code> <p>[Optional] pruned statistical map.</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray | Nifti1Image</code> <p>MRI with original size (if original_mri is given as Nifti1Image, returns Nifti1Image).</p> Source code in <code>src/xai4mri/dataloader/prune_image.py</code> <pre><code>def reverse_pruning(\n    original_mri: np.ndarray | nib.Nifti1Image,\n    pruned_mri: np.ndarray,\n    pruned_stats_map: np.ndarray | None = None,\n) -&gt; np.ndarray | nib.Nifti1Image:\n    \"\"\"\n    Reverse the pruning of an MRI or its corresponding statistical map.\n\n    If a statistical map is given, both the original MRI and the pruned MRI are necessary to find the edges of\n    the cut-off during pruning.\n    If no statistical map is given, only the original MRI and the pruned MRI are required.\n    Note, in this case `reverse_pruning()` is applied to a processed and pruned version of the original MRI.\n\n    Make sure that the original MRI and the pruned MRI have the same orientation.\n\n    :param original_mri: Original (i.e., non-pruned) MRI.\n    :param pruned_mri: Pruned MRI.\n    :param pruned_stats_map: [Optional] pruned statistical map.\n    :return: MRI with original size (if original_mri is given as Nifti1Image, returns Nifti1Image).\n    \"\"\"\n    # Check whether original_mri is Nifti1Image\n    is_nifti = isinstance(original_mri, nib.Nifti1Image)\n\n    # Define which volume to use for reverse pruning\n    volume_to_reverse_pruning = pruned_mri if pruned_stats_map is None else pruned_stats_map\n\n    # Initialize the MRI to fill\n    volume_to_fill = np.zeros(shape=original_mri.shape)\n    volume_to_fill[...] = BG_VALUE  # set background\n\n    # Find the edges of the brain (slice format)\n    original_mri_edge_slices = find_brain_edges(x3d=original_mri.get_fdata() if is_nifti else original_mri, sl=True)\n    pruned_mri_edge_slices = find_brain_edges(x3d=pruned_mri, sl=True)\n\n    # Use the edges to place the brain data at the right spot\n    volume_to_fill[original_mri_edge_slices] = volume_to_reverse_pruning[pruned_mri_edge_slices]\n\n    if is_nifti:\n        return nib.Nifti1Image(\n            dataobj=volume_to_fill,\n            affine=original_mri.affine,\n            header=original_mri.header if pruned_stats_map is None else None,\n            extra=original_mri.extra if pruned_stats_map is None else None,\n            dtype=original_mri.get_data_dtype() if pruned_stats_map is None else None,\n        )\n\n    return volume_to_fill\n</code></pre>"},{"location":"reference/dataloader/transformation/","title":"<code class=\"doc-symbol doc-symbol-nav doc-symbol-module\"></code> transformation","text":""},{"location":"reference/dataloader/transformation/#xai4mri.dataloader.transformation","title":"transformation","text":"<p>Functions to transform MRIs.</p> <pre><code>Author: Simon M. Hofmann\nYears: 2023-2024\n</code></pre>"},{"location":"reference/dataloader/transformation/#xai4mri.dataloader.transformation.apply_mask","title":"apply_mask","text":"<pre><code>apply_mask(data: ndarray, mask: ndarray) -&gt; ndarray\n</code></pre> <p>Apply volume mask to data.</p> <p>Data and the corresponding mask must have the same shape.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Data to be masked.</p> required <code>mask</code> <code>ndarray</code> <p>Mask to be applied.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Masked data.</p> Source code in <code>src/xai4mri/dataloader/transformation.py</code> <pre><code>def apply_mask(data: np.ndarray, mask: np.ndarray) -&gt; np.ndarray:\n    \"\"\"\n    Apply volume mask to data.\n\n    Data and the corresponding mask must have the same shape.\n\n    :param data: Data to be masked.\n    :param mask: Mask to be applied.\n    :return: Masked data.\n    \"\"\"\n    if data.shape != mask.shape:\n        # check orientation/shape\n        msg = f\"Data shape {data.shape} does not match brain mask shape {mask.shape}.\"\n        raise ValueError(msg)\n    return data * mask\n</code></pre>"},{"location":"reference/dataloader/transformation/#xai4mri.dataloader.transformation.clip_data","title":"clip_data","text":"<pre><code>clip_data(\n    data: ndarray, at_percentile: float = CLIP_PERCENTILE\n) -&gt; ndarray\n</code></pre> <p>Clip provided data at a certain intensity percentile as the clipping threshold.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Data to be clipped.</p> required <code>at_percentile</code> <code>float</code> <p>Percentile of the upper bound.</p> <code>CLIP_PERCENTILE</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Clipped data.</p> Source code in <code>src/xai4mri/dataloader/transformation.py</code> <pre><code>def clip_data(data: np.ndarray, at_percentile: float = CLIP_PERCENTILE) -&gt; np.ndarray:\n    \"\"\"\n    Clip provided data at a certain intensity percentile as the clipping threshold.\n\n    :param data: Data to be clipped.\n    :param at_percentile: Percentile of the upper bound.\n    :return: Clipped data.\n    \"\"\"\n    min_clip_val, max_clip_val = determine_min_max_clip(data=data, at_percentile=at_percentile)\n    return np.clip(a=data, a_min=min_clip_val, a_max=max_clip_val)\n</code></pre>"},{"location":"reference/dataloader/transformation/#xai4mri.dataloader.transformation.compress_and_norm","title":"compress_and_norm","text":"<pre><code>compress_and_norm(\n    data: ndarray,\n    clip_min: float | int | None,\n    clip_max: float | int | None,\n    norm: bool | None,\n    global_norm_min: float | int | None,\n    global_norm_max: float | int | None,\n) -&gt; ndarray\n</code></pre> <p>Clip, normalize, and/or compress data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Data to be processed.</p> required <code>clip_min</code> <code>float | int | None</code> <p>Minimum clip value.</p> required <code>clip_max</code> <code>float | int | None</code> <p>Maximum clip value.</p> required <code>norm</code> <code>bool | None</code> <p>Whether to normalize data.</p> required <code>global_norm_min</code> <code>float | int | None</code> <p>Global minimum value for normalization (usually if data is part of bigger dataset).</p> required <code>global_norm_max</code> <code>float | int | None</code> <p>Global maximum value for normalization (usually if data is part of bigger dataset).</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Processed data.</p> Source code in <code>src/xai4mri/dataloader/transformation.py</code> <pre><code>def compress_and_norm(\n    data: np.ndarray,\n    clip_min: float | int | None,\n    clip_max: float | int | None,\n    norm: bool | None,\n    global_norm_min: float | int | None,\n    global_norm_max: float | int | None,\n) -&gt; np.ndarray:\n    \"\"\"\n    Clip, normalize, and/or compress data.\n\n    :param data: Data to be processed.\n    :param clip_min: Minimum clip value.\n    :param clip_max: Maximum clip value.\n    :param norm: Whether to normalize data.\n    :param global_norm_min: Global minimum value for normalization (usually if data is part of bigger dataset).\n    :param global_norm_max: Global maximum value for normalization (usually if data is part of bigger dataset).\n    :return: Processed data.\n    \"\"\"\n    # Check args\n    if type(clip_min) is not type(clip_max):\n        msg = f\"clip_min [{type(clip_min)}] and clip_max [{type(clip_max)}] must be of same type.\"\n        raise TypeError(msg)\n\n    compress = False  # init\n\n    # Clip\n    if clip_min is not None and clip_max is not None:\n        data = np.clip(a=data, a_min=clip_min, a_max=clip_max)\n        compress = True\n\n    # Normalize\n    norm = (global_norm_min is not None and global_norm_max is not None) or norm\n\n    if norm and _check_norm(data=data, compress=compress):\n        data = normalize(\n            array=data,\n            lower_bound=0,\n            upper_bound=255,\n            global_min=global_norm_min,\n            global_max=global_norm_max,\n        )\n    # Compress\n    if compress and norm:\n        data = np.round(data).astype(np.uint8)\n    return data\n</code></pre>"},{"location":"reference/dataloader/transformation/#xai4mri.dataloader.transformation.determine_min_max_clip","title":"determine_min_max_clip","text":"<pre><code>determine_min_max_clip(\n    data: ndarray, at_percentile: float = CLIP_PERCENTILE\n) -&gt; tuple[float, float]\n</code></pre> <p>Determine the min and max clip value for the given data.</p> <p>This clips the data at the given percentile. That is, all values below the min clip value are set to the min clip value, and all values above the max clip value are set to the max clip value.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>data as numpy array</p> required <code>at_percentile</code> <code>float</code> <p>percentile of the upperbound</p> <code>CLIP_PERCENTILE</code> <p>Returns:</p> Type Description <code>tuple[float, float]</code> <p>min and max clipping values</p> Source code in <code>src/xai4mri/dataloader/transformation.py</code> <pre><code>def determine_min_max_clip(data: np.ndarray, at_percentile: float = CLIP_PERCENTILE) -&gt; tuple[float, float]:\n    \"\"\"\n    Determine the min and max clip value for the given data.\n\n    This clips the data at the given percentile.\n    That is, all values below the min clip value are set to the min clip value,\n    and all values above the max clip value are set to the max clip value.\n\n    :param data: data as numpy array\n    :param at_percentile: percentile of the upperbound\n    :return: min and max clipping values\n    \"\"\"\n    bg = float(BG_VALUE)  # asserting background value at zero\n    d = data[data != bg]  # filter zeros / background, leave informative signal\n    n_dec = len(str(at_percentile)) - 1\n    max_clip_val = np.nanpercentile(d, q=at_percentile).round(decimals=n_dec)\n    min_clip_val = np.minimum(\n        bg,  # min_clip_val must be negative or zero\n        np.nanpercentile(d, q=100 - at_percentile).round(decimals=n_dec),\n    )\n    return min_clip_val, max_clip_val\n</code></pre>"},{"location":"reference/dataloader/transformation/#xai4mri.dataloader.transformation.file_to_ref_orientation","title":"file_to_ref_orientation","text":"<pre><code>file_to_ref_orientation(\n    image_file: Nifti1Image,\n    reference_space: str = GLOBAL_ORIENTATION_SPACE,\n) -&gt; Nifti1Image\n</code></pre> <p>Take a Nibabel NIfTI-file (not array) and return it reoriented to the (global) reference orientation space.</p> <p>Parameters:</p> Name Type Description Default <code>image_file</code> <code>Nifti1Image</code> <p>NIfTI image file.</p> required <code>reference_space</code> <code>str</code> <p>Reference orientation space. For example, 'LIA' (default) or 'RSP' (as in <code>ANTsPy</code>)</p> <code>GLOBAL_ORIENTATION_SPACE</code> <p>Returns:</p> Type Description <code>Nifti1Image</code> <p>reoriented NIfTI image.</p> Source code in <code>src/xai4mri/dataloader/transformation.py</code> <pre><code>def file_to_ref_orientation(\n    image_file: nib.Nifti1Image, reference_space: str = GLOBAL_ORIENTATION_SPACE\n) -&gt; nib.Nifti1Image:\n    \"\"\"\n    Take a Nibabel NIfTI-file (not array) and return it reoriented to the (global) reference orientation space.\n\n    :param image_file: NIfTI image file.\n    :param reference_space: Reference orientation space.\n                            For example, 'LIA' (default) or 'RSP' (as in `ANTsPy`)\n    :return: reoriented NIfTI image.\n    \"\"\"\n    orient_trans = get_orientation_transform(affine=image_file.affine, reference_space=reference_space)\n    return image_file.as_reoriented(orient_trans)\n</code></pre>"},{"location":"reference/dataloader/transformation/#xai4mri.dataloader.transformation.get_orientation_transform","title":"get_orientation_transform","text":"<pre><code>get_orientation_transform(\n    affine: ndarray,\n    reference_space: str = GLOBAL_ORIENTATION_SPACE,\n) -&gt; Nifti1Image\n</code></pre> <p>Get the orientation transform from a given affine matrix to the reference space.</p> <p>The resulting orientation transform (<code>orient_trans</code>) can be used to reorient an MRI to a reference space:</p> <pre><code>nibabel_image_file.as_reoriented(orient_trans)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>affine</code> <code>ndarray</code> <p>affine matrix</p> required <code>reference_space</code> <code>str</code> <p>reference space</p> <code>GLOBAL_ORIENTATION_SPACE</code> <p>Returns:</p> Type Description <code>Nifti1Image</code> <p>orientation transform</p> Source code in <code>src/xai4mri/dataloader/transformation.py</code> <pre><code>def get_orientation_transform(\n    affine: np.ndarray,\n    reference_space: str = GLOBAL_ORIENTATION_SPACE,\n) -&gt; nib.Nifti1Image:\n    \"\"\"\n    Get the orientation transform from a given affine matrix to the reference space.\n\n    The resulting orientation transform (`orient_trans`) can be used to reorient an MRI to a reference space:\n\n        nibabel_image_file.as_reoriented(orient_trans)\n\n    :param affine: affine matrix\n    :param reference_space: reference space\n    :return: orientation transform\n    \"\"\"\n    return nib.orientations.ornt_transform(\n        start_ornt=nib.orientations.io_orientation(affine),\n        end_ornt=nib.orientations.axcodes2ornt(reference_space),\n    )\n</code></pre>"},{"location":"reference/dataloader/transformation/#xai4mri.dataloader.transformation.mri_to_ref_orientation","title":"mri_to_ref_orientation","text":"<pre><code>mri_to_ref_orientation(\n    image: ndarray,\n    affine: ndarray,\n    reference_space: str = GLOBAL_ORIENTATION_SPACE,\n) -&gt; ndarray\n</code></pre> <p>Reorient an MRI array to a reference orientation space.</p> <p>Take an MRI array plus its corresponding affine matrix and return the MRI reoriented to the (global) reference space.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>ndarray</code> <p>MRI array.</p> required <code>affine</code> <code>ndarray</code> <p>Corresponding affine matrix of the MRI array.</p> required <code>reference_space</code> <code>str</code> <p>Reference orientation space. For example, 'LIA' (default) or 'RSP' (as in <code>ANTsPy</code>)</p> <code>GLOBAL_ORIENTATION_SPACE</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>reoriented MRI array.</p> Source code in <code>src/xai4mri/dataloader/transformation.py</code> <pre><code>def mri_to_ref_orientation(\n    image: np.ndarray,\n    affine: np.ndarray,\n    reference_space: str = GLOBAL_ORIENTATION_SPACE,\n) -&gt; np.ndarray:\n    \"\"\"\n    Reorient an MRI array to a reference orientation space.\n\n    Take an MRI array plus its corresponding affine matrix\n    and return the MRI reoriented to the (global) reference space.\n\n    :param image: MRI array.\n    :param affine: Corresponding affine matrix of the MRI array.\n    :param reference_space: Reference orientation space.\n                            For example, 'LIA' (default) or 'RSP' (as in `ANTsPy`)\n    :return: reoriented MRI array.\n    \"\"\"\n    # Create orientation transform object first\n    orient_trans = get_orientation_transform(affine=affine, reference_space=reference_space)\n    return nib.apply_orientation(image, orient_trans)\n</code></pre>"},{"location":"reference/dataloader/transformation/#xai4mri.dataloader.transformation.save_ants_warpers","title":"save_ants_warpers","text":"<pre><code>save_ants_warpers(\n    tx: dict[str, Any],\n    folder_path: str | Path,\n    image_name: str,\n) -&gt; None\n</code></pre> <p>Save warper files from <code>ANTsPy</code>'s <code>tx</code> object to the given <code>folder_path</code>.</p> <p>Parameters:</p> Name Type Description Default <code>tx</code> <code>dict[str, Any]</code> <p><code>ANTsPy</code> transformation object (via <code>ants.registration()</code>).</p> required <code>folder_path</code> <code>str | Path</code> <p>folder path to save warper files</p> required <code>image_name</code> <code>str</code> <p>Image name that will be used as prefix for the warper files.</p> required Source code in <code>src/xai4mri/dataloader/transformation.py</code> <pre><code>def save_ants_warpers(tx: dict[str, Any], folder_path: str | Path, image_name: str) -&gt; None:\n    \"\"\"\n    Save warper files from `ANTsPy`'s `tx` object to the given `folder_path`.\n\n    :param tx: `ANTsPy` transformation object (via `ants.registration()`).\n    :param folder_path: folder path to save warper files\n    :param image_name: Image name that will be used as prefix for the warper files.\n    \"\"\"\n    if \"fwdtransforms\" not in list(tx.keys()) or \"invtransforms\" not in list(tx.keys()):\n        msg = \"tx object misses forward and/or inverse transformation files.\"\n        raise ValueError(msg)\n\n    # Check whether linear transformation (\"Rigid\") or non-linear (\"SyN\")\n    linear = tx[\"fwdtransforms\"] == tx[\"invtransforms\"]\n\n    # # Set paths\n    # for forward warper\n    save_path_name_fwd = str(Path(folder_path, f\"{image_name}1Warp.nii.gz\"))\n    # for inverse warper\n    save_path_name_inv = str(Path(folder_path, f\"{image_name}1InverseWarp.nii.gz\"))\n    # # Save also linear transformation .mat file\n    save_path_name_mat = str(Path(folder_path, f\"{image_name}0GenericAffine.mat\"))\n\n    # # Copy warper files from the temporary tx folder file to new location\n    if linear:\n        copyfile(tx[\"fwdtransforms\"][0], save_path_name_mat)\n    else:\n        copyfile(tx[\"fwdtransforms\"][0], save_path_name_fwd)\n        copyfile(tx[\"invtransforms\"][1], save_path_name_inv)\n        copyfile(tx[\"invtransforms\"][0], save_path_name_mat)  # == ['fwdtransforms'][1]\n</code></pre>"},{"location":"reference/model/","title":"Index","text":""},{"location":"reference/model/#xai4mri.model","title":"model","text":"<p>Init <code>model</code> submodule of <code>xai4mri</code>.</p> <pre><code>Author: Simon M. Hofmann\nYears: 2023-2024\n</code></pre>"},{"location":"reference/model/#xai4mri.model.OutOfTheBoxModels","title":"OutOfTheBoxModels","text":"<p>               Bases: <code>Enum</code></p> <p>Enum class for out-of-the-box models for MRI-based predictions.</p> <p>Call the <code>show</code> method to get an overview of available models: <pre><code>OutOfTheBoxModels.show()\n</code></pre></p> <p>Get a model by selecting it</p> <pre><code>mrinet_creator = OutOfTheBoxModels.MRINET.value\nmrinet = mrinet_creator.create(...)\n\n# Alternatively, get the model by string\nsfcn = OutOfTheBoxModels(\"sfcn\").value.create(...)\n</code></pre>"},{"location":"reference/model/#xai4mri.model.OutOfTheBoxModels.default","title":"default  <code>classmethod</code>","text":"<pre><code>default()\n</code></pre> <p>Get the default model, which is <code>MRInet</code>.</p> Source code in <code>src/xai4mri/model/mrinets.py</code> <pre><code>@classmethod\ndef default(cls):\n    \"\"\"Get the default model, which is `MRInet`.\"\"\"\n    return cls.MRINET\n</code></pre>"},{"location":"reference/model/#xai4mri.model.OutOfTheBoxModels.pretrained_models","title":"pretrained_models","text":"<pre><code>pretrained_models()\n</code></pre> <p>Get the pretrained models for the model.</p> <p>Get information about pretrained <code>MRInet</code> models</p> <pre><code>OutOfTheBoxModels.MRINET.pretrained_models().show()\n</code></pre> <p>Ultimately, this is just a small wrapper avoiding calling the <code>value</code> attribute.</p> Source code in <code>src/xai4mri/model/mrinets.py</code> <pre><code>def pretrained_models(self):\n    \"\"\"\n    Get the pretrained models for the model.\n\n    !!! example \"Get information about pretrained `MRInet` models\"\n        ```python\n        OutOfTheBoxModels.MRINET.pretrained_models().show()\n        ```\n    Ultimately, this is just a small wrapper avoiding calling the `value` attribute.\n    \"\"\"\n    return self.value.pretrained_models()\n</code></pre>"},{"location":"reference/model/#xai4mri.model.OutOfTheBoxModels.reference","title":"reference","text":"<pre><code>reference()\n</code></pre> <p>Get the reference for the model.</p> <p>Get the reference for <code>MRInet</code></p> <pre><code>OutOfTheBoxModels.MRINET.reference()\n</code></pre> <p>Ultimately, this is just a small wrapper avoiding calling the <code>value</code> attribute.</p> Source code in <code>src/xai4mri/model/mrinets.py</code> <pre><code>def reference(self):\n    \"\"\"\n    Get the reference for the model.\n\n    !!! example \"Get the reference for `MRInet`\"\n        ```python\n        OutOfTheBoxModels.MRINET.reference()\n        ```\n    Ultimately, this is just a small wrapper avoiding calling the `value` attribute.\n    \"\"\"\n    return self.value.reference()\n</code></pre>"},{"location":"reference/model/#xai4mri.model.OutOfTheBoxModels.show","title":"show  <code>classmethod</code>","text":"<pre><code>show()\n</code></pre> <p>Show available models.</p> Source code in <code>src/xai4mri/model/mrinets.py</code> <pre><code>@classmethod\ndef show(cls):\n    \"\"\"Show available models.\"\"\"\n    return print(*[(model, model.reference()) for model in cls], sep=\"\\n\")\n</code></pre>"},{"location":"reference/model/#xai4mri.model.analyze_model","title":"analyze_model","text":"<pre><code>analyze_model(\n    model: Model,\n    ipt: ndarray,\n    norm: bool,\n    analyzer_type: str = \"lrp.sequential_preset_a\",\n    neuron_selection: int | None = None,\n    **kwargs\n) -&gt; ndarray\n</code></pre> <p>Analyze the prediction of a model with respect to a given input.</p> <p>Produce an analyzer map ('heatmap') for a given model and input image. The heatmap indicates the relevance of each pixel w.r.t. the model's prediction.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Model</code> <p>Deep learning model.</p> required <code>ipt</code> <code>ndarray</code> <p>Input image to model, shape: <code>[batch_size: = 1, x, y, z, channels: = 1]</code>.</p> required <code>norm</code> <code>bool</code> <p>True: normalize the computed analyzer map to [-1, 1].</p> required <code>analyzer_type</code> <code>str</code> <p>Type of model analyzers [default: \"lrp.sequential_preset_a\" for ConvNets]. Check documentation of <code>iNNvestigate</code> for different types of analyzers.</p> <code>'lrp.sequential_preset_a'</code> <code>neuron_selection</code> <code>int | None</code> <p>Index of the model's output neuron [int], whose activity is to be analyzed; Or take the 'max_activation' neuron [if <code>None</code>]</p> <code>None</code> <code>kwargs</code> <p>Additional keyword arguments for the <code>innvestigate.create_analyzer()</code> function.</p> <code>{}</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The computed analyzer map.</p> Source code in <code>src/xai4mri/model/interpreter.py</code> <pre><code>def analyze_model(\n    model: keras.Model,\n    ipt: np.ndarray,\n    norm: bool,\n    analyzer_type: str = \"lrp.sequential_preset_a\",\n    neuron_selection: int | None = None,\n    **kwargs,\n) -&gt; np.ndarray:\n    \"\"\"\n    Analyze the prediction of a model with respect to a given input.\n\n    Produce an analyzer map ('heatmap') for a given model and input image.\n    The heatmap indicates the relevance of each pixel w.r.t. the model's prediction.\n\n    :param model: Deep learning model.\n    :param ipt: Input image to model, shape: `[batch_size: = 1, x, y, z, channels: = 1]`.\n    :param norm: True: normalize the computed analyzer map to [-1, 1].\n    :param analyzer_type: Type of model analyzers [default: \"lrp.sequential_preset_a\" for ConvNets].\n                          Check documentation of `iNNvestigate` for different types of analyzers.\n    :param neuron_selection: Index of the model's output neuron [int], whose activity is to be analyzed;\n                             Or take the 'max_activation' neuron [if `None`]\n    :param kwargs: Additional keyword arguments for the `innvestigate.create_analyzer()` function.\n    :return: The computed analyzer map.\n    \"\"\"\n    # Create analyzer\n    disable_model_checks = kwargs.pop(\"disable_model_checks\", True)\n    analyzer = innvestigate.create_analyzer(\n        name=analyzer_type,\n        model=model,\n        disable_model_checks=disable_model_checks,\n        neuron_selection_mode=\"index\" if isinstance(neuron_selection, int) else \"max_activation\",\n        **kwargs,\n    )\n\n    # Apply analyzer w.r.t. maximum activated output-neuron\n    a = analyzer.analyze(ipt, neuron_selection=neuron_selection)\n\n    if norm:\n        # Normalize between [-1, 1]\n        a /= np.max(np.abs(a))\n\n    return a\n</code></pre>"},{"location":"reference/model/#xai4mri.model.get_model","title":"get_model","text":"<pre><code>get_model(\n    model_type: OutOfTheBoxModels | str, **kwargs\n) -&gt; Sequential | None\n</code></pre> <p>Get a freshly initiated out-of-the-box model.</p> <p>Example of how to get an <code>MRInet</code> model</p> <pre><code>mrinet = get_model(\n             model_type=OutOfTheBoxModels.MRINET,\n             name=\"MyMRInet\",\n             n_classes=False,\n             input_shape=(91, 109, 91),\n             )\n\n# Alternatively, get the model by string\nsfcn = get_model(\n           model_type=\"sfcn\",\n           name=\"MySFCN\",\n           n_classes=40,\n           input_shape=(160, 192, 160),\n           )\n\nThis is a wrapper for the `create` method of the model creator classes.\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>model_type</code> <code>OutOfTheBoxModels | str</code> <p>model of type <code>OutOfTheBoxModels</code> or <code>string</code> (e.g., 'mrinet')</p> required <code>kwargs</code> <p>keyword arguments for model creation</p> <code>{}</code> Source code in <code>src/xai4mri/model/mrinets.py</code> <pre><code>def get_model(model_type: OutOfTheBoxModels | str, **kwargs) -&gt; keras.Sequential | None:\n    \"\"\"\n    Get a freshly initiated out-of-the-box model.\n\n    !!! example \"Example of how to get an `MRInet` model\"\n        ```python\n        mrinet = get_model(\n                     model_type=OutOfTheBoxModels.MRINET,\n                     name=\"MyMRInet\",\n                     n_classes=False,\n                     input_shape=(91, 109, 91),\n                     )\n\n        # Alternatively, get the model by string\n        sfcn = get_model(\n                   model_type=\"sfcn\",\n                   name=\"MySFCN\",\n                   n_classes=40,\n                   input_shape=(160, 192, 160),\n                   )\n\n        This is a wrapper for the `create` method of the model creator classes.\n        ```\n    :param model_type: model of type `OutOfTheBoxModels` or `string` (e.g., 'mrinet')\n    :param kwargs: keyword arguments for model creation\n    \"\"\"\n    if OutOfTheBoxModels(model_type) == OutOfTheBoxModels.MRINET:\n        return MRInet.create(**kwargs)\n    if OutOfTheBoxModels(model_type) == OutOfTheBoxModels.SFCN:\n        return SFCN.create(**kwargs)\n    return None\n</code></pre>"},{"location":"reference/model/#xai4mri.model.mono_phase_model_training","title":"mono_phase_model_training","text":"<pre><code>mono_phase_model_training(\n    model: Sequential,\n    epochs: int,\n    data: BaseDataSet,\n    target: str,\n    model_parent_path: str | Path,\n    split_dict: dict | None = None,\n    callbacks: list[Callback] | None = None,\n    **kwargs\n) -&gt; Sequential | None\n</code></pre> <p>Train / finetune all model weights at once.</p> <p>This simply trains the model on the provided dataset for the given number of epochs.</p> <p>When used for transfer learning</p> <p>This is a naive approach to transfer learning, and can lead to issues such as catastrophic forgetting.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Sequential</code> <p>Compiled <code>Keras</code> model to be trained on the provided dataset.</p> required <code>epochs</code> <code>int</code> <p>Number of training epochs.</p> required <code>data</code> <code>BaseDataSet</code> <p>Dataset for training and evaluation. This must be a subclass of <code>BaseDataSet</code>.</p> required <code>target</code> <code>str</code> <p>Variable to be predicted. This must be in the 'study_table<code>of the dataset (</code>data').</p> required <code>model_parent_path</code> <code>str | Path</code> <p>The path to the parent folder of the given model, where the model will be saved.</p> required <code>split_dict</code> <code>dict | None</code> <p>Data split dictionary for training, validation, and test data.</p> <code>None</code> <code>callbacks</code> <code>list[Callback] | None</code> <p>A list of <code>Keras</code>'s <code>callbacks</code> (except of <code>ModelCheckpoint</code>).</p> <code>None</code> <code>kwargs</code> <p>Additional keyword arguments for <code>data.create_data_split()</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Sequential | None</code> <p>Trained model.</p> Source code in <code>src/xai4mri/model/transfer.py</code> <pre><code>def mono_phase_model_training(\n    model: keras.Sequential,\n    epochs: int,\n    data: BaseDataSet,\n    target: str,\n    model_parent_path: str | Path,\n    split_dict: dict | None = None,\n    callbacks: list[keras.callbacks.Callback] | None = None,\n    **kwargs,\n) -&gt; keras.Sequential | None:\n    \"\"\"\n    Train / finetune all model weights at once.\n\n    This simply trains the model on the provided dataset for the given number of epochs.\n\n    !!! note \"When used for transfer learning\"\n        This is a naive approach to transfer learning, and can lead to issues such as catastrophic forgetting.\n\n    :param model: Compiled `Keras` model to be trained on the provided dataset.\n    :param epochs: Number of training epochs.\n    :param data: Dataset for training and evaluation. This must be a subclass of `BaseDataSet`.\n    :param target: Variable to be predicted. This must be in the 'study_table` of the dataset (`data').\n    :param model_parent_path: The path to the parent folder of the given model, where the model will be saved.\n    :param split_dict: Data split dictionary for training, validation, and test data.\n    :param callbacks: A list of `Keras`'s `callbacks` (except of `ModelCheckpoint`).\n    :param kwargs: Additional keyword arguments for `data.create_data_split()`.\n    :return: Trained model.\n    \"\"\"\n    # Set path to model and split dictionary\n    path_to_model = Path(model_parent_path) / model.name\n    path_to_checkpoints = path_to_model / \"checkpoints\"\n    path_to_split_dict = path_to_model / f\"{model.name}_split_dict\"\n\n    # Check if model has been trained already\n    if list(path_to_checkpoints.glob(\"*\")):\n        cprint(string=\"Model has been trained already. Skipping training.\", col=\"y\")\n        return None\n\n    # Create data splits\n    split_dict, train_data_gen, val_data_gen, test_data_gen = data.create_data_split(\n        target=target,\n        batch_size=kwargs.pop(\"batch_size\", 1),\n        split_ratio=kwargs.pop(\"split_ratio\", (0.8, 0.1, 0.1)),\n        split_dict=split_dict,\n    )\n\n    # Define callbacks\n    callbacks = [] if callbacks is None else callbacks\n    for c in callbacks:\n        if isinstance(c, keras.callbacks.ModelCheckpoint):\n            break\n    else:\n        callbacks.append(\n            keras.callbacks.ModelCheckpoint(\n                filepath=path_to_checkpoints / \"cp-{epoch:04d}.ckpt\",\n                save_weights_only=True,  # TODO: revisit  # noqa: FIX002\n                monitor=\"val_loss\",\n                mode=\"auto\",\n                save_best_only=True,  # TODO: revisit  # noqa: FIX002\n                save_freq=\"epoch\",\n            )\n        )\n\n    # Train model\n    model.fit(\n        x=train_data_gen,\n        epochs=epochs,\n        validation_data=val_data_gen,\n        callbacks=callbacks,\n    )\n\n    # Save split dictionary and model\n    data.save_split_dict(save_path=path_to_split_dict)\n    model.save(path_to_model / f\"{model.name}.h5\")\n\n    # Model evaluation\n    model.evaluate(test_data_gen)\n\n    return model\n</code></pre>"},{"location":"reference/model/interpreter/","title":"<code class=\"doc-symbol doc-symbol-nav doc-symbol-module\"></code> interpreter","text":""},{"location":"reference/model/interpreter/#xai4mri.model.interpreter","title":"interpreter","text":"<p>Model analyzer using explainable AI (XAI) methods.</p> <p>Functionality is built around the <code>iNNvestigate</code> toolbox to analyze predictions of deep learning models.</p> <pre><code>Author: Simon M. Hofmann\nYears: 2023-2024\n</code></pre>"},{"location":"reference/model/interpreter/#xai4mri.model.interpreter.analyze_model","title":"analyze_model","text":"<pre><code>analyze_model(\n    model: Model,\n    ipt: ndarray,\n    norm: bool,\n    analyzer_type: str = \"lrp.sequential_preset_a\",\n    neuron_selection: int | None = None,\n    **kwargs\n) -&gt; ndarray\n</code></pre> <p>Analyze the prediction of a model with respect to a given input.</p> <p>Produce an analyzer map ('heatmap') for a given model and input image. The heatmap indicates the relevance of each pixel w.r.t. the model's prediction.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Model</code> <p>Deep learning model.</p> required <code>ipt</code> <code>ndarray</code> <p>Input image to model, shape: <code>[batch_size: = 1, x, y, z, channels: = 1]</code>.</p> required <code>norm</code> <code>bool</code> <p>True: normalize the computed analyzer map to [-1, 1].</p> required <code>analyzer_type</code> <code>str</code> <p>Type of model analyzers [default: \"lrp.sequential_preset_a\" for ConvNets]. Check documentation of <code>iNNvestigate</code> for different types of analyzers.</p> <code>'lrp.sequential_preset_a'</code> <code>neuron_selection</code> <code>int | None</code> <p>Index of the model's output neuron [int], whose activity is to be analyzed; Or take the 'max_activation' neuron [if <code>None</code>]</p> <code>None</code> <code>kwargs</code> <p>Additional keyword arguments for the <code>innvestigate.create_analyzer()</code> function.</p> <code>{}</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The computed analyzer map.</p> Source code in <code>src/xai4mri/model/interpreter.py</code> <pre><code>def analyze_model(\n    model: keras.Model,\n    ipt: np.ndarray,\n    norm: bool,\n    analyzer_type: str = \"lrp.sequential_preset_a\",\n    neuron_selection: int | None = None,\n    **kwargs,\n) -&gt; np.ndarray:\n    \"\"\"\n    Analyze the prediction of a model with respect to a given input.\n\n    Produce an analyzer map ('heatmap') for a given model and input image.\n    The heatmap indicates the relevance of each pixel w.r.t. the model's prediction.\n\n    :param model: Deep learning model.\n    :param ipt: Input image to model, shape: `[batch_size: = 1, x, y, z, channels: = 1]`.\n    :param norm: True: normalize the computed analyzer map to [-1, 1].\n    :param analyzer_type: Type of model analyzers [default: \"lrp.sequential_preset_a\" for ConvNets].\n                          Check documentation of `iNNvestigate` for different types of analyzers.\n    :param neuron_selection: Index of the model's output neuron [int], whose activity is to be analyzed;\n                             Or take the 'max_activation' neuron [if `None`]\n    :param kwargs: Additional keyword arguments for the `innvestigate.create_analyzer()` function.\n    :return: The computed analyzer map.\n    \"\"\"\n    # Create analyzer\n    disable_model_checks = kwargs.pop(\"disable_model_checks\", True)\n    analyzer = innvestigate.create_analyzer(\n        name=analyzer_type,\n        model=model,\n        disable_model_checks=disable_model_checks,\n        neuron_selection_mode=\"index\" if isinstance(neuron_selection, int) else \"max_activation\",\n        **kwargs,\n    )\n\n    # Apply analyzer w.r.t. maximum activated output-neuron\n    a = analyzer.analyze(ipt, neuron_selection=neuron_selection)\n\n    if norm:\n        # Normalize between [-1, 1]\n        a /= np.max(np.abs(a))\n\n    return a\n</code></pre>"},{"location":"reference/model/mrinets/","title":"<code class=\"doc-symbol doc-symbol-nav doc-symbol-module\"></code> mrinets","text":""},{"location":"reference/model/mrinets/#xai4mri.model.mrinets","title":"mrinets","text":"<p>Train &amp; load deep learning models for MRI-based predictions.</p> <p>This module provides a set of out-of-the-box models for MRI-based predictions. The models are designed for 3D MRI data and can be used for regression or classification tasks. Moreover, there are pretrained models available for some model architectures.</p> <p>Models are built on top of the <code>TensorFlow</code> <code>Keras</code> API. This is necessary to ensure compatibility with <code>iNNvestigate</code> for model interpretability.</p> <pre><code>Author: Simon M. Hofmann\nYears: 2022-2024\n</code></pre>"},{"location":"reference/model/mrinets/#xai4mri.model.mrinets.MRInet","title":"MRInet","text":"<p>               Bases: <code>_ModelCreator</code></p> <p><code>MRInet</code> model creator.</p> <p><code>MRInet</code> is the basemodel architecture (3D-ConvNet) used within the multi-level ensembles in Hofmann et al. (2022, NeuroImage). The models were trained to predict age from MR images of different sequences (<code>T1</code>, <code>FLAIR</code>, <code>SWI</code>) in the <code>LIFE Adult</code> study.</p> <p>This model creator class provides a hard-coded Keras implementation of the 3D-CNN model. Creating a model with this class is as simple as calling the <code>create</code> method. This will return a fresh (i.e., untrained) and compiled <code>Keras</code> model ready to be trained:</p> <p>Create a new instance of <code>MRInet</code></p> <pre><code># Create a new instance of MRInet\nmrinet = MRInet.create(name=\"MyMRInet\", n_classes=False, input_shape=(91, 109, 91))\n\n# Train on MRI dataset\nmrinet.fit(X_train, y_train, ...)\n</code></pre> <p>Pretrained models are available for <code>T1</code>, <code>FLAIR</code>, and <code>SWI</code> images.</p> <p>Get an overview of pretrained models by calling:</p> <pre><code>MRInet.pretrained_models().show()\n</code></pre>"},{"location":"reference/model/mrinets/#xai4mri.model.mrinets.MRInet.create","title":"create  <code>staticmethod</code>","text":"<pre><code>create(\n    name: str,\n    n_classes: bool | None | int,\n    input_shape: tuple[int, int, int],\n    learning_rate: float = 0.0005,\n    target_bias: float | None = None,\n    leaky_relu: bool = False,\n    batch_norm: bool = False,\n) -&gt; Sequential\n</code></pre> <p>Create a new instance of <code>MRInet</code>, a 3D-convolutional neural network (CNN) for predictions on MRIs.</p> <p>This is a hard-coded Keras implementation of 3D-CNN model as reported in Hofmann et al. (2022, NeuroImage).</p> <p>The model can be trained for regression (<code>n_classes=False</code>) or classification (<code>n_classes: int &gt;= 2</code>) tasks.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Model name, which, for instance, could refer to the project it is applied for.</p> required <code>target_bias</code> <code>float | None</code> <p>Model output bias. For classification tasks with this can be left blank [<code>None</code>]. For regression tasks, it is recommended to set this bias to the average of the prediction target distribution in the dataset.</p> <code>None</code> <code>input_shape</code> <code>tuple[int, int, int]</code> <p>Shape of the input to the model. This should be the shape of a single MRI (e.g., (91, 91, 109).</p> required <code>learning_rate</code> <code>float</code> <p>Learning rate which is used for the model's optimizer (here, <code>Adam</code>).</p> <code>0.0005</code> <code>batch_norm</code> <code>bool</code> <p>Use batch normalization or not. Batch normalization should only be used if the model is fed with larger batches. For model interpretability provided by <code>xai4mri</code>, it is recommended to not use batch normalization.</p> <code>False</code> <code>leaky_relu</code> <code>bool</code> <p>Using leaky or vanilla ReLU activation functions. Leaky ReLU is recommended for better performance. However, <code>iNNvestigate</code>, which is used for model interpretability, does not support leaky ReLU currently.</p> <code>False</code> <code>n_classes</code> <code>bool | None | int</code> <p>Number of classes. For regression tasks set to <code>False</code> or <code>0</code>; For classification tasks, provide integer &gt;= 2.</p> required <p>Returns:</p> Type Description <code>Sequential</code> <p>Compiled <code>MRInet</code> model (based on <code>Keras</code>), ready to be trained.</p> Source code in <code>src/xai4mri/model/mrinets.py</code> <pre><code>@staticmethod\ndef create(\n    name: str,\n    n_classes: bool | None | int,\n    input_shape: tuple[int, int, int],\n    learning_rate: float = 5e-4,\n    target_bias: float | None = None,\n    leaky_relu: bool = False,\n    batch_norm: bool = False,\n) -&gt; keras.Sequential:\n    \"\"\"\n    Create a new instance of `MRInet`, a 3D-convolutional neural network (CNN) for predictions on MRIs.\n\n    This is a hard-coded Keras implementation of 3D-CNN model as reported in\n    [Hofmann et al. (2022, *NeuroImage*)](https://doi.org/10.1016/j.neuroimage.2022.119504).\n\n    The model can be trained for regression (`n_classes=False`) or classification (`n_classes: int &gt;= 2`) tasks.\n\n    :param name: Model name, which, for instance, could refer to the project it is applied for.\n    :param target_bias: Model output bias.\n                        For classification tasks with this can be left blank [`None`].\n                        For regression tasks, it is recommended to set this bias to the average of the\n                        prediction target distribution in the dataset.\n    :param input_shape: Shape of the input to the model.\n                        This should be the shape of a single MRI (e.g., (91, 91, 109).\n    :param learning_rate: Learning rate which is used for the model's optimizer (here, `Adam`).\n    :param batch_norm: Use batch normalization or not.\n                       Batch normalization should only be used if the model is fed with larger batches.\n                       For model interpretability provided by `xai4mri`,\n                       it is recommended to not use batch normalization.\n    :param leaky_relu: Using leaky or vanilla ReLU activation functions.\n                       Leaky ReLU is recommended for better performance.\n                       However, `iNNvestigate`, which is used for model interpretability,\n                       does not support leaky ReLU currently.\n    :param n_classes: Number of classes.\n                      For regression tasks set to `False` or `0`;\n                      For classification tasks, provide integer &gt;= 2.\n    :return: Compiled `MRInet` model (based on `Keras`), ready to be trained.\n    \"\"\"\n    if target_bias is not None:\n        cprint(string=f\"\\nGiven target bias is {target_bias:.3f}\\n\", col=\"y\")\n\n    actfct = None if leaky_relu and not batch_norm else \"relu\"\n\n    _check_n_classes(n_classes=n_classes)\n\n    k_model = keras.Sequential(name=name)  # OR: Sequential([keras.layer.Conv3d(....), layer...])\n\n    # 3D-Conv\n    if batch_norm:\n        k_model.add(keras.layers.BatchNormalization(input_shape=(*input_shape, 1)))\n        k_model.add(keras.layers.Conv3D(filters=16, kernel_size=(3, 3, 3), padding=\"SAME\", activation=actfct))\n    else:\n        k_model.add(\n            keras.layers.Conv3D(\n                filters=16,\n                kernel_size=(3, 3, 3),\n                padding=\"SAME\",\n                activation=actfct,\n                input_shape=(*input_shape, 1),\n            )\n        )\n        # auto-add batch:None, last: channels\n    if leaky_relu:\n        k_model.add(keras.layers.LeakyReLU(alpha=0.2))  # lrelu\n    k_model.add(keras.layers.MaxPool3D(pool_size=(3, 3, 3), strides=(2, 2, 2), padding=\"SAME\"))\n\n    if batch_norm:\n        k_model.add(keras.layers.BatchNormalization())\n    k_model.add(keras.layers.Conv3D(filters=16, kernel_size=(3, 3, 3), padding=\"SAME\", activation=actfct))\n    if leaky_relu:\n        k_model.add(keras.layers.LeakyReLU(alpha=0.2))\n    k_model.add(keras.layers.MaxPool3D(pool_size=(3, 3, 3), strides=(2, 2, 2), padding=\"SAME\"))\n\n    if batch_norm:\n        k_model.add(keras.layers.BatchNormalization())\n    k_model.add(keras.layers.Conv3D(filters=32, kernel_size=(3, 3, 3), padding=\"SAME\", activation=actfct))\n    if leaky_relu:\n        k_model.add(keras.layers.LeakyReLU(alpha=0.2))\n    k_model.add(keras.layers.MaxPool3D(pool_size=(3, 3, 3), strides=(2, 2, 2), padding=\"SAME\"))\n\n    if batch_norm:\n        k_model.add(keras.layers.BatchNormalization())\n    k_model.add(keras.layers.Conv3D(filters=64, kernel_size=(3, 3, 3), padding=\"SAME\", activation=actfct))\n    if leaky_relu:\n        k_model.add(keras.layers.LeakyReLU(alpha=0.2))\n    k_model.add(keras.layers.MaxPool3D(pool_size=(3, 3, 3), strides=(2, 2, 2), padding=\"SAME\"))\n\n    # 3D-Conv (1x1x1)\n    if batch_norm:\n        k_model.add(keras.layers.BatchNormalization())\n    k_model.add(keras.layers.Conv3D(filters=32, kernel_size=(1, 1, 1), padding=\"SAME\", activation=actfct))\n    if leaky_relu:\n        k_model.add(keras.layers.LeakyReLU(alpha=0.2))\n\n    k_model.add(keras.layers.MaxPool3D(pool_size=(3, 3, 3), strides=(2, 2, 2), padding=\"SAME\"))\n\n    if batch_norm:\n        k_model.add(keras.layers.BatchNormalization())\n\n    # FC\n    k_model.add(keras.layers.Flatten())\n    k_model.add(keras.layers.Dropout(rate=0.5))\n    k_model.add(keras.layers.Dense(units=64, activation=actfct))\n    if leaky_relu:\n        k_model.add(keras.layers.LeakyReLU(alpha=0.2))\n\n    # Output\n    if n_classes:\n        k_model.add(\n            keras.layers.Dense(\n                units=n_classes,\n                activation=\"softmax\",  # in binary case. also: 'sigmoid'\n                use_bias=False,\n            )\n        )  # default: True\n\n    else:\n        k_model.add(\n            keras.layers.Dense(\n                units=1,\n                activation=\"linear\",\n                # add target bias (recommended: mean of target distribution)\n                use_bias=True,\n                bias_initializer=keras.initializers.Constant(value=target_bias) if target_bias else \"zeros\",\n            )\n        )\n\n    # Compile\n    k_model.compile(\n        optimizer=keras.optimizers.Adam(learning_rate),  # =\"adam\",\n        loss=\"mse\",\n        metrics=[\"accuracy\"] if n_classes else [\"mae\"],\n    )\n\n    # Summary\n    k_model.summary()\n\n    return k_model\n</code></pre>"},{"location":"reference/model/mrinets/#xai4mri.model.mrinets.MRInet.pretrained_models","title":"pretrained_models  <code>staticmethod</code>","text":"<pre><code>pretrained_models() -&gt; type[PretrainedModelsMRInet]\n</code></pre> <p>Return enum of pretrained <code>MRInet</code> models.</p> <p>Call the <code>show</code> method to get an overview of available pretrained models:</p> <pre><code>MRInet.pretrained_models().show()\n</code></pre> Source code in <code>src/xai4mri/model/mrinets.py</code> <pre><code>@staticmethod\ndef pretrained_models() -&gt; type[PretrainedModelsMRInet]:\n    \"\"\"\n    Return enum of pretrained `MRInet` models.\n\n    !!! tip \"Call the `show` method to get an overview of available pretrained models:\"\n        ```python\n        MRInet.pretrained_models().show()\n        ```\n    \"\"\"\n    return PretrainedModelsMRInet\n</code></pre>"},{"location":"reference/model/mrinets/#xai4mri.model.mrinets.MRInet.reference","title":"reference  <code>staticmethod</code>","text":"<pre><code>reference() -&gt; str\n</code></pre> <p>Get the reference for the <code>MRInet</code> model.</p> Source code in <code>src/xai4mri/model/mrinets.py</code> <pre><code>@staticmethod\ndef reference() -&gt; str:\n    \"\"\"Get the reference for the `MRInet` model.\"\"\"\n    return \"Hofmann et al. (2022). NeuroImage. https://doi.org/10.1016/j.neuroimage.2022.119504\"\n</code></pre>"},{"location":"reference/model/mrinets/#xai4mri.model.mrinets.OutOfTheBoxModels","title":"OutOfTheBoxModels","text":"<p>               Bases: <code>Enum</code></p> <p>Enum class for out-of-the-box models for MRI-based predictions.</p> <p>Call the <code>show</code> method to get an overview of available models: <pre><code>OutOfTheBoxModels.show()\n</code></pre></p> <p>Get a model by selecting it</p> <pre><code>mrinet_creator = OutOfTheBoxModels.MRINET.value\nmrinet = mrinet_creator.create(...)\n\n# Alternatively, get the model by string\nsfcn = OutOfTheBoxModels(\"sfcn\").value.create(...)\n</code></pre>"},{"location":"reference/model/mrinets/#xai4mri.model.mrinets.OutOfTheBoxModels.default","title":"default  <code>classmethod</code>","text":"<pre><code>default()\n</code></pre> <p>Get the default model, which is <code>MRInet</code>.</p> Source code in <code>src/xai4mri/model/mrinets.py</code> <pre><code>@classmethod\ndef default(cls):\n    \"\"\"Get the default model, which is `MRInet`.\"\"\"\n    return cls.MRINET\n</code></pre>"},{"location":"reference/model/mrinets/#xai4mri.model.mrinets.OutOfTheBoxModels.pretrained_models","title":"pretrained_models","text":"<pre><code>pretrained_models()\n</code></pre> <p>Get the pretrained models for the model.</p> <p>Get information about pretrained <code>MRInet</code> models</p> <pre><code>OutOfTheBoxModels.MRINET.pretrained_models().show()\n</code></pre> <p>Ultimately, this is just a small wrapper avoiding calling the <code>value</code> attribute.</p> Source code in <code>src/xai4mri/model/mrinets.py</code> <pre><code>def pretrained_models(self):\n    \"\"\"\n    Get the pretrained models for the model.\n\n    !!! example \"Get information about pretrained `MRInet` models\"\n        ```python\n        OutOfTheBoxModels.MRINET.pretrained_models().show()\n        ```\n    Ultimately, this is just a small wrapper avoiding calling the `value` attribute.\n    \"\"\"\n    return self.value.pretrained_models()\n</code></pre>"},{"location":"reference/model/mrinets/#xai4mri.model.mrinets.OutOfTheBoxModels.reference","title":"reference","text":"<pre><code>reference()\n</code></pre> <p>Get the reference for the model.</p> <p>Get the reference for <code>MRInet</code></p> <pre><code>OutOfTheBoxModels.MRINET.reference()\n</code></pre> <p>Ultimately, this is just a small wrapper avoiding calling the <code>value</code> attribute.</p> Source code in <code>src/xai4mri/model/mrinets.py</code> <pre><code>def reference(self):\n    \"\"\"\n    Get the reference for the model.\n\n    !!! example \"Get the reference for `MRInet`\"\n        ```python\n        OutOfTheBoxModels.MRINET.reference()\n        ```\n    Ultimately, this is just a small wrapper avoiding calling the `value` attribute.\n    \"\"\"\n    return self.value.reference()\n</code></pre>"},{"location":"reference/model/mrinets/#xai4mri.model.mrinets.OutOfTheBoxModels.show","title":"show  <code>classmethod</code>","text":"<pre><code>show()\n</code></pre> <p>Show available models.</p> Source code in <code>src/xai4mri/model/mrinets.py</code> <pre><code>@classmethod\ndef show(cls):\n    \"\"\"Show available models.\"\"\"\n    return print(*[(model, model.reference()) for model in cls], sep=\"\\n\")\n</code></pre>"},{"location":"reference/model/mrinets/#xai4mri.model.mrinets.PretrainedMRInetFLAIR","title":"PretrainedMRInetFLAIR  <code>dataclass</code>","text":"<pre><code>PretrainedMRInetFLAIR(\n    name: str = \"flair_model\",\n    url: str = \"https://keeper.mpdl.mpg.de/f/8481f5906f3d4192ab12/?dl=1\",\n)\n</code></pre> <p>               Bases: <code>_PretrainedMRInet</code></p> <p>Pretrained <code>MRInet</code> model for <code>FLAIR</code> images.</p> <p>This is a basemodel in the <code>FLAIR</code> sub-ensemble as reported in Hofmann et al. (2022, NeuroImage).</p> <p>The training data stem from the <code>LIFE Adult</code> study, and were normalized and registered to the <code>T1w</code>-<code>FreeSurfer</code> file (<code>brain.finalsurfs.mgz</code>), and subsequently pruned to <code>(198, 198, 198)</code> voxels (for more details, see Hofmann et al. (2022, NeuroImage).</p>"},{"location":"reference/model/mrinets/#xai4mri.model.mrinets.PretrainedMRInetFLAIR.load_model","title":"load_model  <code>classmethod</code>","text":"<pre><code>load_model(\n    parent_folder: str | Path,\n    custom_objects: T | None = None,\n    compile_model: bool = False,\n) -&gt; Sequential\n</code></pre> <p>Load a pretrained <code>MRInet</code> model.</p> <p>If the model is not present on the local machine, it will be downloaded from the server and saved in the provided parent folder.</p> <p>Parameters:</p> Name Type Description Default <code>parent_folder</code> <code>str | Path</code> <p>Path to parent folder of the model.</p> required <code>custom_objects</code> <code>T | None</code> <p>Custom objects to load (e.g., loss functions).</p> <code>None</code> <code>compile_model</code> <code>bool</code> <p>Compile the model or not.</p> <code>False</code> <p>Returns:</p> Type Description <code>Sequential</code> <p>Pretrained <code>MRInet</code> model.</p> Source code in <code>src/xai4mri/model/mrinets.py</code> <pre><code>@classmethod\ndef load_model(\n    cls, parent_folder: str | Path, custom_objects: T | None = None, compile_model: bool = False\n) -&gt; keras.Sequential:\n    \"\"\"\n    Load a pretrained `MRInet` model.\n\n    If the model is not present on the local machine, it will be downloaded from the server\n    and saved in the provided parent folder.\n\n    :param parent_folder: Path to parent folder of the model.\n    :param custom_objects: Custom objects to load (e.g., loss functions).\n    :param compile_model: Compile the model or not.\n    :return: Pretrained `MRInet` model.\n    \"\"\"\n    return _load_pretrained_mrinet_model(\n        pretrained_model_type=cls,\n        parent_folder=parent_folder,\n        custom_objects=custom_objects,\n        compile_model=compile_model,\n    )\n</code></pre>"},{"location":"reference/model/mrinets/#xai4mri.model.mrinets.PretrainedMRInetSWI","title":"PretrainedMRInetSWI  <code>dataclass</code>","text":"<pre><code>PretrainedMRInetSWI(\n    name: str = \"swi_model\",\n    url: str = \"https://keeper.mpdl.mpg.de/f/f53d43b723274687b6e2/?dl=1\",\n)\n</code></pre> <p>               Bases: <code>_PretrainedMRInet</code></p> <p>Pretrained <code>MRInet</code> model for <code>SWI</code>.</p> <p>This is a basemodel in the <code>SWI</code> sub-ensemble as reported in Hofmann et al. (2022, NeuroImage).</p> <p>The training data stem from the <code>LIFE Adult</code> study, and were normalized and registered to the <code>T1w</code>-<code>FreeSurfer</code> file (<code>brain.finalsurfs.mgz</code>), and subsequently pruned to <code>(198, 198, 198)</code> voxels (for more details, see Hofmann et al. (2022, NeuroImage).</p>"},{"location":"reference/model/mrinets/#xai4mri.model.mrinets.PretrainedMRInetSWI.load_model","title":"load_model  <code>classmethod</code>","text":"<pre><code>load_model(\n    parent_folder: str | Path,\n    custom_objects: T | None = None,\n    compile_model: bool = False,\n) -&gt; Sequential\n</code></pre> <p>Load a pretrained <code>MRInet</code> model.</p> <p>If the model is not present on the local machine, it will be downloaded from the server and saved in the provided parent folder.</p> <p>Parameters:</p> Name Type Description Default <code>parent_folder</code> <code>str | Path</code> <p>Path to parent folder of the model.</p> required <code>custom_objects</code> <code>T | None</code> <p>Custom objects to load (e.g., loss functions).</p> <code>None</code> <code>compile_model</code> <code>bool</code> <p>Compile the model or not.</p> <code>False</code> <p>Returns:</p> Type Description <code>Sequential</code> <p>Pretrained <code>MRInet</code> model.</p> Source code in <code>src/xai4mri/model/mrinets.py</code> <pre><code>@classmethod\ndef load_model(\n    cls, parent_folder: str | Path, custom_objects: T | None = None, compile_model: bool = False\n) -&gt; keras.Sequential:\n    \"\"\"\n    Load a pretrained `MRInet` model.\n\n    If the model is not present on the local machine, it will be downloaded from the server\n    and saved in the provided parent folder.\n\n    :param parent_folder: Path to parent folder of the model.\n    :param custom_objects: Custom objects to load (e.g., loss functions).\n    :param compile_model: Compile the model or not.\n    :return: Pretrained `MRInet` model.\n    \"\"\"\n    return _load_pretrained_mrinet_model(\n        pretrained_model_type=cls,\n        parent_folder=parent_folder,\n        custom_objects=custom_objects,\n        compile_model=compile_model,\n    )\n</code></pre>"},{"location":"reference/model/mrinets/#xai4mri.model.mrinets.PretrainedMRInetT1","title":"PretrainedMRInetT1  <code>dataclass</code>","text":"<pre><code>PretrainedMRInetT1(\n    name: str = \"t1_model\",\n    url: str = \"https://keeper.mpdl.mpg.de/f/3be6fed59b4948aca699/?dl=1\",\n)\n</code></pre> <p>               Bases: <code>_PretrainedMRInet</code></p> <p>Pretrained <code>MRInet</code> model for <code>T1</code>-weighted images.</p> <p>This is a basemodel in the <code>T1</code> sub-ensemble as reported in Hofmann et al. (2022, NeuroImage).</p> <p>The training data stem from the <code>LIFE Adult</code> study, and were preprocessed using FreeSurfer (<code>brain.finalsurfs.mgz</code>), and subsequently pruned to <code>(198, 198, 198)</code> voxels (for more details, see Hofmann et al. (2022, NeuroImage).</p>"},{"location":"reference/model/mrinets/#xai4mri.model.mrinets.PretrainedMRInetT1.load_model","title":"load_model  <code>classmethod</code>","text":"<pre><code>load_model(\n    parent_folder: str | Path,\n    custom_objects: T | None = None,\n    compile_model: bool = False,\n) -&gt; Sequential\n</code></pre> <p>Load a pretrained <code>MRInet</code> model.</p> <p>If the model is not present on the local machine, it will be downloaded from the server and saved in the provided parent folder.</p> <p>Parameters:</p> Name Type Description Default <code>parent_folder</code> <code>str | Path</code> <p>Path to parent folder of the model.</p> required <code>custom_objects</code> <code>T | None</code> <p>Custom objects to load (e.g., loss functions).</p> <code>None</code> <code>compile_model</code> <code>bool</code> <p>Compile the model or not.</p> <code>False</code> <p>Returns:</p> Type Description <code>Sequential</code> <p>Pretrained <code>MRInet</code> model.</p> Source code in <code>src/xai4mri/model/mrinets.py</code> <pre><code>@classmethod\ndef load_model(\n    cls, parent_folder: str | Path, custom_objects: T | None = None, compile_model: bool = False\n) -&gt; keras.Sequential:\n    \"\"\"\n    Load a pretrained `MRInet` model.\n\n    If the model is not present on the local machine, it will be downloaded from the server\n    and saved in the provided parent folder.\n\n    :param parent_folder: Path to parent folder of the model.\n    :param custom_objects: Custom objects to load (e.g., loss functions).\n    :param compile_model: Compile the model or not.\n    :return: Pretrained `MRInet` model.\n    \"\"\"\n    return _load_pretrained_mrinet_model(\n        pretrained_model_type=cls,\n        parent_folder=parent_folder,\n        custom_objects=custom_objects,\n        compile_model=compile_model,\n    )\n</code></pre>"},{"location":"reference/model/mrinets/#xai4mri.model.mrinets.PretrainedModelsMRInet","title":"PretrainedModelsMRInet","text":"<p>               Bases: <code>Enum</code></p> <p>Enum class for pretrained <code>MRInet</code> models (<code>T1</code>, <code>FLAIR</code>, <code>SWI</code>).</p> <p>Call the <code>show</code> method to get an overview of available models</p> <pre><code>PretrainedModelsMRInet.show()\n</code></pre> <p>Get a model by selecting it</p> <pre><code>t1_mrinet = PretrainedModelsMRInet.T1_MODEL.value.load_model(...)\n\n# Alternatively, get the model by string\nswi_mrinet = PretrainedModelsMRInet(\"swi_model\").value.load_model(...)\n</code></pre>"},{"location":"reference/model/mrinets/#xai4mri.model.mrinets.PretrainedModelsMRInet.show","title":"show  <code>classmethod</code>","text":"<pre><code>show()\n</code></pre> <p>Show available pretrained <code>MRInet</code> models.</p> Source code in <code>src/xai4mri/model/mrinets.py</code> <pre><code>@classmethod\ndef show(cls):\n    \"\"\"Show available pretrained `MRInet` models.\"\"\"\n    return print(*[model.value for model in cls], sep=\"\\n\")\n</code></pre>"},{"location":"reference/model/mrinets/#xai4mri.model.mrinets.SFCN","title":"SFCN","text":"<p>               Bases: <code>_ModelCreator</code></p> <p><code>SFCN</code> model creator.</p> <p><code>SFCN</code> is the fully convolutional neural network (<code>SFCN</code>) model by Peng et al. (2021, Medical Image Analysis) for age prediction from MRI data of the <code>ukbiobank</code>.</p> <p>The architecture won the first place in the brain-age competition <code>PAC 2019</code>.</p>"},{"location":"reference/model/mrinets/#xai4mri.model.mrinets.SFCN.create","title":"create  <code>staticmethod</code>","text":"<pre><code>create(\n    name: str,\n    n_classes: int,\n    input_shape: tuple[int, int, int] = (160, 192, 160),\n    learning_rate: float = 0.01,\n    dropout: bool = True,\n) -&gt; Sequential\n</code></pre> <p>Create the fully convolutional neural network (<code>SFCN</code>) model.</p> <p>The <code>SFCN</code> was introduced in Peng et al. (2021, Medical Image Analysis).</p> <p>The original open-source implementation is done in <code>PyTorch</code> and can be found at: https://github.com/ha-ha-ha-han/UKBiobank_deep_pretrain</p> <p>For training:</p> <p>from Peng et al. (2021, p.4):</p> <p>\"The L2 weight decay coefficient was 0.001. The batch size was 8. The learning rate for the SGD optimiser was initialized as 0.01, then multiplied by 0.3 every 30 epochs unless otherwise specified. The total epoch number is 130 for the 12,949 training subjects. The epoch number is adjusted accordingly for the experiments with smaller training sets so that the training steps are roughly the same.\"</p> Use this version of the <code>SFCN</code> model with caution <ul> <li>The implementation is still experimental, is not tested properly yet, and might be updated in the future.</li> <li>The authors used \"Gaussian soft labels\" (<code>sigma=1, mean=*true age*</code>) for their loss function. This is not implemented here yet, and might require additional adjustments of the <code>xai4mri.dataloader</code> module.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Model name, which, for instance, could refer to the project it is applied for.</p> required <code>input_shape</code> <code>tuple[int, int, int]</code> <p>Shape of the input to the model. This should be the shape of a single MRI.</p> <code>(160, 192, 160)</code> <code>n_classes</code> <code>int</code> <p>Number of classes. In Peng et al. (2021) there were 40 age classes, representing 40 age strata.</p> required <code>learning_rate</code> <code>float</code> <p>Learning rate which is used for the optimizer of the model.</p> <code>0.01</code> <code>dropout</code> <code>bool</code> <p>Use dropout or not.</p> <code>True</code> <p>Returns:</p> Type Description <code>Sequential</code> <p>Compiled <code>SFCN</code> model (based on <code>Keras</code>), ready to be trained.</p> Source code in <code>src/xai4mri/model/mrinets.py</code> <pre><code>@staticmethod\n@_experimental\ndef create(\n    name: str,\n    n_classes: int,\n    input_shape: tuple[int, int, int] = (160, 192, 160),\n    learning_rate: float = 0.01,\n    dropout: bool = True,\n) -&gt; keras.Sequential:\n    \"\"\"\n    Create the fully convolutional neural network (`SFCN`) model.\n\n    The `SFCN` was introduced in\n    [Peng et al. (2021, *Medical Image Analysis*)](https://doi.org/10.1016/j.media.2020.101871).\n\n    The original open-source implementation is done in `PyTorch` and can be found at:\n    https://github.com/ha-ha-ha-han/UKBiobank_deep_pretrain\n\n    For training:\n\n    !!! quote \"from [Peng et al. (2021, p.4)](https://doi.org/10.1016/j.media.2020.101871):\"\n        &gt; \"The L2 weight decay coefficient was 0.001.\n        The batch size was 8.\n        The learning rate for the SGD optimiser was initialized as 0.01,\n        then multiplied by 0.3 every 30 epochs unless otherwise specified.\n        The total epoch number is 130 for the 12,949 training subjects.\n        The epoch number is adjusted accordingly for the experiments with\n        smaller training sets so that the training steps are roughly the\n        same.\"\n\n    ???+ warning \"Use this version of the `SFCN` model with caution\"\n        - The **implementation is still experimental**,\n        is not tested properly yet, and might be updated in the future.\n        - The authors used \"Gaussian soft labels\" (`sigma=1, mean=*true age*`) for their loss function.\n        This is not implemented here yet,\n        and might require additional adjustments of the `xai4mri.dataloader` module.\n\n    :param name: Model name, which, for instance, could refer to the project it is applied for.\n    :param input_shape: Shape of the input to the model.\n                        This should be the shape of a single MRI.\n    :param n_classes: Number of classes.\n                      In [Peng et al. (2021)](https://doi.org/10.1016/j.media.2020.101871)\n                      there were 40 age classes, representing 40 age strata.\n    :param learning_rate: Learning rate which is used for the optimizer of the model.\n    :param dropout: Use dropout or not.\n    :return: Compiled `SFCN` model (based on `Keras`), ready to be trained.\n    \"\"\"\n    conv_ctn = 0  # conv block counter\n    _check_n_classes(n_classes=n_classes)\n\n    def conv_block(\n        _out_channel: int,\n        max_pool: bool = True,\n        kernel_size: int = 3,\n        padding: str = \"same\",\n        max_pool_stride: int = 2,\n        in_shape: tuple[int, int, int] | None = None,\n    ) -&gt; keras.Sequential:\n        \"\"\"Define a convolutional block for SFCN.\"\"\"\n        c_block = keras.Sequential(name=f\"conv3D_block_{conv_ctn}\")\n\n        conv_kwargs = {} if in_shape is None else {\"input_shape\": (*in_shape, 1)}\n        c_block.add(keras.layers.Conv3D(_out_channel, kernel_size=kernel_size, padding=padding, **conv_kwargs))\n        c_block.add(keras.layers.BatchNormalization())\n        if max_pool:\n            c_block.add(keras.layers.MaxPooling3D(pool_size=2, strides=max_pool_stride))\n        c_block.add(keras.layers.ReLU())\n        return c_block\n\n    # Build the model\n    k_model = keras.Sequential(name=name)\n\n    # Feature extractor\n    channel_number = (32, 64, 128, 256, 256, 64)\n    n_layer = len(channel_number)\n\n    for i in range(n_layer):\n        out_channel = channel_number[i]\n        if i &lt; n_layer - 1:\n            k_model.add(\n                conv_block(\n                    out_channel,\n                    max_pool=True,\n                    kernel_size=3,\n                    padding=\"same\",\n                    in_shape=input_shape if i == 0 else None,\n                )\n            )\n        else:\n            k_model.add(conv_block(out_channel, max_pool=False, kernel_size=1, padding=\"valid\"))\n        conv_ctn += 1\n\n    # Classifier [in: (bs, 5, 6, 5, 64)]\n    avg_shape = [5, 6, 5]\n    k_model.add(keras.layers.AveragePooling3D(pool_size=avg_shape))\n    if dropout:\n        k_model.add(keras.layers.Dropout(rate=0.5))\n\n    k_model.add(keras.layers.Conv3D(filters=n_classes, kernel_size=1, padding=\"valid\"))\n\n    # Output\n    k_model.add(keras.layers.Activation(activation=\"log_softmax\", name=\"log_softmax\"))\n\n    # Compile\n    # Define the learning rate schedule\n    lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n        initial_learning_rate=learning_rate,\n        decay_steps=30,  # for the total number of 130 epochs in Peng et al. (2021)\n        decay_rate=0.3,\n        staircase=True,\n    )\n    k_model.compile(\n        optimizer=keras.optimizers.SGD(  # SGD best in Peng et al. (2021)\n            learning_rate=lr_schedule,\n            weight_decay=keras.regularizers.l2(0.001),\n        ),\n        loss=\"kl_divergence\",  # Peng et al. (2021) use K-L Divergence loss:\n        # no one-hot encoding required: loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n        # no log_softmax when using from_logits=True, however, KL-Div. loss expects log_softmax\n        metrics=[\"accuracy\"],  # ... if n_classes else [\"mae\"],\n    )\n    # ... to minimize a Kullback-Leibler divergence loss function between the predicted probability and a\n    # Gaussian distribution (the mean is the true age,\n    # and the distribution sigma is 1 year for UKB) for each training subject.\n    # This soft-classification loss encourages the model to predict age as accurately as possible.\n\n    # Summary\n    k_model.summary()\n    return k_model\n</code></pre>"},{"location":"reference/model/mrinets/#xai4mri.model.mrinets.SFCN.pretrained_models","title":"pretrained_models  <code>staticmethod</code>","text":"<pre><code>pretrained_models() -&gt; None\n</code></pre> <p>Return enum of pretrained <code>SFCN</code> models.</p> <p>Note</p> <p>There are no pretrained models available for <code>SFCN</code> yet.</p> Source code in <code>src/xai4mri/model/mrinets.py</code> <pre><code>@staticmethod\ndef pretrained_models() -&gt; None:\n    \"\"\"\n    Return enum of pretrained `SFCN` models.\n\n    !!! note\n        There are no pretrained models available for `SFCN` yet.\n    \"\"\"\n    cprint(string=\"There are no pretrained models available for SFCN (yet).\", col=\"y\")\n</code></pre>"},{"location":"reference/model/mrinets/#xai4mri.model.mrinets.SFCN.reference","title":"reference  <code>staticmethod</code>","text":"<pre><code>reference() -&gt; str\n</code></pre> <p>Get the reference for the <code>SFCN</code> model.</p> Source code in <code>src/xai4mri/model/mrinets.py</code> <pre><code>@staticmethod\ndef reference() -&gt; str:\n    \"\"\"Get the reference for the `SFCN` model.\"\"\"\n    return \"Peng et al. (2021). Medical Image Analysis. https://doi.org/10.1016/j.media.2020.101871\"\n</code></pre>"},{"location":"reference/model/mrinets/#xai4mri.model.mrinets.get_model","title":"get_model","text":"<pre><code>get_model(\n    model_type: OutOfTheBoxModels | str, **kwargs\n) -&gt; Sequential | None\n</code></pre> <p>Get a freshly initiated out-of-the-box model.</p> <p>Example of how to get an <code>MRInet</code> model</p> <pre><code>mrinet = get_model(\n             model_type=OutOfTheBoxModels.MRINET,\n             name=\"MyMRInet\",\n             n_classes=False,\n             input_shape=(91, 109, 91),\n             )\n\n# Alternatively, get the model by string\nsfcn = get_model(\n           model_type=\"sfcn\",\n           name=\"MySFCN\",\n           n_classes=40,\n           input_shape=(160, 192, 160),\n           )\n\nThis is a wrapper for the `create` method of the model creator classes.\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>model_type</code> <code>OutOfTheBoxModels | str</code> <p>model of type <code>OutOfTheBoxModels</code> or <code>string</code> (e.g., 'mrinet')</p> required <code>kwargs</code> <p>keyword arguments for model creation</p> <code>{}</code> Source code in <code>src/xai4mri/model/mrinets.py</code> <pre><code>def get_model(model_type: OutOfTheBoxModels | str, **kwargs) -&gt; keras.Sequential | None:\n    \"\"\"\n    Get a freshly initiated out-of-the-box model.\n\n    !!! example \"Example of how to get an `MRInet` model\"\n        ```python\n        mrinet = get_model(\n                     model_type=OutOfTheBoxModels.MRINET,\n                     name=\"MyMRInet\",\n                     n_classes=False,\n                     input_shape=(91, 109, 91),\n                     )\n\n        # Alternatively, get the model by string\n        sfcn = get_model(\n                   model_type=\"sfcn\",\n                   name=\"MySFCN\",\n                   n_classes=40,\n                   input_shape=(160, 192, 160),\n                   )\n\n        This is a wrapper for the `create` method of the model creator classes.\n        ```\n    :param model_type: model of type `OutOfTheBoxModels` or `string` (e.g., 'mrinet')\n    :param kwargs: keyword arguments for model creation\n    \"\"\"\n    if OutOfTheBoxModels(model_type) == OutOfTheBoxModels.MRINET:\n        return MRInet.create(**kwargs)\n    if OutOfTheBoxModels(model_type) == OutOfTheBoxModels.SFCN:\n        return SFCN.create(**kwargs)\n    return None\n</code></pre>"},{"location":"reference/model/transfer/","title":"<code class=\"doc-symbol doc-symbol-nav doc-symbol-module\"></code> transfer","text":""},{"location":"reference/model/transfer/#xai4mri.model.transfer","title":"transfer","text":"<p>Scripts for transfer learning of deep learning models for MRI-based predictions.</p> <p>The goal is to transfer models such as the 3D-CNNs reported in Hofmann et al. (2022, NeuroImage) to new and smaller datasets and other prediction tasks.</p> <pre><code>Author: Simon M. Hofmann\nYears: 2023\n</code></pre> <p>This module is experimental and still in development.</p>"},{"location":"reference/model/transfer/#xai4mri.model.transfer.adapt_model","title":"adapt_model","text":"<pre><code>adapt_model(\n    model: Sequential,\n    learning_rate: float = 0.0005,\n    target_bias: float | None = None,\n    n_classes: bool | int = False,\n) -&gt; Sequential\n</code></pre> <p>Adapt a pretrained model to a new dataset and/or task.</p> <p>This function adapts the output layer of a pretrained model to a new dataset and/or task by replacing the output layer. The model is recompiled with a new learning rate and loss function.</p> <p>This function is experimental and still in development.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Sequential</code> <p>Pretrained <code>Keras</code> model.</p> required <code>learning_rate</code> <code>float</code> <p>Learning rate for the optimizer.</p> <code>0.0005</code> <code>target_bias</code> <code>float | None</code> <p>Model output bias. For classification tasks with this can be left blank [<code>None</code>]. For regression tasks, it is recommended to set this bias to the average of the prediction target distribution in the dataset.</p> <code>None</code> <code>n_classes</code> <code>bool | int</code> <p>Number of classes. For regression tasks set to <code>False</code> or <code>0</code>; For classification tasks, provide integer &gt;= 2.</p> <code>False</code> <p>Returns:</p> Type Description <code>Sequential</code> <p>The adapted model.</p> Source code in <code>src/xai4mri/model/transfer.py</code> <pre><code>@_experimental\ndef adapt_model(\n    model: keras.Sequential,\n    learning_rate: float = 5e-4,\n    target_bias: float | None = None,\n    n_classes: bool | int = False,\n) -&gt; keras.Sequential:\n    \"\"\"\n    Adapt a pretrained model to a new dataset and/or task.\n\n    This function adapts the output layer of a pretrained model to a new dataset and/or task\n    by replacing the output layer.\n    The model is recompiled with a new learning rate and loss function.\n\n    !!! warning \"This function is experimental and still in development.\"\n\n    :param model: Pretrained `Keras` model.\n    :param learning_rate: Learning rate for the optimizer.\n    :param target_bias: Model output bias.\n                        For classification tasks with this can be left blank [`None`].\n                        For regression tasks, it is recommended to set this bias to the average of the\n                        prediction target distribution in the dataset.\n    :param n_classes: Number of classes.\n                      For regression tasks set to `False` or `0`;\n                      For classification tasks, provide integer &gt;= 2.\n    :return: The adapted model.\n    \"\"\"\n    if isinstance(n_classes, int) and n_classes == 1:\n        msg = \"For a regression model, choose n_classes = 0, for a classification task n_classes &gt;= 2.\"\n        raise ValueError(msg)\n    n_outputs = n_classes if n_classes else 1\n\n    if model.layers[-1].units != n_outputs:\n        model.pop()\n        model.add(\n            keras.layers.Dense(\n                units=n_outputs,\n                activation=\"softmax\" if n_classes else None,\n                use_bias=not n_classes,\n                bias_initializer=keras.initializers.Constant(target_bias) if target_bias else \"zeros\",\n            )\n        )\n\n    # Compile\n    model.compile(\n        optimizer=keras.optimizers.Adam(learning_rate),  # =\"adam\",\n        loss=\"mse\",\n        metrics=[\"accuracy\"] if n_classes else [\"mae\"],\n    )\n\n    # Summary\n    model.summary()\n\n    return model\n</code></pre>"},{"location":"reference/model/transfer/#xai4mri.model.transfer.analyse_model_and_data","title":"analyse_model_and_data","text":"<pre><code>analyse_model_and_data(\n    model: Sequential, data: BaseDataSet, target: str\n)\n</code></pre> <p>Analyze model and data to estimate training parameters for transfer learning.</p> <p>This function is not implemented yet.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Sequential</code> <p>Pre-trained <code>Keras</code> model.</p> required <code>data</code> <code>BaseDataSet</code> <p>Dataset, which should be used for model fine-tuning.</p> required <code>target</code> <code>str</code> <p>Variable in the dataset, which is supposed to be predicted.</p> required <p>Returns:</p> Type Description <p>Recommended number of training epochs, number of training samples, freeze weights, ...</p> Source code in <code>src/xai4mri/model/transfer.py</code> <pre><code>def analyse_model_and_data(model: keras.Sequential, data: BaseDataSet, target: str):  # noqa: ARG001\n    \"\"\"\n    Analyze model and data to estimate training parameters for transfer learning.\n\n    !!! warning \"This function is not implemented yet.\"\n\n    :param model: Pre-trained `Keras` model.\n    :param data: Dataset, which should be used for model fine-tuning.\n    :param target: Variable in the dataset, which is supposed to be predicted.\n    :return: Recommended number of training epochs, number of training samples, freeze weights, ...\n    \"\"\"\n    msg = \"This function is not implemented yet.\"\n    raise NotImplementedError(msg)\n</code></pre>"},{"location":"reference/model/transfer/#xai4mri.model.transfer.dual_phase_model_training","title":"dual_phase_model_training","text":"<pre><code>dual_phase_model_training(\n    model: Sequential,\n    epochs: tuple[int, int],\n    data: BaseDataSet,\n    target: str,\n    model_parent_path: str | Path,\n    split_dict: dict | None = None,\n    callbacks: list[Callback] | None = None,\n    **kwargs\n) -&gt; Sequential | None\n</code></pre> <p>Train / finetune a model in two phases.</p> <p>First, train all layers of the model. Then, freeze the first layers, and only finetune the last layers.</p> <p>This function is experimental and is still in development.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Sequential</code> <p>Compiled <code>Keras</code> model to be trained on the provided dataset.</p> required <code>epochs</code> <code>tuple[int, int]</code> <p>Number of training epochs.</p> required <code>data</code> <code>BaseDataSet</code> <p>Dataset for training and evaluation.</p> required <code>target</code> <code>str</code> <p>Variable to be predicted.</p> required <code>model_parent_path</code> <code>str | Path</code> <p>The path to the parent folder of the given model, where the model will be saved.</p> required <code>split_dict</code> <code>dict | None</code> <p>Data split dictionary for training, validation, and test data.</p> <code>None</code> <code>callbacks</code> <code>list[Callback] | None</code> <p>A list of <code>Keras</code>'s <code>callbacks</code> (except of <code>ModelCheckpoint</code>).</p> <code>None</code> <code>kwargs</code> <p>Additional keyword arguments for <code>data.create_data_split()</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Sequential | None</code> <p>trained model</p> Source code in <code>src/xai4mri/model/transfer.py</code> <pre><code>@_experimental\ndef dual_phase_model_training(\n    model: keras.Sequential,\n    epochs: tuple[int, int],\n    data: BaseDataSet,\n    target: str,\n    model_parent_path: str | Path,\n    split_dict: dict | None = None,\n    callbacks: list[keras.callbacks.Callback] | None = None,\n    **kwargs,\n) -&gt; keras.Sequential | None:\n    \"\"\"\n    Train / finetune a model in two phases.\n\n    First, train all layers of the model.\n    Then, freeze the first layers, and only finetune the last layers.\n\n    !!! warning \"This function is experimental and is still in development.\"\n\n    :param model: Compiled `Keras` model to be trained on the provided dataset.\n    :param epochs: Number of training epochs.\n    :param data: Dataset for training and evaluation.\n    :param target: Variable to be predicted.\n    :param model_parent_path: The path to the parent folder of the given model, where the model will be saved.\n    :param split_dict: Data split dictionary for training, validation, and test data.\n    :param callbacks: A list of `Keras`'s `callbacks` (except of `ModelCheckpoint`).\n    :param kwargs: Additional keyword arguments for `data.create_data_split()`.\n    :return: trained model\n    \"\"\"\n    # Set path to model and split dictionary\n    path_to_model = Path(model_parent_path) / model.name\n    path_to_checkpoints = path_to_model / \"checkpoints\"\n    path_to_split_dict = path_to_model / f\"{model.name}_split_dict\"\n\n    # Check if model has been trained already\n    if list(path_to_checkpoints.glob(\"*\")):\n        cprint(string=\"Model has been trained already. Skipping training.\", col=\"y\")\n        return None\n\n    # TODO: Create data splits  # noqa: FIX002\n    #   This should be done in a separate function\n    split_dict, train_data_gen, val_data_gen, test_data_gen = data.create_data_split(\n        target=target,\n        batch_size=kwargs.pop(\"batch_size\", 1),\n        split_ratio=kwargs.pop(\"split_ratio\", (0.8, 0.1, 0.1)),\n        split_dict=split_dict,\n    )\n\n    # Define callbacks\n    callbacks = [] if callbacks is None else callbacks\n    # Add model checkpoint\n    for c in callbacks:\n        if isinstance(c, keras.callbacks.ModelCheckpoint):\n            break\n    else:\n        callbacks.append(\n            keras.callbacks.ModelCheckpoint(\n                filepath=path_to_checkpoints / \"cp-{epoch:04d}.ckpt\",\n                save_weights_only=True,  # TODO: revisit  # noqa: FIX002\n                monitor=\"val_loss\",\n                mode=\"auto\",\n                save_best_only=True,  # TODO: revisit  # noqa: FIX002\n                save_freq=\"epoch\",\n            )\n        )\n    # Add early stopping\n    for c in callbacks:\n        if isinstance(c, keras.callbacks.EarlyStopping):\n            break\n    else:\n        callbacks.append(\n            keras.callbacks.EarlyStopping(\n                monitor=\"val_loss\",\n                mode=\"auto\",\n                min_delta=0.001,\n                patience=10,\n                verbose=1,\n            )\n        )\n\n    # First training loop over all layers\n    model.fit(\n        x=train_data_gen,\n        epochs=epochs[0],\n        validation_data=val_data_gen,\n        callbacks=callbacks,\n    )\n\n    # Fine-tuning of later layers while freezing earlier layers\n    # Freeze all but fully connected layers\n    for layer in model.layers:\n        if not isinstance(layer, keras.layers.Dense):\n            layer.trainable = False\n    # TODO: revisit this later, since this is a naive approach &amp; has specific architectures in mind  # noqa: FIX002\n\n    # Recompile the model after making any changes to the `trainable` attribute of any inner layer,\n    # so that changes are taken into account\n    model.compile()\n\n    # Fine-tuning\n    model.fit(\n        x=train_data_gen,\n        epochs=epochs[1],\n        validation_data=val_data_gen,\n        callbacks=callbacks,\n    )\n\n    # Save split dictionary and model\n    data.save_split_dict(save_path=path_to_split_dict)\n    model.save(path_to_model / f\"{model.name}.h5\")\n\n    # Model evaluation\n    model.evaluate(test_data_gen)\n\n    return model\n</code></pre>"},{"location":"reference/model/transfer/#xai4mri.model.transfer.mono_phase_model_training","title":"mono_phase_model_training","text":"<pre><code>mono_phase_model_training(\n    model: Sequential,\n    epochs: int,\n    data: BaseDataSet,\n    target: str,\n    model_parent_path: str | Path,\n    split_dict: dict | None = None,\n    callbacks: list[Callback] | None = None,\n    **kwargs\n) -&gt; Sequential | None\n</code></pre> <p>Train / finetune all model weights at once.</p> <p>This simply trains the model on the provided dataset for the given number of epochs.</p> <p>When used for transfer learning</p> <p>This is a naive approach to transfer learning, and can lead to issues such as catastrophic forgetting.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Sequential</code> <p>Compiled <code>Keras</code> model to be trained on the provided dataset.</p> required <code>epochs</code> <code>int</code> <p>Number of training epochs.</p> required <code>data</code> <code>BaseDataSet</code> <p>Dataset for training and evaluation. This must be a subclass of <code>BaseDataSet</code>.</p> required <code>target</code> <code>str</code> <p>Variable to be predicted. This must be in the 'study_table<code>of the dataset (</code>data').</p> required <code>model_parent_path</code> <code>str | Path</code> <p>The path to the parent folder of the given model, where the model will be saved.</p> required <code>split_dict</code> <code>dict | None</code> <p>Data split dictionary for training, validation, and test data.</p> <code>None</code> <code>callbacks</code> <code>list[Callback] | None</code> <p>A list of <code>Keras</code>'s <code>callbacks</code> (except of <code>ModelCheckpoint</code>).</p> <code>None</code> <code>kwargs</code> <p>Additional keyword arguments for <code>data.create_data_split()</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Sequential | None</code> <p>Trained model.</p> Source code in <code>src/xai4mri/model/transfer.py</code> <pre><code>def mono_phase_model_training(\n    model: keras.Sequential,\n    epochs: int,\n    data: BaseDataSet,\n    target: str,\n    model_parent_path: str | Path,\n    split_dict: dict | None = None,\n    callbacks: list[keras.callbacks.Callback] | None = None,\n    **kwargs,\n) -&gt; keras.Sequential | None:\n    \"\"\"\n    Train / finetune all model weights at once.\n\n    This simply trains the model on the provided dataset for the given number of epochs.\n\n    !!! note \"When used for transfer learning\"\n        This is a naive approach to transfer learning, and can lead to issues such as catastrophic forgetting.\n\n    :param model: Compiled `Keras` model to be trained on the provided dataset.\n    :param epochs: Number of training epochs.\n    :param data: Dataset for training and evaluation. This must be a subclass of `BaseDataSet`.\n    :param target: Variable to be predicted. This must be in the 'study_table` of the dataset (`data').\n    :param model_parent_path: The path to the parent folder of the given model, where the model will be saved.\n    :param split_dict: Data split dictionary for training, validation, and test data.\n    :param callbacks: A list of `Keras`'s `callbacks` (except of `ModelCheckpoint`).\n    :param kwargs: Additional keyword arguments for `data.create_data_split()`.\n    :return: Trained model.\n    \"\"\"\n    # Set path to model and split dictionary\n    path_to_model = Path(model_parent_path) / model.name\n    path_to_checkpoints = path_to_model / \"checkpoints\"\n    path_to_split_dict = path_to_model / f\"{model.name}_split_dict\"\n\n    # Check if model has been trained already\n    if list(path_to_checkpoints.glob(\"*\")):\n        cprint(string=\"Model has been trained already. Skipping training.\", col=\"y\")\n        return None\n\n    # Create data splits\n    split_dict, train_data_gen, val_data_gen, test_data_gen = data.create_data_split(\n        target=target,\n        batch_size=kwargs.pop(\"batch_size\", 1),\n        split_ratio=kwargs.pop(\"split_ratio\", (0.8, 0.1, 0.1)),\n        split_dict=split_dict,\n    )\n\n    # Define callbacks\n    callbacks = [] if callbacks is None else callbacks\n    for c in callbacks:\n        if isinstance(c, keras.callbacks.ModelCheckpoint):\n            break\n    else:\n        callbacks.append(\n            keras.callbacks.ModelCheckpoint(\n                filepath=path_to_checkpoints / \"cp-{epoch:04d}.ckpt\",\n                save_weights_only=True,  # TODO: revisit  # noqa: FIX002\n                monitor=\"val_loss\",\n                mode=\"auto\",\n                save_best_only=True,  # TODO: revisit  # noqa: FIX002\n                save_freq=\"epoch\",\n            )\n        )\n\n    # Train model\n    model.fit(\n        x=train_data_gen,\n        epochs=epochs,\n        validation_data=val_data_gen,\n        callbacks=callbacks,\n    )\n\n    # Save split dictionary and model\n    data.save_split_dict(save_path=path_to_split_dict)\n    model.save(path_to_model / f\"{model.name}.h5\")\n\n    # Model evaluation\n    model.evaluate(test_data_gen)\n\n    return model\n</code></pre>"},{"location":"reference/visualizer/","title":"Index","text":""},{"location":"reference/visualizer/#xai4mri.visualizer","title":"visualizer","text":"<p>Init <code>visualizer</code> submodule of <code>xai4mri</code>.</p> <pre><code>Author: Simon M. Hofmann\nYears: 2023\n</code></pre>"},{"location":"reference/visualizer/#xai4mri.visualizer.plot_heatmap","title":"plot_heatmap","text":"<pre><code>plot_heatmap(\n    ipt: ndarray,\n    analyser_obj: ndarray,\n    cmap_name: str = \"black-fire-red\",\n    mode: str = \"triplet\",\n    fig_name: str = \"Heatmap\",\n    **kwargs\n) -&gt; Figure\n</code></pre> <p>Plot an XAI-based analyzer object over the model input in the form of a heatmap.</p> <p>How to use</p> <pre><code>from xai4mri.model.interpreter import analyze_model\nfrom xai4mri.visualizer import plot_heatmap\n\n# Analyze model\nanalyzer_obj = analyze_model(model=model, ipt=mri_image, ...)\n\n# Visualize heatmap / relevance map\nanalyzer_fig = plot_heatmap(ipt=mri_image, analyser_obj=analyzer_obj, ...)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>ipt</code> <code>ndarray</code> <p>Model input image.</p> required <code>analyser_obj</code> <code>ndarray</code> <p>Analyzer object (relevance map) that is computed by the model interpreter (e.g., <code>LRP</code>). Both the input image and the analyzer object must have the same shape.</p> required <code>cmap_name</code> <code>str</code> <p>Name of color-map (<code>cmap</code>) to be applied.</p> <code>'black-fire-red'</code> <code>mode</code> <code>str</code> <p>\"triplet\": Plot three slices of different axes. \"all\": Plot all slices (w/ brain OR w/o brain \u2192 set: <code>plot_empty=True</code> in <code>kwargs</code>)</p> <code>'triplet'</code> <code>fig_name</code> <code>str</code> <p>name of figure</p> <code>'Heatmap'</code> <code>kwargs</code> <p>Additional kwargs: \"c_intensifier\", \"clip_q\", \"min_sym_clip\", \"true_scale\", \"plot_empty\", \"axis\", \"every\", \"crosshair\", \"gamma\". And, <code>kwargs</code> for <code>plot_mid_slice()</code> and <code>slice_through()</code> from <code>xai4mri.visualizer.visualize_mri</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Figure</code> <p><code>plt.Figure</code> object of the heatmap plot.</p> Source code in <code>src/xai4mri/visualizer/visualize_heatmap.py</code> <pre><code>def plot_heatmap(\n    ipt: np.ndarray,\n    analyser_obj: np.ndarray,\n    cmap_name: str = \"black-fire-red\",\n    mode: str = \"triplet\",\n    fig_name: str = \"Heatmap\",\n    **kwargs,\n) -&gt; plt.Figure:\n    \"\"\"\n    Plot an XAI-based analyzer object over the model input in the form of a heatmap.\n\n    !!! example \"How to use\"\n        ```python\n        from xai4mri.model.interpreter import analyze_model\n        from xai4mri.visualizer import plot_heatmap\n\n        # Analyze model\n        analyzer_obj = analyze_model(model=model, ipt=mri_image, ...)\n\n        # Visualize heatmap / relevance map\n        analyzer_fig = plot_heatmap(ipt=mri_image, analyser_obj=analyzer_obj, ...)\n        ```\n\n    :param ipt: Model input image.\n    :param analyser_obj: Analyzer object (relevance map) that is computed by the model interpreter (e.g., `LRP`).\n                         Both the input image and the analyzer object must have the same shape.\n    :param cmap_name: Name of color-map (`cmap`) to be applied.\n    :param mode: \"triplet\": Plot three slices of different axes.\n                 \"all\": Plot all slices (w/ brain OR w/o brain \u2192 set: `plot_empty=True` in `kwargs`)\n    :param fig_name: name of figure\n    :param kwargs: Additional kwargs:\n                   \"c_intensifier\", \"clip_q\", \"min_sym_clip\", \"true_scale\", \"plot_empty\", \"axis\", \"every\", \"crosshair\",\n                    \"gamma\".\n                    And, `kwargs` for `plot_mid_slice()` and `slice_through()` from `xai4mri.visualizer.visualize_mri`.\n    :return: `plt.Figure` object of the heatmap plot.\n    \"\"\"\n    a = analyser_obj.copy().squeeze().astype(np.float32)\n    mode = mode.lower()\n    if mode not in {\"triplet\", \"all\"}:\n        msg = \"mode must be 'triplet', or 'all'!\"\n        raise ValueError(msg)\n\n    # Extract kwargs\n    cintensifier = kwargs.pop(\"c_intensifier\", 1.0)\n    clipq = kwargs.pop(\"clip_q\", 1e-2)\n    min_sym_clip = kwargs.pop(\"min_sym_clip\", True)\n    true_scale = kwargs.pop(\"true_scale\", False)\n    plot_empty = kwargs.pop(\"plot_empty\", False)\n    axis = kwargs.pop(\"axis\", 0)\n    every = kwargs.pop(\"every\", 2)\n    crosshairs = kwargs.pop(\"crosshair\", False)\n    gamma = kwargs.pop(\"gamma\", 0.2)\n\n    # Render image\n    colored_a = _apply_colormap(\n        analyser_obj=a,\n        input_image=ipt.squeeze().astype(np.float32),\n        cmap_name=cmap_name,\n        c_intensifier=cintensifier,\n        clip_q=clipq,\n        min_sym_clip=min_sym_clip,\n        gamma=gamma,\n        true_scale=true_scale,\n    )\n    heatmap = colored_a[0]\n\n    cbar_range = (-1, 1) if not true_scale else (-colored_a[2], colored_a[2])\n    if mode == \"triplet\":\n        fig = plot_mid_slice(\n            volume=heatmap,\n            fig_name=fig_name,\n            cmap=_create_cmap(gregoire_black_fire_red),\n            c_range=\"full\",\n            cbar=True,\n            cbar_range=cbar_range,\n            edges=False,\n            crosshairs=crosshairs,\n            **kwargs,\n        )\n\n    else:  # mode == \"all\"\n        if not plot_empty:\n            # Remove planes with no information\n            heatmap = heatmap.compress(\n                ~np.all(\n                    heatmap == 0,\n                    axis=tuple(ax for ax in range(heatmap.ndim) if ax != axis),\n                ),\n                axis=axis,\n            )\n\n        fig = slice_through(\n            volume=heatmap,\n            every=every,\n            axis=axis,\n            fig_name=fig_name,\n            edges=False,\n            cmap=_create_cmap(gregoire_black_fire_red),\n            c_range=\"full\",\n            crosshairs=crosshairs,\n            **kwargs,\n        )\n    return fig\n</code></pre>"},{"location":"reference/visualizer/#xai4mri.visualizer.plot_mid_slice","title":"plot_mid_slice","text":"<pre><code>plot_mid_slice(\n    volume: ndarray,\n    axis: int | _Axis | None = None,\n    fig_name: str | None = None,\n    edges: bool = True,\n    c_range: str | None = None,\n    **kwargs\n) -&gt; Figure\n</code></pre> <p>Plot 2D-slices of a given 3D-volume.</p> <p>If no axis is given, plot for each axis its middle slice.</p> <p>Parameters:</p> Name Type Description Default <code>volume</code> <code>ndarray</code> <p>3D volume (MRI).</p> required <code>axis</code> <code>int | _Axis | None</code> <p><code>None</code>: Slices from all three axes are plotted. To plot a specific axis only, provide <code>int</code> or <code>_Axis</code>.</p> <code>None</code> <code>fig_name</code> <code>str | None</code> <p>Name of the figure.</p> <code>None</code> <code>edges</code> <code>bool</code> <p>Draw edges around the brain if set to <code>True</code>.</p> <code>True</code> <code>c_range</code> <code>str | None</code> <p>Color range: \"full\": Full possible spectrum (0-255 or 0-1), \"single\": Take min/max of given volume. <code>None</code>: Default: do not change color range.</p> <code>None</code> <code>kwargs</code> <p>Additional keyword arguments for <code>plt.imshow()</code>. And, <code>crosshairs: bool = True</code>, <code>ticks: bool = False</code>. Also, <code>cbar: bool = False</code> and <code>cbar_range: tuple[int, int] = None</code> for a color bar, <code>suptitle: str = None</code> for a title, and <code>slice_idx: int | tuple[int, int, int] = None</code> for specific slice indices to plot, if not provided, the middle slice(s) are plotted.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Figure</code> <p>The figure object of the plot.</p> Source code in <code>src/xai4mri/visualizer/visualize_mri.py</code> <pre><code>def plot_mid_slice(\n    volume: np.ndarray,\n    axis: int | _Axis | None = None,\n    fig_name: str | None = None,\n    edges: bool = True,\n    c_range: str | None = None,\n    **kwargs,\n) -&gt; plt.Figure:\n    \"\"\"\n    Plot 2D-slices of a given 3D-volume.\n\n    If no axis is given, plot for each axis its middle slice.\n\n    :param volume: 3D volume (MRI).\n    :param axis: `None`: Slices from all three axes are plotted.\n                 To plot a specific axis only, provide `int` or `_Axis`.\n    :param fig_name: Name of the figure.\n    :param edges:  Draw edges around the brain if set to `True`.\n    :param c_range: Color range:\n                    \"full\": Full possible spectrum (0-255 or 0-1),\n                    \"single\": Take min/max of given volume.\n                    `None`: Default: do not change color range.\n    :param kwargs: Additional keyword arguments for `plt.imshow()`.\n                   And, `crosshairs: bool = True`, `ticks: bool = False`.\n                   Also, `cbar: bool = False` and `cbar_range: tuple[int, int] = None` for a color bar,\n                   `suptitle: str = None` for a title,\n                   and `slice_idx: int | tuple[int, int, int] = None` for specific slice indices to plot,\n                   if not provided, the middle slice(s) are plotted.\n    :return: The figure object of the plot.\n    \"\"\"\n    # Get color bar kwargs (if any)\n    cbar = kwargs.pop(\"cbar\", False)\n    cbar_range = kwargs.pop(\"cbar_range\") if (\"cbar_range\" in kwargs and cbar) else None\n    # only if cbar is active\n    suptitle = kwargs.pop(\"suptitle\", None)\n    slice_idx = kwargs.pop(\"slice_idx\", None)  # in case mid or other slice is given\n\n    # Set (mid-)slice index\n    sl = int(np.round(volume.shape[0] / 2)) if slice_idx is None else slice_idx\n    max_n_axes = 3\n    if slice_idx is None:\n        sl_str = \"mid\"\n    elif isinstance(sl, (list, tuple)):\n        if len(sl) != max_n_axes:\n            msg = \"slice_idx must be tuple or list of length 3, is None or single int.\"\n            raise ValueError(msg)\n        sl_str = str(sl)\n    else:\n        sl_str = str(int(sl))\n\n    # Begin plotting\n    if axis is None:\n        _fs = {\"size\": 10}  # define font size\n\n        fig = plt.figure(num=f\"{fig_name if fig_name else ''} volume {sl_str}-slice\", figsize=(12, 4))\n        if isinstance(suptitle, str) and suptitle:\n            fig.suptitle(suptitle, fontsize=14)\n\n        # Planes\n        ims = []\n        axs = []\n        sls = [sl] * 3 if isinstance(sl, int) else sl  # is tuple pf length 3 or int\n        for ip, _plane in enumerate(PLANES):\n            axs.append(fig.add_subplot(1, 3, ip + 1))\n            ims.append(\n                plot_slice(\n                    volume,\n                    axis=ip,\n                    idx_slice=sls[ip],\n                    edges=edges,\n                    c_range=c_range,\n                    **kwargs,\n                )\n            )\n            plt.title(_plane, fontdict=_fs)\n\n            divider = make_axes_locatable(axs[ip])\n            cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n            cax.axis(\"off\")\n            if cbar and ip == len(PLANES) - 1:\n                cax_bar = fig.colorbar(ims[-1], ax=cax, fraction=0.048, pad=0.04)  # shrink=.8, aspect=50)\n                if cbar_range:\n                    cax_bar.set_ticks(ticks=np.linspace(start=0, stop=1, num=7), minor=True)\n                    cax_bar.ax.set_yticklabels(\n                        labels=[\n                            f\"{tick:.2g}\"\n                            for tick in np.linspace(cbar_range[0], cbar_range[1], len(cax_bar.get_ticks()))\n                        ]\n                    )\n\n    else:  # If specific axis to plot\n        axis = _Axis(axis)\n        axis_name = axis.name.lower()\n\n        fig = plt.figure(f\"{fig_name if fig_name else ''} {axis_name} {sl_str}-slice\")\n        im = plot_slice(volume, axis.value, idx_slice=sl, edges=edges, c_range=c_range, **kwargs)\n        if cbar:\n            cax_bar = fig.colorbar(im, fraction=0.048, pad=0.04)  # shrink=0.8, aspect=50)\n            if cbar_range:\n                cax_bar.set_ticks(ticks=np.linspace(start=0, stop=1, num=7), minor=True)\n                cax_bar.ax.set_yticklabels(\n                    labels=[\n                        f\"{tick:.2g}\" for tick in np.linspace(cbar_range[0], cbar_range[1], len(cax_bar.get_ticks()))\n                    ]\n                )\n\n        plt.tight_layout()\n\n    return fig\n</code></pre>"},{"location":"reference/visualizer/#xai4mri.visualizer.plot_slice","title":"plot_slice","text":"<pre><code>plot_slice(\n    volume: ndarray,\n    axis: int | _Axis,\n    idx_slice: int,\n    edges: bool = False,\n    c_range: str | None = None,\n    **kwargs\n) -&gt; AxesImage\n</code></pre> <p>Plot one slice of a 3D volume.</p> <p>Parameters:</p> Name Type Description Default <code>volume</code> <code>ndarray</code> <p>3D volume (MRI).</p> required <code>axis</code> <code>int | _Axis</code> <p>The volume axis to plot from.</p> required <code>idx_slice</code> <code>int</code> <p>The slice index to plot.</p> required <code>edges</code> <code>bool</code> <p>Draw edges around the brain if set to <code>True</code>.</p> <code>False</code> <code>c_range</code> <code>str | None</code> <p>Color range: \"full\": Full possible spectrum (0-255 or 0-1), \"single\": Take min/max of given volume. <code>None</code>: Default: do not change color range.</p> <code>None</code> <code>kwargs</code> <p>Additional keyword arguments for <code>plt.imshow()</code>. And, <code>crosshairs: bool = True</code>, <code>ticks: bool = False</code>.</p> <code>{}</code> Source code in <code>src/xai4mri/visualizer/visualize_mri.py</code> <pre><code>def plot_slice(\n    volume: np.ndarray,\n    axis: int | _Axis,\n    idx_slice: int,\n    edges: bool = False,\n    c_range: str | None = None,\n    **kwargs,\n) -&gt; plt.AxesImage:\n    \"\"\"\n    Plot one slice of a 3D volume.\n\n    :param volume: 3D volume (MRI).\n    :param axis: The volume axis to plot from.\n    :param idx_slice: The slice index to plot.\n    :param edges: Draw edges around the brain if set to `True`.\n    :param c_range: Color range:\n                    \"full\": Full possible spectrum (0-255 or 0-1),\n                    \"single\": Take min/max of given volume.\n                    `None`: Default: do not change color range.\n    :param kwargs: Additional keyword arguments for `plt.imshow()`.\n                   And, `crosshairs: bool = True`, `ticks: bool = False`.\n    \"\"\"\n    im, _edges = None, None  # init\n    if edges:\n        n_dims = 4\n        _edges = find_brain_edges(volume if volume.shape[-1] &gt; n_dims else volume[..., -1])\n        # works for transparent RGB images (x,y,z,4) and volumes (x,y,z)\n\n    # Set color range\n    if c_range == \"full\":  # takes full possible spectrum\n        i_max = 255 if np.max(volume) &gt; 1 else 1.0\n        i_min = 0 if np.min(volume) &gt;= 0 else -1.0\n    elif c_range == \"single\":  # takes min/max of given brain\n        i_max = np.max(volume)\n        i_min = np.min(volume)\n    else:  # c_range=None\n        if c_range is not None:\n            msg = \"c_range must be 'full', 'single' or None.\"\n            raise ValueError(msg)\n        i_max, i_min = None, None\n\n    # Get kwargs (which are not for imshow)\n    crosshairs = kwargs.pop(\"crosshairs\", False)\n    ticks = kwargs.pop(\"ticks\", False)\n\n    axis = _Axis(axis)  # this also checks if the axis is valid\n    if axis is _Axis.SAGITTAL:  # sagittal\n        im = plt.imshow(volume[idx_slice, :, :], vmin=i_min, vmax=i_max, **kwargs)\n        if edges:\n            plt.hlines(_edges[2] - 1, 2, volume.shape[1] - 2, colors=\"darkgrey\", alpha=0.3)  # == max edges\n            plt.hlines(_edges[3] + 1, 2, volume.shape[1] - 2, colors=\"darkgrey\", alpha=0.3)\n            plt.vlines(_edges[4] - 1, 2, volume.shape[0] - 2, colors=\"darkgrey\", alpha=0.3)\n            plt.vlines(_edges[5] + 1, 2, volume.shape[0] - 2, colors=\"darkgrey\", alpha=0.3)\n\n    elif axis == _Axis.TRANSVERSE:  # transverse / superior\n        im = plt.imshow(\n            np.rot90(volume[:, idx_slice, :], axes=(0, 1)),\n            vmin=i_min,\n            vmax=i_max,\n            **kwargs,\n        )\n        if edges:\n            plt.hlines(\n                volume.shape[0] - _edges[5] - 1,\n                2,\n                volume.shape[0] - 2,\n                colors=\"darkgrey\",\n                alpha=0.3,\n            )\n            plt.hlines(\n                volume.shape[0] - _edges[4] + 1,\n                2,\n                volume.shape[0] - 2,\n                colors=\"darkgrey\",\n                alpha=0.3,\n            )\n            plt.vlines(_edges[0] - 1, 2, volume.shape[1] - 2, colors=\"darkgrey\", alpha=0.3)\n            plt.vlines(_edges[1] + 1, 2, volume.shape[1] - 2, colors=\"darkgrey\", alpha=0.3)\n\n    elif axis == _Axis.CORONAL:  # coronal / posterior\n        im = plt.imshow(\n            np.rot90(volume[:, :, idx_slice], axes=(1, 0)),\n            vmin=i_min,\n            vmax=i_max,\n            **kwargs,\n        )\n        if edges:\n            plt.hlines(_edges[2] - 1, 2, volume.shape[0] - 2, colors=\"darkgrey\", alpha=0.3)\n            plt.hlines(_edges[3] + 1, 2, volume.shape[0] - 2, colors=\"darkgrey\", alpha=0.3)\n            plt.vlines(\n                volume.shape[1] - _edges[1] - 1,\n                2,\n                volume.shape[1] - 2,\n                colors=\"darkgrey\",\n                alpha=0.3,\n            )\n            plt.vlines(\n                volume.shape[1] - _edges[0] + 1,\n                2,\n                volume.shape[1] - 2,\n                colors=\"darkgrey\",\n                alpha=0.3,\n            )\n\n    # Add mid-cross ('crosshairs')\n    if crosshairs:\n        plt.hlines(int(volume.shape[axis.value] / 2), 2, len(volume) - 2, colors=\"red\", alpha=0.3)\n        plt.vlines(int(volume.shape[axis.value] / 2), 2, len(volume) - 2, colors=\"red\", alpha=0.3)\n\n    if not ticks:\n        plt.axis(\"off\")\n\n    return im\n</code></pre>"},{"location":"reference/visualizer/#xai4mri.visualizer.slice_through","title":"slice_through","text":"<pre><code>slice_through(\n    volume: ndarray,\n    every: int = 2,\n    axis: int | _Axis = 0,\n    fig_name: str | None = None,\n    edges: bool = True,\n    c_range: str | None = None,\n    **kwargs\n) -&gt; Figure\n</code></pre> <p>Plot several slices of a given 3D-volume in the form of a grid.</p> <p>For fancy slicing, check: https://docs.pyvista.org/examples/01-filter/slicing.html.</p> <p>Parameters:</p> Name Type Description Default <code>volume</code> <code>ndarray</code> <p>3D volume (MRI).</p> required <code>every</code> <code>int</code> <p>Plot every n-th slice. That is, for <code>every=1</code>, all slices are plotted. And, for <code>every=2</code>, every second slice is plotted, and so on.</p> <code>2</code> <code>axis</code> <code>int | _Axis</code> <p>The volume axis to plot from.</p> <code>0</code> <code>fig_name</code> <code>str | None</code> <p>Name of the figure.</p> <code>None</code> <code>edges</code> <code>bool</code> <p>Draw edges around the brain if set to <code>True</code>.</p> <code>True</code> <code>c_range</code> <code>str | None</code> <p>Color range: \"full\": Full possible spectrum (0-255 or 0-1), \"single\": Take min/max of given volume. <code>None</code>: Default: do not change color range.</p> <code>None</code> <code>kwargs</code> <p>Additional keyword arguments for <code>plt.imshow()</code>. And, <code>crosshairs: bool = True</code>, <code>ticks: bool = False</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Figure</code> <p>The figure object of the plot.</p> Source code in <code>src/xai4mri/visualizer/visualize_mri.py</code> <pre><code>def slice_through(\n    volume: np.ndarray,\n    every: int = 2,\n    axis: int | _Axis = 0,\n    fig_name: str | None = None,\n    edges: bool = True,\n    c_range: str | None = None,\n    **kwargs,\n) -&gt; plt.Figure:\n    \"\"\"\n    Plot several slices of a given 3D-volume in the form of a grid.\n\n    For fancy slicing, check: https://docs.pyvista.org/examples/01-filter/slicing.html.\n\n    :param volume: 3D volume (MRI).\n    :param every: Plot every n-th slice.\n                  That is, for `every=1`, all slices are plotted.\n                  And, for `every=2`, every second slice is plotted, and so on.\n    :param axis: The volume axis to plot from.\n    :param fig_name: Name of the figure.\n    :param edges: Draw edges around the brain if set to `True`.\n    :param c_range: Color range:\n                    \"full\": Full possible spectrum (0-255 or 0-1),\n                    \"single\": Take min/max of given volume.\n                    `None`: Default: do not change color range.\n    :param kwargs: Additional keyword arguments for `plt.imshow()`.\n                   And, `crosshairs: bool = True`, `ticks: bool = False`.\n    :return: The figure object of the plot.\n    \"\"\"\n    axis = _Axis(axis)\n\n    n_row_sq_grid = 5\n    n_slices = volume.shape[axis.value] // every\n    n_figs = np.round(n_slices // n_row_sq_grid**2)\n\n    axis_name = axis.name.lower()\n\n    fig_n = 1\n    sub_n = 1\n    fig = None  # init\n    for scl in range(n_slices):\n        if scl % (n_row_sq_grid**2) == 0:\n            fig = plt.figure(\n                num=f\"{fig_name if fig_name else ''} {axis_name} slice-through {fig_n}|{n_figs}\",\n                figsize=(10, 10),\n            )\n\n        plt.subplot(n_row_sq_grid, n_row_sq_grid, sub_n)\n\n        plot_slice(\n            volume=volume,\n            axis=axis,\n            idx_slice=scl + (every - 1),\n            edges=edges,\n            c_range=c_range,\n            **kwargs,\n        )\n\n        plt.tight_layout()\n\n        sub_n += 1\n\n        if ((sub_n - 1) % (n_row_sq_grid**2) == 0) or (scl + 1 == n_slices):\n            fig_n += 1\n            sub_n = 1\n\n    return fig\n</code></pre>"},{"location":"reference/visualizer/visualize_heatmap/","title":"<code class=\"doc-symbol doc-symbol-nav doc-symbol-module\"></code> visualize_heatmap","text":""},{"location":"reference/visualizer/visualize_heatmap/#xai4mri.visualizer.visualize_heatmap","title":"visualize_heatmap","text":"<p>Functions to visualize analyzer (XAI) heatmaps.</p> <p>Quick Start</p> <p>Particularly, the <code>plot_heatmap</code> function is used to visualize the relevance maps of the <code>LRP</code> analyzer from <code>xai4mri.model.interpreter</code>.</p> <pre><code>from xai4mri.model.interpreter import analyze_model\nfrom xai4mri.visualizer import plot_heatmap\n\n# Analyze model\nanalyzer_obj = analyze_model(model=model, ipt=mri_image, ...)\n\n# Visualize heatmap / relevance map\nanalyzer_fig = plot_heatmap(ipt=mri_image, analyser_obj=analyzer_obj, ...)\n</code></pre> <pre><code>Author: Simon M. Hofmann\nYears: 2023-2024\n</code></pre>"},{"location":"reference/visualizer/visualize_heatmap/#xai4mri.visualizer.visualize_heatmap.gregoire_black_fire_red","title":"gregoire_black_fire_red","text":"<pre><code>gregoire_black_fire_red(analyser_obj: ndarray) -&gt; ndarray\n</code></pre> <p>Apply a color scheme to the analyzer object.</p> <p>Parameters:</p> Name Type Description Default <code>analyser_obj</code> <code>ndarray</code> <p>XAI analyzer object (e.g., <code>LRP</code> relevance map).</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Colorized relevance map.</p> Source code in <code>src/xai4mri/visualizer/visualize_heatmap.py</code> <pre><code>def gregoire_black_fire_red(analyser_obj: np.ndarray) -&gt; np.ndarray:\n    \"\"\"\n    Apply a color scheme to the analyzer object.\n\n    :param analyser_obj: XAI analyzer object (e.g., `LRP` relevance map).\n    :return: Colorized relevance map.\n    \"\"\"\n    x = analyser_obj.copy()\n    x /= np.max(np.abs(x))\n\n    hrp = np.clip(x - 0.00, a_min=0, a_max=0.25) / 0.25  # all pos. values(+) above 0 get red, above .25 full red(=1.)\n    hgp = np.clip(x - 0.25, a_min=0, a_max=0.25) / 0.25  # all above .25 get green, above .50 full green\n    hbp = np.clip(x - 0.50, a_min=0, a_max=0.50) / 0.50  # all above .50 get blue until full blue at 1. (mix 2 white)\n\n    hbn = np.clip(-x - 0.00, a_min=0, a_max=0.25) / 0.25  # all neg. values(-) below 0 get blue ...\n    hgn = np.clip(-x - 0.25, a_min=0, a_max=0.25) / 0.25  # ... green ....\n    hrn = np.clip(-x - 0.50, a_min=0, a_max=0.50) / 0.50  # ... red ... mixes to white (1.,1.,1.)\n\n    return np.concatenate(\n        [(hrp + hrn)[..., None], (hgp + hgn)[..., None], (hbp + hbn)[..., None]],\n        axis=x.ndim,\n    )\n</code></pre>"},{"location":"reference/visualizer/visualize_heatmap/#xai4mri.visualizer.visualize_heatmap.list_supported_cmaps","title":"list_supported_cmaps","text":"<pre><code>list_supported_cmaps()\n</code></pre> <p>Return a list of supported color maps for heatmap plotting.</p> Source code in <code>src/xai4mri/visualizer/visualize_heatmap.py</code> <pre><code>def list_supported_cmaps():\n    \"\"\"Return a list of supported color maps for heatmap plotting.\"\"\"\n    print(*(list(custom_maps.keys()) + CMAPS), sep=\"\\n\")\n    return list(custom_maps.keys()) + CMAPS\n</code></pre>"},{"location":"reference/visualizer/visualize_heatmap/#xai4mri.visualizer.visualize_heatmap.plot_heatmap","title":"plot_heatmap","text":"<pre><code>plot_heatmap(\n    ipt: ndarray,\n    analyser_obj: ndarray,\n    cmap_name: str = \"black-fire-red\",\n    mode: str = \"triplet\",\n    fig_name: str = \"Heatmap\",\n    **kwargs\n) -&gt; Figure\n</code></pre> <p>Plot an XAI-based analyzer object over the model input in the form of a heatmap.</p> <p>How to use</p> <pre><code>from xai4mri.model.interpreter import analyze_model\nfrom xai4mri.visualizer import plot_heatmap\n\n# Analyze model\nanalyzer_obj = analyze_model(model=model, ipt=mri_image, ...)\n\n# Visualize heatmap / relevance map\nanalyzer_fig = plot_heatmap(ipt=mri_image, analyser_obj=analyzer_obj, ...)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>ipt</code> <code>ndarray</code> <p>Model input image.</p> required <code>analyser_obj</code> <code>ndarray</code> <p>Analyzer object (relevance map) that is computed by the model interpreter (e.g., <code>LRP</code>). Both the input image and the analyzer object must have the same shape.</p> required <code>cmap_name</code> <code>str</code> <p>Name of color-map (<code>cmap</code>) to be applied.</p> <code>'black-fire-red'</code> <code>mode</code> <code>str</code> <p>\"triplet\": Plot three slices of different axes. \"all\": Plot all slices (w/ brain OR w/o brain \u2192 set: <code>plot_empty=True</code> in <code>kwargs</code>)</p> <code>'triplet'</code> <code>fig_name</code> <code>str</code> <p>name of figure</p> <code>'Heatmap'</code> <code>kwargs</code> <p>Additional kwargs: \"c_intensifier\", \"clip_q\", \"min_sym_clip\", \"true_scale\", \"plot_empty\", \"axis\", \"every\", \"crosshair\", \"gamma\". And, <code>kwargs</code> for <code>plot_mid_slice()</code> and <code>slice_through()</code> from <code>xai4mri.visualizer.visualize_mri</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Figure</code> <p><code>plt.Figure</code> object of the heatmap plot.</p> Source code in <code>src/xai4mri/visualizer/visualize_heatmap.py</code> <pre><code>def plot_heatmap(\n    ipt: np.ndarray,\n    analyser_obj: np.ndarray,\n    cmap_name: str = \"black-fire-red\",\n    mode: str = \"triplet\",\n    fig_name: str = \"Heatmap\",\n    **kwargs,\n) -&gt; plt.Figure:\n    \"\"\"\n    Plot an XAI-based analyzer object over the model input in the form of a heatmap.\n\n    !!! example \"How to use\"\n        ```python\n        from xai4mri.model.interpreter import analyze_model\n        from xai4mri.visualizer import plot_heatmap\n\n        # Analyze model\n        analyzer_obj = analyze_model(model=model, ipt=mri_image, ...)\n\n        # Visualize heatmap / relevance map\n        analyzer_fig = plot_heatmap(ipt=mri_image, analyser_obj=analyzer_obj, ...)\n        ```\n\n    :param ipt: Model input image.\n    :param analyser_obj: Analyzer object (relevance map) that is computed by the model interpreter (e.g., `LRP`).\n                         Both the input image and the analyzer object must have the same shape.\n    :param cmap_name: Name of color-map (`cmap`) to be applied.\n    :param mode: \"triplet\": Plot three slices of different axes.\n                 \"all\": Plot all slices (w/ brain OR w/o brain \u2192 set: `plot_empty=True` in `kwargs`)\n    :param fig_name: name of figure\n    :param kwargs: Additional kwargs:\n                   \"c_intensifier\", \"clip_q\", \"min_sym_clip\", \"true_scale\", \"plot_empty\", \"axis\", \"every\", \"crosshair\",\n                    \"gamma\".\n                    And, `kwargs` for `plot_mid_slice()` and `slice_through()` from `xai4mri.visualizer.visualize_mri`.\n    :return: `plt.Figure` object of the heatmap plot.\n    \"\"\"\n    a = analyser_obj.copy().squeeze().astype(np.float32)\n    mode = mode.lower()\n    if mode not in {\"triplet\", \"all\"}:\n        msg = \"mode must be 'triplet', or 'all'!\"\n        raise ValueError(msg)\n\n    # Extract kwargs\n    cintensifier = kwargs.pop(\"c_intensifier\", 1.0)\n    clipq = kwargs.pop(\"clip_q\", 1e-2)\n    min_sym_clip = kwargs.pop(\"min_sym_clip\", True)\n    true_scale = kwargs.pop(\"true_scale\", False)\n    plot_empty = kwargs.pop(\"plot_empty\", False)\n    axis = kwargs.pop(\"axis\", 0)\n    every = kwargs.pop(\"every\", 2)\n    crosshairs = kwargs.pop(\"crosshair\", False)\n    gamma = kwargs.pop(\"gamma\", 0.2)\n\n    # Render image\n    colored_a = _apply_colormap(\n        analyser_obj=a,\n        input_image=ipt.squeeze().astype(np.float32),\n        cmap_name=cmap_name,\n        c_intensifier=cintensifier,\n        clip_q=clipq,\n        min_sym_clip=min_sym_clip,\n        gamma=gamma,\n        true_scale=true_scale,\n    )\n    heatmap = colored_a[0]\n\n    cbar_range = (-1, 1) if not true_scale else (-colored_a[2], colored_a[2])\n    if mode == \"triplet\":\n        fig = plot_mid_slice(\n            volume=heatmap,\n            fig_name=fig_name,\n            cmap=_create_cmap(gregoire_black_fire_red),\n            c_range=\"full\",\n            cbar=True,\n            cbar_range=cbar_range,\n            edges=False,\n            crosshairs=crosshairs,\n            **kwargs,\n        )\n\n    else:  # mode == \"all\"\n        if not plot_empty:\n            # Remove planes with no information\n            heatmap = heatmap.compress(\n                ~np.all(\n                    heatmap == 0,\n                    axis=tuple(ax for ax in range(heatmap.ndim) if ax != axis),\n                ),\n                axis=axis,\n            )\n\n        fig = slice_through(\n            volume=heatmap,\n            every=every,\n            axis=axis,\n            fig_name=fig_name,\n            edges=False,\n            cmap=_create_cmap(gregoire_black_fire_red),\n            c_range=\"full\",\n            crosshairs=crosshairs,\n            **kwargs,\n        )\n    return fig\n</code></pre>"},{"location":"reference/visualizer/visualize_mri/","title":"<code class=\"doc-symbol doc-symbol-nav doc-symbol-module\"></code> visualize_mri","text":""},{"location":"reference/visualizer/visualize_mri/#xai4mri.visualizer.visualize_mri","title":"visualize_mri","text":"<p>Functions to visualize MRIs.</p> <pre><code>Author: Simon M. Hofmann\nYears: 2023-2024\n</code></pre>"},{"location":"reference/visualizer/visualize_mri/#xai4mri.visualizer.visualize_mri.plot_mid_slice","title":"plot_mid_slice","text":"<pre><code>plot_mid_slice(\n    volume: ndarray,\n    axis: int | _Axis | None = None,\n    fig_name: str | None = None,\n    edges: bool = True,\n    c_range: str | None = None,\n    **kwargs\n) -&gt; Figure\n</code></pre> <p>Plot 2D-slices of a given 3D-volume.</p> <p>If no axis is given, plot for each axis its middle slice.</p> <p>Parameters:</p> Name Type Description Default <code>volume</code> <code>ndarray</code> <p>3D volume (MRI).</p> required <code>axis</code> <code>int | _Axis | None</code> <p><code>None</code>: Slices from all three axes are plotted. To plot a specific axis only, provide <code>int</code> or <code>_Axis</code>.</p> <code>None</code> <code>fig_name</code> <code>str | None</code> <p>Name of the figure.</p> <code>None</code> <code>edges</code> <code>bool</code> <p>Draw edges around the brain if set to <code>True</code>.</p> <code>True</code> <code>c_range</code> <code>str | None</code> <p>Color range: \"full\": Full possible spectrum (0-255 or 0-1), \"single\": Take min/max of given volume. <code>None</code>: Default: do not change color range.</p> <code>None</code> <code>kwargs</code> <p>Additional keyword arguments for <code>plt.imshow()</code>. And, <code>crosshairs: bool = True</code>, <code>ticks: bool = False</code>. Also, <code>cbar: bool = False</code> and <code>cbar_range: tuple[int, int] = None</code> for a color bar, <code>suptitle: str = None</code> for a title, and <code>slice_idx: int | tuple[int, int, int] = None</code> for specific slice indices to plot, if not provided, the middle slice(s) are plotted.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Figure</code> <p>The figure object of the plot.</p> Source code in <code>src/xai4mri/visualizer/visualize_mri.py</code> <pre><code>def plot_mid_slice(\n    volume: np.ndarray,\n    axis: int | _Axis | None = None,\n    fig_name: str | None = None,\n    edges: bool = True,\n    c_range: str | None = None,\n    **kwargs,\n) -&gt; plt.Figure:\n    \"\"\"\n    Plot 2D-slices of a given 3D-volume.\n\n    If no axis is given, plot for each axis its middle slice.\n\n    :param volume: 3D volume (MRI).\n    :param axis: `None`: Slices from all three axes are plotted.\n                 To plot a specific axis only, provide `int` or `_Axis`.\n    :param fig_name: Name of the figure.\n    :param edges:  Draw edges around the brain if set to `True`.\n    :param c_range: Color range:\n                    \"full\": Full possible spectrum (0-255 or 0-1),\n                    \"single\": Take min/max of given volume.\n                    `None`: Default: do not change color range.\n    :param kwargs: Additional keyword arguments for `plt.imshow()`.\n                   And, `crosshairs: bool = True`, `ticks: bool = False`.\n                   Also, `cbar: bool = False` and `cbar_range: tuple[int, int] = None` for a color bar,\n                   `suptitle: str = None` for a title,\n                   and `slice_idx: int | tuple[int, int, int] = None` for specific slice indices to plot,\n                   if not provided, the middle slice(s) are plotted.\n    :return: The figure object of the plot.\n    \"\"\"\n    # Get color bar kwargs (if any)\n    cbar = kwargs.pop(\"cbar\", False)\n    cbar_range = kwargs.pop(\"cbar_range\") if (\"cbar_range\" in kwargs and cbar) else None\n    # only if cbar is active\n    suptitle = kwargs.pop(\"suptitle\", None)\n    slice_idx = kwargs.pop(\"slice_idx\", None)  # in case mid or other slice is given\n\n    # Set (mid-)slice index\n    sl = int(np.round(volume.shape[0] / 2)) if slice_idx is None else slice_idx\n    max_n_axes = 3\n    if slice_idx is None:\n        sl_str = \"mid\"\n    elif isinstance(sl, (list, tuple)):\n        if len(sl) != max_n_axes:\n            msg = \"slice_idx must be tuple or list of length 3, is None or single int.\"\n            raise ValueError(msg)\n        sl_str = str(sl)\n    else:\n        sl_str = str(int(sl))\n\n    # Begin plotting\n    if axis is None:\n        _fs = {\"size\": 10}  # define font size\n\n        fig = plt.figure(num=f\"{fig_name if fig_name else ''} volume {sl_str}-slice\", figsize=(12, 4))\n        if isinstance(suptitle, str) and suptitle:\n            fig.suptitle(suptitle, fontsize=14)\n\n        # Planes\n        ims = []\n        axs = []\n        sls = [sl] * 3 if isinstance(sl, int) else sl  # is tuple pf length 3 or int\n        for ip, _plane in enumerate(PLANES):\n            axs.append(fig.add_subplot(1, 3, ip + 1))\n            ims.append(\n                plot_slice(\n                    volume,\n                    axis=ip,\n                    idx_slice=sls[ip],\n                    edges=edges,\n                    c_range=c_range,\n                    **kwargs,\n                )\n            )\n            plt.title(_plane, fontdict=_fs)\n\n            divider = make_axes_locatable(axs[ip])\n            cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n            cax.axis(\"off\")\n            if cbar and ip == len(PLANES) - 1:\n                cax_bar = fig.colorbar(ims[-1], ax=cax, fraction=0.048, pad=0.04)  # shrink=.8, aspect=50)\n                if cbar_range:\n                    cax_bar.set_ticks(ticks=np.linspace(start=0, stop=1, num=7), minor=True)\n                    cax_bar.ax.set_yticklabels(\n                        labels=[\n                            f\"{tick:.2g}\"\n                            for tick in np.linspace(cbar_range[0], cbar_range[1], len(cax_bar.get_ticks()))\n                        ]\n                    )\n\n    else:  # If specific axis to plot\n        axis = _Axis(axis)\n        axis_name = axis.name.lower()\n\n        fig = plt.figure(f\"{fig_name if fig_name else ''} {axis_name} {sl_str}-slice\")\n        im = plot_slice(volume, axis.value, idx_slice=sl, edges=edges, c_range=c_range, **kwargs)\n        if cbar:\n            cax_bar = fig.colorbar(im, fraction=0.048, pad=0.04)  # shrink=0.8, aspect=50)\n            if cbar_range:\n                cax_bar.set_ticks(ticks=np.linspace(start=0, stop=1, num=7), minor=True)\n                cax_bar.ax.set_yticklabels(\n                    labels=[\n                        f\"{tick:.2g}\" for tick in np.linspace(cbar_range[0], cbar_range[1], len(cax_bar.get_ticks()))\n                    ]\n                )\n\n        plt.tight_layout()\n\n    return fig\n</code></pre>"},{"location":"reference/visualizer/visualize_mri/#xai4mri.visualizer.visualize_mri.plot_slice","title":"plot_slice","text":"<pre><code>plot_slice(\n    volume: ndarray,\n    axis: int | _Axis,\n    idx_slice: int,\n    edges: bool = False,\n    c_range: str | None = None,\n    **kwargs\n) -&gt; AxesImage\n</code></pre> <p>Plot one slice of a 3D volume.</p> <p>Parameters:</p> Name Type Description Default <code>volume</code> <code>ndarray</code> <p>3D volume (MRI).</p> required <code>axis</code> <code>int | _Axis</code> <p>The volume axis to plot from.</p> required <code>idx_slice</code> <code>int</code> <p>The slice index to plot.</p> required <code>edges</code> <code>bool</code> <p>Draw edges around the brain if set to <code>True</code>.</p> <code>False</code> <code>c_range</code> <code>str | None</code> <p>Color range: \"full\": Full possible spectrum (0-255 or 0-1), \"single\": Take min/max of given volume. <code>None</code>: Default: do not change color range.</p> <code>None</code> <code>kwargs</code> <p>Additional keyword arguments for <code>plt.imshow()</code>. And, <code>crosshairs: bool = True</code>, <code>ticks: bool = False</code>.</p> <code>{}</code> Source code in <code>src/xai4mri/visualizer/visualize_mri.py</code> <pre><code>def plot_slice(\n    volume: np.ndarray,\n    axis: int | _Axis,\n    idx_slice: int,\n    edges: bool = False,\n    c_range: str | None = None,\n    **kwargs,\n) -&gt; plt.AxesImage:\n    \"\"\"\n    Plot one slice of a 3D volume.\n\n    :param volume: 3D volume (MRI).\n    :param axis: The volume axis to plot from.\n    :param idx_slice: The slice index to plot.\n    :param edges: Draw edges around the brain if set to `True`.\n    :param c_range: Color range:\n                    \"full\": Full possible spectrum (0-255 or 0-1),\n                    \"single\": Take min/max of given volume.\n                    `None`: Default: do not change color range.\n    :param kwargs: Additional keyword arguments for `plt.imshow()`.\n                   And, `crosshairs: bool = True`, `ticks: bool = False`.\n    \"\"\"\n    im, _edges = None, None  # init\n    if edges:\n        n_dims = 4\n        _edges = find_brain_edges(volume if volume.shape[-1] &gt; n_dims else volume[..., -1])\n        # works for transparent RGB images (x,y,z,4) and volumes (x,y,z)\n\n    # Set color range\n    if c_range == \"full\":  # takes full possible spectrum\n        i_max = 255 if np.max(volume) &gt; 1 else 1.0\n        i_min = 0 if np.min(volume) &gt;= 0 else -1.0\n    elif c_range == \"single\":  # takes min/max of given brain\n        i_max = np.max(volume)\n        i_min = np.min(volume)\n    else:  # c_range=None\n        if c_range is not None:\n            msg = \"c_range must be 'full', 'single' or None.\"\n            raise ValueError(msg)\n        i_max, i_min = None, None\n\n    # Get kwargs (which are not for imshow)\n    crosshairs = kwargs.pop(\"crosshairs\", False)\n    ticks = kwargs.pop(\"ticks\", False)\n\n    axis = _Axis(axis)  # this also checks if the axis is valid\n    if axis is _Axis.SAGITTAL:  # sagittal\n        im = plt.imshow(volume[idx_slice, :, :], vmin=i_min, vmax=i_max, **kwargs)\n        if edges:\n            plt.hlines(_edges[2] - 1, 2, volume.shape[1] - 2, colors=\"darkgrey\", alpha=0.3)  # == max edges\n            plt.hlines(_edges[3] + 1, 2, volume.shape[1] - 2, colors=\"darkgrey\", alpha=0.3)\n            plt.vlines(_edges[4] - 1, 2, volume.shape[0] - 2, colors=\"darkgrey\", alpha=0.3)\n            plt.vlines(_edges[5] + 1, 2, volume.shape[0] - 2, colors=\"darkgrey\", alpha=0.3)\n\n    elif axis == _Axis.TRANSVERSE:  # transverse / superior\n        im = plt.imshow(\n            np.rot90(volume[:, idx_slice, :], axes=(0, 1)),\n            vmin=i_min,\n            vmax=i_max,\n            **kwargs,\n        )\n        if edges:\n            plt.hlines(\n                volume.shape[0] - _edges[5] - 1,\n                2,\n                volume.shape[0] - 2,\n                colors=\"darkgrey\",\n                alpha=0.3,\n            )\n            plt.hlines(\n                volume.shape[0] - _edges[4] + 1,\n                2,\n                volume.shape[0] - 2,\n                colors=\"darkgrey\",\n                alpha=0.3,\n            )\n            plt.vlines(_edges[0] - 1, 2, volume.shape[1] - 2, colors=\"darkgrey\", alpha=0.3)\n            plt.vlines(_edges[1] + 1, 2, volume.shape[1] - 2, colors=\"darkgrey\", alpha=0.3)\n\n    elif axis == _Axis.CORONAL:  # coronal / posterior\n        im = plt.imshow(\n            np.rot90(volume[:, :, idx_slice], axes=(1, 0)),\n            vmin=i_min,\n            vmax=i_max,\n            **kwargs,\n        )\n        if edges:\n            plt.hlines(_edges[2] - 1, 2, volume.shape[0] - 2, colors=\"darkgrey\", alpha=0.3)\n            plt.hlines(_edges[3] + 1, 2, volume.shape[0] - 2, colors=\"darkgrey\", alpha=0.3)\n            plt.vlines(\n                volume.shape[1] - _edges[1] - 1,\n                2,\n                volume.shape[1] - 2,\n                colors=\"darkgrey\",\n                alpha=0.3,\n            )\n            plt.vlines(\n                volume.shape[1] - _edges[0] + 1,\n                2,\n                volume.shape[1] - 2,\n                colors=\"darkgrey\",\n                alpha=0.3,\n            )\n\n    # Add mid-cross ('crosshairs')\n    if crosshairs:\n        plt.hlines(int(volume.shape[axis.value] / 2), 2, len(volume) - 2, colors=\"red\", alpha=0.3)\n        plt.vlines(int(volume.shape[axis.value] / 2), 2, len(volume) - 2, colors=\"red\", alpha=0.3)\n\n    if not ticks:\n        plt.axis(\"off\")\n\n    return im\n</code></pre>"},{"location":"reference/visualizer/visualize_mri/#xai4mri.visualizer.visualize_mri.slice_through","title":"slice_through","text":"<pre><code>slice_through(\n    volume: ndarray,\n    every: int = 2,\n    axis: int | _Axis = 0,\n    fig_name: str | None = None,\n    edges: bool = True,\n    c_range: str | None = None,\n    **kwargs\n) -&gt; Figure\n</code></pre> <p>Plot several slices of a given 3D-volume in the form of a grid.</p> <p>For fancy slicing, check: https://docs.pyvista.org/examples/01-filter/slicing.html.</p> <p>Parameters:</p> Name Type Description Default <code>volume</code> <code>ndarray</code> <p>3D volume (MRI).</p> required <code>every</code> <code>int</code> <p>Plot every n-th slice. That is, for <code>every=1</code>, all slices are plotted. And, for <code>every=2</code>, every second slice is plotted, and so on.</p> <code>2</code> <code>axis</code> <code>int | _Axis</code> <p>The volume axis to plot from.</p> <code>0</code> <code>fig_name</code> <code>str | None</code> <p>Name of the figure.</p> <code>None</code> <code>edges</code> <code>bool</code> <p>Draw edges around the brain if set to <code>True</code>.</p> <code>True</code> <code>c_range</code> <code>str | None</code> <p>Color range: \"full\": Full possible spectrum (0-255 or 0-1), \"single\": Take min/max of given volume. <code>None</code>: Default: do not change color range.</p> <code>None</code> <code>kwargs</code> <p>Additional keyword arguments for <code>plt.imshow()</code>. And, <code>crosshairs: bool = True</code>, <code>ticks: bool = False</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Figure</code> <p>The figure object of the plot.</p> Source code in <code>src/xai4mri/visualizer/visualize_mri.py</code> <pre><code>def slice_through(\n    volume: np.ndarray,\n    every: int = 2,\n    axis: int | _Axis = 0,\n    fig_name: str | None = None,\n    edges: bool = True,\n    c_range: str | None = None,\n    **kwargs,\n) -&gt; plt.Figure:\n    \"\"\"\n    Plot several slices of a given 3D-volume in the form of a grid.\n\n    For fancy slicing, check: https://docs.pyvista.org/examples/01-filter/slicing.html.\n\n    :param volume: 3D volume (MRI).\n    :param every: Plot every n-th slice.\n                  That is, for `every=1`, all slices are plotted.\n                  And, for `every=2`, every second slice is plotted, and so on.\n    :param axis: The volume axis to plot from.\n    :param fig_name: Name of the figure.\n    :param edges: Draw edges around the brain if set to `True`.\n    :param c_range: Color range:\n                    \"full\": Full possible spectrum (0-255 or 0-1),\n                    \"single\": Take min/max of given volume.\n                    `None`: Default: do not change color range.\n    :param kwargs: Additional keyword arguments for `plt.imshow()`.\n                   And, `crosshairs: bool = True`, `ticks: bool = False`.\n    :return: The figure object of the plot.\n    \"\"\"\n    axis = _Axis(axis)\n\n    n_row_sq_grid = 5\n    n_slices = volume.shape[axis.value] // every\n    n_figs = np.round(n_slices // n_row_sq_grid**2)\n\n    axis_name = axis.name.lower()\n\n    fig_n = 1\n    sub_n = 1\n    fig = None  # init\n    for scl in range(n_slices):\n        if scl % (n_row_sq_grid**2) == 0:\n            fig = plt.figure(\n                num=f\"{fig_name if fig_name else ''} {axis_name} slice-through {fig_n}|{n_figs}\",\n                figsize=(10, 10),\n            )\n\n        plt.subplot(n_row_sq_grid, n_row_sq_grid, sub_n)\n\n        plot_slice(\n            volume=volume,\n            axis=axis,\n            idx_slice=scl + (every - 1),\n            edges=edges,\n            c_range=c_range,\n            **kwargs,\n        )\n\n        plt.tight_layout()\n\n        sub_n += 1\n\n        if ((sub_n - 1) % (n_row_sq_grid**2) == 0) or (scl + 1 == n_slices):\n            fig_n += 1\n            sub_n = 1\n\n    return fig\n</code></pre>"},{"location":"coverage/","title":"Coverage report","text":""}]}